---
论文名称: Phi-4-Mini Technical Report Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs
tags:
  - "#技术报告"
  - "#Phi-4-Mini"
摘要: 我们介绍了 Phi-4-Mini 和 Phi-4-Multimodal，这两种紧凑且高度强大的语言和多模态模型。Phi-4-Mini 是一个在高质量网页和合成数据上训练的 38 亿参数语言模型，在类似规模的最新开源模型中表现出色，在需要复杂推理的数学和编码任务上，其性能与两倍大小的模型相当。这一成就得益于精心策划的合成数据配方，强调高质量的数学和编码数据集。与它的前身 Phi-3.5-Mini 相比，Phi-4-Mini 具有 200K 个标记的扩展词汇量，以更好地支持多语言应用，以及组查询注意力以更有效地生成长序列。Phi-4-Multimodal 是一种多模态模型，将文本、视觉和语音/音频输入模态集成到一个单一模型中。其新颖的模态扩展方法利用 LoRA 适配器和模态特定路由器，允许结合各种模态的多个推理模式而不会相互干扰。例如，它目前在 OpenASR 排行榜上排名第一，尽管语音/音频模态的 LoRA 组件仅有 4.6 亿参数。 Phi-4-Multimodal 支持涉及（视觉+语言）、（视觉+语音）和（语音/音频）输入的场景，在广泛的任务上优于更大的视觉-语言和语音-语言模型。此外，我们尝试进一步训练 Phi-4-Mini 以增强其推理能力。尽管其参数规模仅为 38 亿，这个实验版本在推理性能上与或显著优于 DeepSeek-R1-Distill-Qwen-7B 和 DeepSeek-R1-Distill-Llama-8B 等更大模型。
发布时间: 2025
链接: https://arxiv.org/abs/2503.01743
---
Phi-4-Mini 技术报告：通过混合 LoRAs 实现紧凑且强大的多模态语言模型


Microsoft1

##   摘要

我们介绍了 Phi-4-Mini 和 Phi-4-Multimodal，这两种紧凑且高度强大的语言和多模态模型。Phi-4-Mini 是一个在高质量网页和合成数据上训练的 38 亿参数语言模型，在类似规模的最新开源模型中表现出色，在需要复杂推理的数学和编码任务上，其性能与两倍大小的模型相当。这一成就得益于精心策划的合成数据配方，强调高质量的数学和编码数据集。与它的前身 Phi-3.5-Mini 相比，Phi-4-Mini 具有 200K 个标记的扩展词汇量，以更好地支持多语言应用，以及组查询注意力以更有效地生成长序列。Phi-4-Multimodal 是一种多模态模型，将文本、视觉和语音/音频输入模态集成到一个单一模型中。其新颖的模态扩展方法利用 LoRA 适配器和模态特定路由器，允许结合各种模态的多个推理模式而不会相互干扰。例如，它目前在 OpenASR 排行榜上排名第一，尽管语音/音频模态的 LoRA 组件仅有 4.6 亿参数。 Phi-4-Multimodal 支持涉及（视觉+语言）、（视觉+语音）和（语音/音频）输入的场景，在广泛的任务上优于更大的视觉-语言和语音-语言模型。此外，我们尝试进一步训练 Phi-4-Mini 以增强其推理能力。尽管其参数规模仅为 38 亿，这个实验版本在推理性能上与或显著优于 DeepSeek-R1-Distill-Qwen-7B 和 DeepSeek-R1-Distill-Llama-8B 等更大模型。

##   1 引言

Phi 模型系列\[AJA <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24, AAB <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]表明，经过精心策划和合成的数据使得小型语言模型（SLM）尽管参数数量显著较少，但仍能实现极具竞争力的性能。这些模型与更大规模的模型相比，取得了相当的结果。在 Phi 系列语言模型成功的基础上，我们扩展了其功能，使其能够处理额外的模态——如视觉和音频，取得了类似于 GPT \[HLG <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]、Claude \[Ant24\]和 Gemini \[TGL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]等私有模型的重大进展。

本报告介绍了 Phi-4-Multimodal，这是一个统一的跨模态 SLM，支持多种推理模式，结合了多种模态（例如，仅文本、文本+图像、语音/音频、语音+图像）在一个单一模型检查点内。Phi-4-Multimodal 采用了一种新颖的“LoRAs 混合”技术，通过整合特定模态的 LoRAs 来实现多模态功能，同时保持基础语言模型完全冻结。我们的发现表明，这种技术优于现有方法（例如，交叉注意力设计\[ADL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 22, AI23\]），并在多模态基准测试上实现了与完全微调模型相当的性能。此外，Phi-4-Multimodal 的设计高度可扩展，允许无缝集成新的 LoRAs 以支持额外的模态，而不会影响现有的模态。

我们的训练过程包括多个阶段，包括语言训练（包括预训练和后训练）以及将语言骨干扩展到视觉和语音/音频模态。对于语言模型，我们使用高质量、富含推理的文本数据训练 Phi-4-Mini。值得注意的是，我们包括精心挑选的高质量代码数据集，以增强在编码任务上的性能。一旦语言模型训练完成，我们冻结语言模型并实施我们的“LoRAs 混合”技术，进入多模态训练阶段。具体来说，我们在模态特定编码器和投影器旁边训练两个额外的 LoRA 模块，以实现与视觉相关的任务（例如，视觉-语言和视觉-语音）以及与语音/音频相关的任务（例如，语音-语言）。它们都包含预训练和后训练阶段，分别用于模态对齐和指令微调。

我们同时探索 Phi-4-Mini 的推理潜力，以创建一个既紧凑又强大的模型，在实质上与 DeepSeek-R1-Distill-Qwen-7B 和 DeepSeek-R1-Distill-Llama-8B 等更大规模的最先进推理系统相媲美。\[GYZ <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 25\]  

本模型的关键贡献如下。

1.  1\. 统一多模态支持：与现有方法\[Tea25b, CWW <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]采用不同模态的独立模型不同，Phi-4-Multimodal 被设计为一个统一的模型，能够高效地处理多种模态场景。通过利用 LoRAs 混合\[HSW <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 22\]，Phi-4-Multimodal 扩展了多模态能力，同时最小化了模态之间的干扰。这种方法实现了无缝集成，并确保涉及文本、图像和语音/音频的任务中的一致性能。
2.  2\. 对于其规模而言，语言模型表现出卓越的语言性能：这些语言模型在其规模类别中实现了自然语言理解和生成的最先进性能。它展示了卓越的推理和数学能力，非常适合复杂问题解决和基于知识的任务。
3.  3\. 优异的代码理解和生成能力：该语言模型在其尺寸类别内实现了代码相关任务的最新技术水平。该模型在代码合成、调试和文档生成等任务上表现出色，赋能开发者并助力软件工程工作流程。
4.  4\. 对于尺寸而言，模型在多模态任务方面表现出卓越的能力：对于其尺寸类别，该模型在多模态任务上实现了最先进的性能，展示了不同数据类型稳健的集成。这包括涉及结合图像、文本和语音模态的任务，实现多模态推理。
5.  5\. 优异的语音和音频性能：该模型在多语言语音识别和翻译任务上表现出色，并且是首个具有语音摘要能力的开源模型。
6.  6\. 增强推理能力：Phi-4-Mini 的推理优化版本在其尺寸类别模型中展现出卓越的推理能力。

##   2 模型架构

Phi-4-Mini 系列包括两个最先进的微型模型：一个语言模型（Phi-4-Mini）和一个集成语言、视觉和语音/音频模态的多模态模型（Phi-4-Multimodal）。所有 Phi-4-Mini 模型都使用分词器 o200k⁢\_⁢base\\text{o200k}\\\_\\text{base}o200k \_ base tiktoken <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">3</sup> 具有 200,064 个词汇量，旨在更有效地支持多语言和多模态输入输出。所有模型均基于仅解码器 Transformer \[VSP <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 17\]，并支持基于 LongRoPE \[DZZ <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24a\]的 128K 上下文长度。

### 2.1 语言模型架构

Phi-4-Mini 和 Phi-4-Multimodal 共享相同的语言模型骨干。Phi-4-Mini 由 32 个 Transformer 层组成，隐藏状态大小为 3,072，并具有绑定输入/输出嵌入，这显著降低了内存消耗，同时与 Phi-3.5 相比，提供了更广泛的词汇覆盖。每个 Transformer 块包括基于组查询注意力（GQA）\[ALTdJ <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]的注意力机制，该机制优化了键和值内存（KV 缓存）的使用，以支持长上下文生成。具体来说，该模型采用 24 个查询头和 8 个键/值头，将 KV 缓存消耗降低到标准大小的三分之一。此外，在 RoPE 配置\[SAL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]中，使用分数 RoPE 维度，确保 25%的注意力头维度保持位置无关。这种设计支持更平滑地处理较长的上下文。为了确定峰值学习率，我们遵循\[BBC <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]，其中 L⁢R∗⁢(D)\=B⁢D−0.32superscriptsuperscript0.32LR^{\*}(D)=BD^{-0.32}italic\_L italic\_R start\_POSTSUPERSCRIPT ∗ end\_POSTSUPERSCRIPT ( italic\_D ) = italic\_B italic\_D start\_POSTSUPERSCRIPT - 0.32 end\_POSTSUPERSCRIPT 是针对此特定模型调整的常数， BBitalic\_B 是总训练令牌数。我们通过在 DDitalic\_D 上调整来拟合 BBitalic\_B 。

### 2.2 多模态模型架构

为了将视觉作为输入模式，已经开发了众多视觉-语言模型，包括 LLava 系列\[LLWL24, LLL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24, LZG <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]，QWenVL 系列\[BBY <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23, WBT <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]，InternVL 系列\[CWT <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24, CWW <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24, CWC <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]，InternLM-XComposer 系列\[ZDW <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23, DZZ <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24b\]，Molmo \[DCL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]，以及 NVLM \[DLW <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]。同样，对于音频输入，值得注意的贡献包括 Qwen2-Audio \[CXY <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]，InternLM-XComposer2.5-Omnilive \[ZDC <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]，InternOmni，Mini-Omni \[ XW24\]，以及 GLM4-Voice \[ZDL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]。

然而，为了实现特定模态的功能，这些多模态模型通常需要微调基础语言模型，这往往降低了其原始的语言能力。因此，在不影响质量的前提下支持多样化的输入信号，需要部署多个模型——这对于资源受限的设备来说是一个特别具有挑战性的限制。为了解决这个问题，LLama-Vision \[DJP <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 采用了一种受 Flamingo \[ADL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 22\] 启发的策略，在保留核心语言模型的同时添加额外的交叉注意力层。然而，与完全微调的模型相比，这种方法在视觉-语言基准测试中的性能会降低。为了填补性能差距，NVLM \[DLW <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 进一步探索了一种混合框架，采用联合监督微调与高质量的文本 SFT 数据。然而，这种方法仅考察了有限的语言基准，并且没有解决 SFT 之后通常需要的额外训练阶段。

![Refer to caption](chrome-extension://pcmpcfapbekmbjjkdalcgopdkipoggdi/html/2503.01743v2/x1.png)

图 1：Phi-4-Multimodal 多模态架构概述

我们采用 LoRAs 混合设计来支持 Phi-4-Multimodal 架构的多种多模态使用场景。不同的 LoRAs 被训练来处理不同模态之间的交互。我们的 Phi-4-Multimodal 支持广泛的任务，包括单/多图像问答/摘要、视频问答/摘要、视觉-语音任务、语音问答/摘要/翻译/识别以及音频理解，同时保持原始语言模型性能。

####   2.2.1 模态细节

#####   视觉模态。

视觉模态通过图像编码器、用于对齐视觉和文本嵌入的项目仪以及 LoRA 适配器实现。视觉编码器基于 SigLIP-400M，使用 LLM2CLIP \[HWY <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]在大规模图像-文本对上进行微调，分辨率为 448×448448448448\\times 448448 × 448 。项目仪是一个 2 层 MLP，将视觉特征维度映射到文本嵌入维度。在语言解码器的所有线性层上添加额外的 LoRA，仅在监督微调（SFT）阶段部署。图像编码器和项目仪引入了 440M 模型参数，而视觉适配器 L⁢o⁢R⁢AVsubscriptLoRA\_{V}italic\_L italic\_o italic\_R italic\_A start\_POSTSUBSCRIPT italic\_V end\_POSTSUBSCRIPT 消耗了另外 370M 模型参数。

为了使模型能够有效地高效地处理具有不同分辨率的图像，我们提出了一种新的动态多裁剪策略。具体来说，对于目标图像，我们首先通过将原始尺寸除以裁剪尺寸来计算每边的裁剪数量，即 ⌈HC⌉×⌈WC⌉\\lceil\\frac{H}{C}\\rceil\\times\\lceil\\frac{W}{C}\\rceil⌈ divide start\_ARG italic\_H end\_ARG start\_ARG italic\_C end\_ARG ⌉ × ⌈ divide start\_ARG italic\_W end\_ARG start\_ARG italic\_C end\_ARG ⌉ ，其中 H,W,CH,W,Citalic\_H , italic\_W , italic\_C 分别是图像高度、宽度和裁剪尺寸。如果总裁剪数量在最大数量之内，即预训练阶段的 16161616 和在 SFT 阶段的 36363636 ，我们只需稍微调整图像大小，使其适应计算出的图像裁剪尺寸。否则，我们将利用 InternVL2 \[CWW <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]中提出的策略，通过匹配最佳长宽比来找到裁剪数量。与 InternVL2 相比，我们策略的关键优势是避免在寻找最接近的图像长宽比时将一个小图像（例如， 28×4482844828\\times 44828 × 448 ）调整到不合理的较大尺寸。

##### 语音和音频模态：

我们使用的语音/音频输入是 80 维对数梅尔滤波器组特征，帧率为 10 毫秒。为了启用 Phi-4-Multimodal 语音和音频功能，我们通过音频适配器将预训练的音频编码器和 Phi-4-Mini 连接起来。此外，在语言解码器上应用 LoRA，以提高语音/音频基准测试的性能，同时保留文本能力。引入的语音/音频模态模块包括：

-   音频编码器，由 3 个卷积层和 24 个 Conformer 块组成，每个 Conformer 块具有 1024 个注意力维度、1536 个前馈维度和 16 个注意力头。\[GQC <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 20\]卷积层贡献了 8 倍的子采样率，因此语言解码器的标记率为 80ms。
-   • 一种音频投影仪，它是一个 2 层 MLP，将 1024 维度的语音特征映射到 3072 维度的文本嵌入空间，类似于视觉投影仪。
-   • L⁢o⁢R⁢AAsubscriptLoRA\_{A}italic\_L italic\_o italic\_R italic\_A start\_POSTSUBSCRIPT italic\_A end\_POSTSUBSCRIPT 已应用于 Phi-4-Mini 中所有注意力层和 MLP 层，秩为 320。

音频编码器和投影仪引入了 460M 个参数，而 L⁢o⁢R⁢AAsubscriptLoRA\_{A}italic\_L italic\_o italic\_R italic\_A start\_POSTSUBSCRIPT italic\_A end\_POSTSUBSCRIPT 消耗了另外 460M 个参数。请注意，语音令牌率为 80ms，表示 1 分钟音频有 750 个令牌。

####   2.2.2 训练流程

多模态训练阶段包括视觉训练、语音/音频训练和视觉-语音联合训练。

#####   视觉训练。

多模态学习整体训练流程包括视觉训练、语音和音频训练以及联合视觉-音频训练。视觉训练遵循四个阶段：1）投影仪对齐阶段：最初，仅使用字幕数据训练投影仪，以对齐视觉和文本嵌入，同时保留视觉编码器的预训练表示。2）联合视觉训练阶段：接下来，投影仪和视觉编码器在完整的视觉预训练数据集上联合训练，以增强关键视觉能力，如 OCR 和密集理解。3）生成视觉-语言训练阶段：然后，在语言解码器上部署 LoRA，并使用精心挑选的单帧 SFT 数据与视觉编码器和投影仪一起训练，使模型具备对视觉-语言输入的生成能力。4）多帧训练阶段：最后，在冻结视觉编码器的情况下，使用多帧 SFT 数据进行训练，将上下文长度覆盖范围扩展到 64k，并实现多图像和时间理解。

##### 语音和音频训练。

使用 Phi-4-Mini 语言模型，我们进行语音和音频训练的两阶段范式，也称为语音/音频预训练和后训练。在预训练阶段，我们使用大规模自动语音识别（ASR）数据在语义空间中对齐音频编码器和 Phi-4-Mini。在此阶段，编码器和投影器以 4e-5 的学习率更新 50k 步，同时语言解码器保持冻结。我们使用基于注意力的编码器解码器（AED）ASR 模型的预训练编码器初始化音频编码器。

在预训练阶段之后，该模型只能执行语音识别任务。为了解锁 Phi-4-Multimodal 在多种语音和音频任务上的指令跟随能力，我们继续使用约 1 亿个精心挑选的语音和音频 SFT 样本（加权后）作为语音后训练阶段来训练模型。请参阅第 3.4.2 节以获取数据详情。在语音/音频后训练中，音频编码器被冻结。我们以 1e-4 的学习率更新音频投影器和 L⁢o⁢R⁢AAsubscriptLoRA\_{A}italic\_L italic\_o italic\_R italic\_A start\_POSTSUBSCRIPT italic\_A end\_POSTSUBSCRIPT ，再进行 50k 步的训练。我们在后训练阶段为不同任务考虑不同的最大音频长度。对于语音摘要任务，我们训练长达 30 分钟的音频（22.5k 个标记）。对于其他任务，训练中暴露的最大音频长度为 30 秒（375 个标记）。如果我们考虑语言解码器的 128k 上下文长度，理论上 Phi-4-Multimodal 可以支持最大 2.8 小时的音频作为即插即用推理。值得注意的是，我们尚未在如此长的音频数据上微调模型，它可能需要进一步的微调才能实际支持此类用例。

##### 视觉-语音联合训练。

视觉-语音联合训练在视觉后训练和语音后训练之后进行。我们冻结语言基础模型、音频编码器和音频投影器，同时微调视觉适配器 L⁢o⁢R⁢AVsubscriptLoRA\_{V}italic\_L italic\_o italic\_R italic\_A start\_POSTSUBSCRIPT italic\_V end\_POSTSUBSCRIPT 、视觉编码器和视觉投影器。在这个阶段，我们主要在视觉-语音 SFT 数据上训练模型，同时也包括语言和视觉后训练数据的混合，以维持相应的性能。

#####   推理训练

近期研究表明，仅需要少量高质量数据即可训练出鲁棒的推理模型，例如 LIMO \[YHX <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 25\] 和 S1K \[MYS <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 25\]。然而，我们提出了一个针对 SLM 的根本不同的训练范式：我们需要在大量的推理数据上进行预训练，以捕捉一般的推理链，然后对精心挑选的 SFT 或偏好数据进行仔细的微调。Phi-4-Mini 推理的持续训练分为三个不同的阶段。1) 首先，在 Phi-4-Mini 的基础上，模型在由前沿推理 LLMs 生成的约 600 亿个推理 CoT tokens 上进行预训练，之后采用拒绝采样来过滤掉错误的输出。这使得 Phi-4-Mini 的推理扩展能够学习这些模型产生的推理链。2) 在第二阶段，模型在约 20K 个高质量 CoT 样本的较小但精心挑选的数据集上进行微调，这些样本被选择以涵盖不同的领域和不同的难度级别。 3) 滚动 DPO：最后，在第三阶段，我们将过滤后的错误输出标记为“不偏好”，并将它们的修正版本标记为‘偏好’，为 DPO 训练编译一个包含 30 万个偏好样本的新数据集。

## 3 数据和训练细节

### 3.1 语言训练数据

####   3.1.1 预训练数据

与 Phi-3.5-Mini 相比，我们从几个关键方面提升了预训练数据的质量：

1.  1\. 更好的数据过滤：通过使用一个在更大、经过精心挑选的数据集上训练的增强质量分类器，该数据集包含更干净的正负样本，我们最终实现了在多种语言和不同方面（例如，有毒、晦涩、科学等）上的更好过滤质量，从而在整体上实现更全面和可控的过滤策略。
2.  2\. 更好的数学和编码数据：对于数学和编码数据，我们通过添加基于特定指令的数学和编码数据集来增强我们的原始数据。这种增强在数学、编码和推理方面取得了有效成果。
3.  3\. 更好的合成数据：我们将 Phi-4 合成数据\[AAB <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]以相同的处理和净化方式纳入此模型训练中。
4.  4\. 更好的数据混合：随着更好的分类器，我们通过消融实验重新调整了数据混合。特别是，我们增加了推理数据的比例。这为我们提升了模型质量。

使用这些技术，我们构建了 5000 亿个预训练数据语料库，其规模和质量均优于 Phi-3.5-Mini。

####   3.1.2 预训练数据

与 Phi-3.5-Mini 相比，Phi-4-Mini 包含了一个更大、更多样化的函数调用和摘要数据集。此外，我们合成大量指令遵循数据，以增强模型的指令遵循能力。在编码方面，我们纳入了大量的代码补全数据，包括需要模型在现有代码片段中间生成缺失代码的任务。这挑战了模型理解需求和现有上下文，从而带来了显著的性能提升。

#### 3.1.3 理解训练数据

我们生成大量来自大型推理模型的合成思维链（CoT）数据，涵盖多个领域和难度级别。在采样过程中，我们采用基于规则和基于模型的双重拒绝方法来丢弃错误生成的内容，并将其反馈用于重新采样。此外，我们将正确采样的答案标记为首选生成，错误答案标记为非首选，并创建 DPO 数据。这些数据仅用于实验推理模型，并未应用于官方发布的 Phi-4-Mini 检查点。

### 3.2 视觉-语言训练数据

Phi-4-Multimodal 模型的预训练阶段涉及丰富多样的数据集，包括交织的图文文档、图文对、图像定位数据、来自 PDF OCR 和真实图像的合成数据集，以及图表理解的合成数据集。在此阶段，模型的主要关注点是预测下一个标记，仅关注文本标记，而忽略与图像标记相关的任何损失。预训练过程涉及总计 0.5T 个标记，结合了视觉和文本元素。此外，最大图像分辨率为 1344x1344，因为大多数训练图像的尺寸都小于这个大小。对于监督微调（SFT），我们使用了文本 SFT 数据集、公开的多模态指令微调数据集以及我们开发的大规模内部多模态指令微调数据集的组合。这些数据集涵盖了多个领域和任务，包括通用自然图像理解、图表、表格和图表的理解和推理、PowerPoint 分析、OCR、多图像比较、视频摘要和模型安全性。 总体而言，多模态 SFT 数据大约包含 0.3T 个 token。

### 3.3 视觉-语音训练数据

对于视觉语音数据，Phi-4-Multimodal 模型在多种合成视觉语音数据集上进行了训练，涵盖单帧和多帧场景。具体来说，我们重用了一部分视觉语言 SFT 数据，并使用内部文本到语音（TTS）引擎将用户查询从文本转换为音频。这个子集经过精心挑选，以避免某些查询不适合语音读出的数据集。我们还通过使用内部 ASR 模型转录音频并计算原始文本与转录之间的词错误率（WER）来衡量合成语音的质量。我们的最终视觉语音数据通过基于 WER 的过滤生成，以确保质量。

### 3.4 语音和音频训练数据

语音/音频功能的训练数据可以分为两种类型：1）带有 ASR 转录的预训练数据，以提供语音和文本模态之间强大的对齐；2）后训练数据，以解锁 Phi-4-Multimodal 在语音/音频模态中的指令跟随能力。后训练数据涵盖了各种任务，包括自动语音识别（ASR）、自动语音翻译（AST）、语音问答（SQA）、口语查询问答（SQQA）、语音摘要（SSUM）和音频理解（AU）。

####   3.4.1 预训练数据

尽管如第 2.2 节所述，音频编码器是从一个经过良好训练的 ASR 模型初始化的，但语音和文本潜在空间不同。为了预训练适配器并减少语音和文本序列之间的模态差距，我们精心制作了一个包含约 200 万小时匿名内部语音-文本对的数据库，具有强/弱 ASR 监督，涵盖八种受支持的语言。.

####   3.4.2 预训练数据

遵循语言后训练范式，我们为语音/音频后训练精心挑选 SFT 数据，旨在通过语音/音频作为查询或上下文来解锁指令遵循能力。在语音后训练过程中，我们使用真实和合成的语音/音频数据，涵盖大多数语音和音频理解任务。所有 SFT 数据均格式化为：  

<|user|\><audio\>{task prompt}<|end|\><|assistant|\>{label}<|end|\><|user|><audio>\\{\\text{task prompt\\}}<|end|><|assistant|>\\{\\text{label}\\}<|end|>< | italic\_u italic\_s italic\_e italic\_r | > < italic\_a italic\_u italic\_d italic\_i italic\_o > { task prompt} < | italic\_e italic\_n italic\_d | > < | italic\_a italic\_s italic\_s italic\_i italic\_s italic\_t italic\_a italic\_n italic\_t | > { label } < | italic\_e italic\_n italic\_d | >  
任务提示用于用自然语言描述每个任务，对于 SQQA 任务则为空。

#####   语音识别数据。

语音识别训练数据包含约 20k 小时内部匿名数据和 20k 小时选定的跨八种语言的公共转录语音录音。加权语音识别训练数据贡献了 2800 万 SFT 示例。

#####   语音翻译数据。

AST 训练数据包含约 30K 小时的匿名内部和公共语音数据，包含双向翻译：从 7 种语言到英语和从英语到 7 种语言。这些数据包含来自机器翻译模型的监督和合成翻译。AST 数据以两种格式创建：直接 ST 和 ASR +以思维链（CoT）方式进行的翻译，为训练后贡献了 2800 万加权训练示例。

##### 语音和口语查询问答数据。

SQA 和 SQQA 训练数据包含来自真实语音和文本 SFT 数据的合成问答对。

-   • SQA 的合成问答对：为了实现 SQA 能力，我们重用 ASR 训练数据中的语音转写对，并提示语言模型为每个转写生成多个文本问答对。在训练过程中过滤掉低质量的问答对。
-   • 人工合成语音查询（音频）用于 SQQA：SQA 的任务是响应语音上下文加上文本查询。直接响应语音查询也是 Phi-4-Multimodal 的重要能力。因此，我们从语言后训练数据中采样，并使用我们内部的零样本 TTS 系统将文本查询转换为音频查询。
-   • 对于 SQQA 的合成语言模型响应：类似于\[FWL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]，我们通过提示语言模型以这些提示的 ASR 转录本来合成语音提示的响应。由于从 ASR 训练数据中采样了更多样化的语音查询，LM 响应数据可以提高 Phi-4-Multimodal 在真实场景中的 SQQA 鲁棒性。

总 SQA 和 SQAQA 数据贡献了 26M 个加权 SFT 示例。

##### 语音摘要数据。

摘要训练数据由匿名音频录音及其转录本组成。音频包括多说话者的对话式言语，涵盖各种主题。我们不是将音频分割成更短的片段，而是保持其完整长度，最长可达 30 分钟。为了为每个音频片段构建查询-摘要对，我们使用 GPT-4 根据转录本生成各种查询及其相应的摘要。对于每个音频片段，摘要查询针对对话的特定或一般方面，格式各异，包括长度（单词或句子数量）和结构（以项目符号、JSON 或电子邮件格式编写的摘要）。加权数据集为仅英语语音贡献了 1M 个 SFT 示例。

##### 音频理解数据。

音频理解数据贡献了大约 1700 万加权 SFT 示例，这些示例来源于公共数据。数据集以（音频，问题，答案）元组的形式创建，其中“音频”包含语音、音频和音乐输入。类似于\[GLL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]，问题和答案对是根据音频转录和/或元信息从 GPT4 生成的。  

此外，除了特定任务的数据外，我们还将在语音/音频后训练中包含音频安全数据。请参阅第 5.2 节以获取音频安全数据的详细信息。对于所有公开数据，我们使用我们的 Azure PII 检测器 <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">5</sup> 用于识别和处理个人身份信息（PII）。检测到个人身份信息的训练示例因隐私问题而被移除。

##   4 评估

###   4.1 多模态基准

  菲-4-多模态 5.6B   Phi-3.5-视觉 4.2B Qwen2.5-VL-3B   38 亿 InternVL2.5-4B   37 亿 Qwen2.5-VL-7B   83 亿 InternVL2.5-8B 8.1B   Gemini-2.0-闪   轻量级-私有-02-05   Gemini-2.0   闪   克劳德-3.5   \- 逊尼特 GPT-4o   \-迷你 GPT-4o \- MMMU   (值) YNZ <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23 55.1 43.0 47.0 48.3 51.8 50.6 54.1 64.7 55.8 52.1 61.7 MMMUPro (标准/视觉) YZN <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24 38.5 (39.7/37.3) 21.8 (25.5/18.0) 29.9 (31.8/28.0) 32.4 (36.1/28.6) 38.7 (39.5/37.9) 34.4 (39.0/29.8) 45.1 (45.8/44.3) 54.4 (57.1/51.6) 54.3 (56.5/52.1) 40.8 (44.0/37.7) 53.0 (55.3/50.7)   科学问答   (测试) LMX <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 22 97.5 91.3 79.4 96.2 87.7 97.3 85.0 88.3 81.2 84.0 88.2   数学视界   （测试迷你）LBX <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24 62.4 43.9 60.8 51.2 67.8 56.7 57.6 47.2 56.9 38.8 56.1   国际 GPS   （测试）LGJ <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 21 48.6 36.3 48.3 53.7 52.7 54.1 57.9 65.4 47.1 39.9 49.1 MMBench   (开发英语) LDZ <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24 86.7 81.9 84.3 86.8 87.8 88.2 85.0 90.0 86.7 83.8 89.0   教皇   （测试）\[LDZ <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\] 85.6 86.1 87.9 89.4 87.5 89.1 87.5 88.0 82.6 83.6 86.5 AI2D   (测试) KSK <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 16 82.3 78.1 78.4 80.0 82.6 83.0 77.6 82.1 70.6 75.2 83.8   图表问答   (测试) MLT <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 22 81.4 81.8 80.0 79.1 85.0 81.0 73.0 79.0 78.4 54.5 75.1   文本问答   (测试) 社交网络服务 <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 19 75.6 72.0 76.8 70.9 77.7 74.8 72.9 74.4 58.6 70.9 73.1   文档问答   （测试）MKJ21 93.2 69.3 93.9 91.6 95.7 93.0 91.2 92.1 95.2 84.2 90.9   信息问答   (测试) MBT <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 22 72.7 36.6 77.1 72.1 82.6 77.6 73.0 77.8 74.3 59.5 71.9   OCR Bench \[[LLH<sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup>24](https://arxiv.org/html/2503.01743v2#bib.bibx55)\] 84.4 63.8 82.2 71.6 87.7 74.8 75.7 81.0 77.0 77.1 77.7 BLINK   (测试) FHL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 25 61.3 57.0 48.1 51.2 55.3 52.5 59.3 64.0 56.9 51.9 62.4   视频 MME-16 帧   (测试) FDL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24 55.0 50.8 56.5 57.3 58.2 58.7 58.8 65.5 60.2 61.2 68.2   平均 72.0 60.9 68.7 68.8 73.3 71.1 70.2 74.3 69.1 63.8 72.4

表 1：公共视觉-语言基准测试的比较结果。所有报告的数字都是使用完全相同的内部管道生成的，以确保数字的可比性。这些数字可能与其他发布的数字有所不同，因为提示略有不同。 ∗\*∗ 注意，对于 MathVista 的 Gemini-2.0-Flash 数量，我们发现其低性能是因为其输出有时无法遵循输入指令和评估脚本定义的格式，导致评估脚本难以轻松解析答案。

  菲-4-多模态 5.6B InternOmni   87 亿   Gemini-2.0-闪   轻量级-私有-02-05   Gemini-2.0   闪 分享 GPT4o\_AI2D\[CWT <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 68.9 53.9 62.0 69.4 分享 GPT4o\_图表问答\[CWT <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 69.0 56.1 35.5 51.3 分享 GPT4o\_DocVQA\[CWT <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 87.3 79.9 76.0 80.3 分享 GPT4o\_InfoVQA\[CWT <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 63.7 60.3 59.4 63.6   平均 72.2 62.6 58.2 66.2

表 2：公共视觉-语音基准测试的比较结果。所有报告的数字均使用完全相同的内部流程生成，以确保数字的可比性。

####   4.1.1 视觉基准

我们在表 1 中报告了 Phi-4-Multimodal 在 13 个开源学术单图像视觉-语言基准、2 个开源多图像/视频视觉-语言基准和 4 个视觉-语音基准上的评估结果。此外，我们将 Phi-4-Multimodal 与多个最先进的开源模型进行了比较：我们之前的 Phi-3.5-Vision \[AJA <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]、Qwen2.5-VL-3B & 7B \[Tea25b\]、InternVL2.5-4B & 8B \[CWC <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]以及闭源的跨模态模型 Gemini \[TAB <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]、Claude-3.5 \[Ant24\] <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">6</sup> ，以及 GPT-4o \[HLG <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">7</sup> . 对于大多数基准测试，我们使用了与 Phi-3.5-Vision \[AJA <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]相同的内部评估流程，以确保与所有基线方法进行公平的比较。对于需要提交到评估服务器进行评估的基准测试（例如，DocVQA 和 InfoVQA），我们直接使用了先前论文中报告的基线方法的结果，并将我们自己的评估提交到服务器以获取 Phi-4-Multimodal 的结果。

对于单图像视觉-语言基准，评估涵盖了多个领域的推理和感知能力，包括但不限于科学、图表、OCR 和一般知识。对于多图像/视频视觉-语言基准，我们使用了 1 个多图像基准（BLINK \[FHL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]）和 1 个视频基准（VideoMME \[FDL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]）。在 VideoMME 的情况下，评估设置与 Phi-3.5-Vision \[AJA <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]中使用的相同，通过以确保均匀时间覆盖的速率采样帧，从每个视频中提取 16 帧。这些基准评估了多个图像/帧和文本的感知能力，涵盖了艺术和风格识别、法医检测和视频理解等场景。对于视觉-语音基准，我们从 InternOmni \[CWT <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]采用了四个现有基准，这些基准将文本提示转换为语音格式，以在四个视觉-语言基准上进行评估。由于 Claude 和 GPT-4o 端点不支持与图像一起的音频输入，因此我们在此不报告它们的数字。 对于 Gemini 模型，仅使用图像和语音输入进行提示将生成难以提取和评估的自由形式响应。因此，我们添加相应的文本指令，提示模型针对 ShareGPT4o 基准测试的相应选项 ABCD 或单个单词或短语进行回答。

从表 1 和表 2 的结果中，我们总结 Phi-4-Multimodal 的表现如下：

-   • 在视觉-语言基准测试中，Phi-4-Multimodal 相较于我们之前的模型 Phi-3.5-Vision \[AJA <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]取得了显著提升，并在总体上优于类似规模的基线模型。值得注意的是，在图表理解和科学推理任务中，Phi-4-Multimodal 甚至超越了某些类似的开源模型，如 Gemini 和 GPT-4o。我们在图 2 中展示了一个演示案例。
-   • 在视觉-语音基准测试中，Phi-4-Multimodal 在模型尺寸更大的 InternOmni 和 Gemini-2.0-Flash 上显著优于它们，例如，在 ShareGPT4o\_AI2D 和 ShareGPT4o\_ChartQA 基准测试中，Phi-4-Multimodal 的性能比 InternOmni 高出 10 多分。
-   与完全微调其基础语言模型（通常会导致纯语言基准测试上的性能下降）的其他开源视觉-语言模型不同，Phi-4-Multimodal 通过仅整合额外的可微调 LoRA 模块，将语言模型完全冻结。这种方法确保了纯文本输入的语言性能保持不变。虽然一些学术努力旨在在保持原始语言性能的同时实现多模态功能（例如，通过添加交叉注意力层\[AI23, DLW <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]），但这些技术通常会导致与完全微调的大型语言模型相比，在视觉-语言基准测试上的性能下降。我们提出的 LoRA 解决方案为社区提供了一个新颖的视角，在多模态基准测试上与完全微调的基线相比，保持了语言能力的同时实现了最小的性能损失。

![Refer to caption](chrome-extension://pcmpcfapbekmbjjkdalcgopdkipoggdi/html/2503.01743v2/extracted/6260032/figures/phio_vision_demo_case.png)

图 2：一个演示案例，展示了 Phi-4-Multimodal 在视觉-语言理解和推理方面的能力。

#### 4.1.2 语音和音频基准

我们评估了 Phi-4-Multimodal 在多种理解任务中的语音和音频能力。Phi-4-Multimodal 的性能与几个最先进的开源语音和音频理解模型进行了比较，包括 WhisperV3 \[RKX <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]、SeamlessM4T-v2 \[BCM <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]、Qwen2-audio \[CXY <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]。我们还包括了闭源多模态模型（GPT-4o \[HLG <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 和 Gemini \[TAB <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]）的性能进行比较 <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">8</sup> . 结果是通过在完全相同的测试数据版本上评估获得的，无需进一步说明。在推理过程中，我们在每个生成步骤中采样每个生成步骤的最高 1 个标记。

主要在语音基准测试上的结果展示在表 3 中。我们总结了 Phi-4-Multimodal 的表现如下：

-   • Phi-4-Multimodal 在 ASR 和 AST 性能上非常强大，在 CommonVoice \[ABD <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 20\]、FLEURS \[CMK <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]、OpenASR \[SMK <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]和 CoVoST2 \[ WWGP21\]测试集上超过了专家 ASR 模型 WhisperV3 和专家 AST 模型 SeamlessM4T-large-v2。
-   • Phi-4-Multimodal 在 WER 方面相对于 Huggingface OpenASR 排行榜上的最佳模型相对提升了 5.5%。
-   • Phi-4-Multimodal 是首个具有语音摘要能力的开源模型。在遵循性和低幻觉方面，其摘要质量接近 GPT-4o。
-   • Phi-4-Multimodal 是最小的开源多模态 LLM，其性能优于开源的 Qwen2-audio \[CXY <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]，体积缩小了 2 倍。

我们应该注意，在表 3 中，Phi-4-Multimodal 针对语音和音频理解任务进行了优化，而 Gemini 和 GPT-4o 可能更偏向于聊天体验。这可能是 Phi-4-Multimodal 在 ASR 和 AST 任务上优于 Gemini-2.0-Flash 和 GPT-4o，但在 SQQA 任务上落后的原因。以下我们描述了每个任务的基准和评估细节。

表 3：语音基准测试的主要结果。所有结果均为零样本评估所得，除 AST 任务上的额外 CoT 评估外，其中 CoT 指的是带有转录和翻译的生成中的思维链解码。MT-Bench 结果是两轮 SQA 对话的平均分数。SSUM 评估包括整体数字，涵盖遵循和幻觉分数。表中的分数由 GPT-4-0613 判断。N/A 表示模型没有这种能力。

<table id="S4.T3.7" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tbody data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tr id="S4.T3.7.8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.7.8.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S4.T3.7.8.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S4.T3.7.8.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S4.T3.7.8.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.8.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">菲-4-多模态</span></span></span></span></td><td id="S4.T3.7.8.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.8.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">轻语 V3</span></span></span></span></td><td id="S4.T3.7.8.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.8.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">无缝 M4T-V2</span></span></span></span></td><td id="S4.T3.7.8.7" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.8.7.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">Qwen2 音频</span></span></span></span></td><td id="S4.T3.7.8.8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.8.8.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">Gemini</span></span></span></span></td><td id="S4.T3.7.8.9" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.8.9.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">GPT-4o</span></td></tr><tr id="S4.T3.7.9" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.7.9.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.9.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">任务</span></span></span></span></td><td id="S4.T3.7.9.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.9.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">指标</span></span></span></span></td><td id="S4.T3.7.9.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.9.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">数据集</span></span></span></span></td><td id="S4.T3.7.9.4"><span id="S4.T3.7.9.4.1">5.6B</span></td><td id="S4.T3.7.9.5"><span id="S4.T3.7.9.5.1">1.5B</span></td><td id="S4.T3.7.9.6"><span id="S4.T3.7.9.6.1">2.3B</span></td><td id="S4.T3.7.9.7"><span id="S4.T3.7.9.7.1">8B</span></td><td id="S4.T3.7.9.8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.9.8.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">2.0-闪存</span></span></span></span></td><td id="S4.T3.7.9.9"><span id="S4.T3.7.9.9.1">-</span></td></tr><tr id="S4.T3.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.1.1.2" rowspan="3"><span id="S4.T3.1.1.2.1">ASR</span></td><td id="S4.T3.1.1.1" rowspan="3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.1.1.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">WER <math alttext="\downarrow" display="inline" id="S4.T3.1.1.1.1.m1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><semantics id="S4.T3.1.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T3.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.1.m1.1d">↓</annotation></semantics></math></span></td><td id="S4.T3.1.1.3"><span id="S4.T3.1.1.3.1">CV15</span></td><td id="S4.T3.1.1.4"><span id="S4.T3.1.1.4.1">6.80</span></td><td id="S4.T3.1.1.5"><span id="S4.T3.1.1.5.1">8.13</span></td><td id="S4.T3.1.1.6"><span id="S4.T3.1.1.6.1">8.46</span></td><td id="S4.T3.1.1.7"><span id="S4.T3.1.1.7.1">8.55</span></td><td id="S4.T3.1.1.8"><span id="S4.T3.1.1.8.1">9.29</span></td><td id="S4.T3.1.1.9"><span id="S4.T3.1.1.9.1">18.14</span></td></tr><tr id="S4.T3.7.10" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.7.10.1"><span id="S4.T3.7.10.1.1">FLEURS</span></td><td id="S4.T3.7.10.2"><span id="S4.T3.7.10.2.1">4.00</span></td><td id="S4.T3.7.10.3"><span id="S4.T3.7.10.3.1">4.58</span></td><td id="S4.T3.7.10.4"><span id="S4.T3.7.10.4.1">7.34</span></td><td id="S4.T3.7.10.5"><span id="S4.T3.7.10.5.1">8.28</span></td><td id="S4.T3.7.10.6"><span id="S4.T3.7.10.6.1">4.73</span></td><td id="S4.T3.7.10.7"><span id="S4.T3.7.10.7.1">5.42</span></td></tr><tr id="S4.T3.7.11" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.7.11.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.11.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">OpenASR</span></td><td id="S4.T3.7.11.2"><span id="S4.T3.7.11.2.1">6.14</span></td><td id="S4.T3.7.11.3"><span id="S4.T3.7.11.3.1">7.44</span></td><td id="S4.T3.7.11.4"><span id="S4.T3.7.11.4.1">20.70</span></td><td id="S4.T3.7.11.5"><span id="S4.T3.7.11.5.1">7.43</span></td><td id="S4.T3.7.11.6"><span id="S4.T3.7.11.6.1">8.56</span></td><td id="S4.T3.7.11.7"><span id="S4.T3.7.11.7.1">15.76</span></td></tr><tr id="S4.T3.2.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.2.2.2" rowspan="5"><span id="S4.T3.2.2.2.1">AST</span></td><td id="S4.T3.2.2.1" rowspan="4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.2.2.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">BLEU <math alttext="\uparrow" display="inline" id="S4.T3.2.2.1.1.m1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><semantics id="S4.T3.2.2.1.1.m1.1a"><mo id="S4.T3.2.2.1.1.m1.1.1" stretchy="false" xref="S4.T3.2.2.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.1.1.m1.1b"><ci id="S4.T3.2.2.1.1.m1.1.1.cmml" xref="S4.T3.2.2.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.1.1.m1.1d">↑</annotation></semantics></math></span></td><td id="S4.T3.2.2.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.2.2.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">推理类型</span></span></span></span></td><td id="S4.T3.2.2.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.2.2.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">（零样本，CoT）</span></span></span></span></td><td id="S4.T3.2.2.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.2.2.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">零样本</span></span></span></span></td><td id="S4.T3.2.2.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.2.2.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">零样本</span></span></span></span></td><td id="S4.T3.2.2.7" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.2.2.7.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">零样本</span></span></span></span></td><td id="S4.T3.2.2.8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.2.2.8.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">零样本</span></span></span></span></td><td id="S4.T3.2.2.9" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.2.2.9.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">零样本</span></span></span></span></td></tr><tr id="S4.T3.7.12" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.7.12.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.12.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">CoVoST2 X-EN</span></td><td id="S4.T3.7.12.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.12.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">(39.33, </span><span id="S4.T3.7.12.2.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">40.76</span><span id="S4.T3.7.12.2.3">)</span></td><td id="S4.T3.7.12.3"><span id="S4.T3.7.12.3.1">33.26</span></td><td id="S4.T3.7.12.4"><span id="S4.T3.7.12.4.1">37.54</span></td><td id="S4.T3.7.12.5"><span id="S4.T3.7.12.5.1">34.80</span></td><td id="S4.T3.7.12.6"><span id="S4.T3.7.12.6.1">36.62</span></td><td id="S4.T3.7.12.7"><span id="S4.T3.7.12.7.1">37.09</span></td></tr><tr id="S4.T3.7.13" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.7.13.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.13.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">CoVoST2 英-中</span></span></span></span></td><td id="S4.T3.7.13.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.13.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">(37.82, </span><span id="S4.T3.7.13.2.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">38.73</span><span id="S4.T3.7.13.2.3">)</span></td><td id="S4.T3.7.13.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.13.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.7.13.4"><span id="S4.T3.7.13.4.1">32.84</span></td><td id="S4.T3.7.13.5"><span id="S4.T3.7.13.5.1">34.04</span></td><td id="S4.T3.7.13.6"><span id="S4.T3.7.13.6.1">35.93</span></td><td id="S4.T3.7.13.7"><span id="S4.T3.7.13.7.1">37.19</span></td></tr><tr id="S4.T3.7.14" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.7.14.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.14.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">FLEURS X-EN</span></td><td id="S4.T3.7.14.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.14.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">(29.86, 32.35)</span></td><td id="S4.T3.7.14.3"><span id="S4.T3.7.14.3.1">25.76</span></td><td id="S4.T3.7.14.4"><span id="S4.T3.7.14.4.1">28.87</span></td><td id="S4.T3.7.14.5"><span id="S4.T3.7.14.5.1">23.72</span></td><td id="S4.T3.7.14.6"><span id="S4.T3.7.14.6.1">30.69</span></td><td id="S4.T3.7.14.7"><span id="S4.T3.7.14.7.1">32.61</span></td></tr><tr id="S4.T3.7.15" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.7.15.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S4.T3.7.15.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.15.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">鲜花在-X</span></span></span></span></td><td id="S4.T3.7.15.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.15.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">(32.15, 33.56)</span></td><td id="S4.T3.7.15.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.15.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.7.15.5"><span id="S4.T3.7.15.5.1">30.44</span></td><td id="S4.T3.7.15.6"><span id="S4.T3.7.15.6.1">23.24</span></td><td id="S4.T3.7.15.7"><span id="S4.T3.7.15.7.1">37.33</span></td><td id="S4.T3.7.15.8"><span id="S4.T3.7.15.8.1">36.78</span></td></tr><tr id="S4.T3.3.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.3.3.2" rowspan="2"><span id="S4.T3.3.3.2.1">SQQA</span></td><td id="S4.T3.3.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">评分 1-10 <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T3.3.3.1.m1.1" display="inline" alttext="\uparrow"><semantics id="S4.T3.3.3.1.m1.1a"><mo stretchy="false" mathsize="50%" id="S4.T3.3.3.1.m1.1.1">↑</mo><annotation-xml id="S4.T3.3.3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T3.3.3.1.m1.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S4.T3.3.3.1.m1.1d" encoding="application/x-llamapun">↑</annotation></semantics></math></span></span></span></td><td id="S4.T3.3.3.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.3.3.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">MT-Bench</span></td><td id="S4.T3.3.3.4"><span id="S4.T3.3.3.4.1">7.05</span></td><td id="S4.T3.3.3.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.3.3.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.3.3.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.3.3.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.3.3.7"><span id="S4.T3.3.3.7.1">4.92</span></td><td id="S4.T3.3.3.8"><span id="S4.T3.3.3.8.1">8.07</span></td><td id="S4.T3.3.3.9"><span id="S4.T3.3.3.9.1">8.11</span></td></tr><tr id="S4.T3.4.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.4.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span id="S4.T3.4.4.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">ACC </span><math alttext="\uparrow" display="inline" id="S4.T3.4.4.1.m1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><semantics id="S4.T3.4.4.1.m1.1a"><mo id="S4.T3.4.4.1.m1.1.1" mathsize="50%" stretchy="false" xref="S4.T3.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.1.m1.1b"><ci id="S4.T3.4.4.1.m1.1.1.cmml" xref="S4.T3.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.4.1.m1.1d">↑</annotation></semantics></math></td><td id="S4.T3.4.4.2"><span id="S4.T3.4.4.2.1">MMMLU</span></td><td id="S4.T3.4.4.3"><span id="S4.T3.4.4.3.1">38.50</span></td><td id="S4.T3.4.4.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.4.4.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.4.4.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.4.4.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.4.4.6"><span id="S4.T3.4.4.6.1">15.53</span></td><td id="S4.T3.4.4.7"><span id="S4.T3.4.4.7.1">72.31</span></td><td id="S4.T3.4.4.8"><span id="S4.T3.4.4.8.1">72.56</span></td></tr><tr id="S4.T3.5.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.5.5.2" rowspan="2"><span id="S4.T3.5.5.2.1">SSUM</span></td><td id="S4.T3.5.5.1" rowspan="2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.5.5.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">得分 1-7 <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T3.5.5.1.1.m1.1" display="inline" alttext="\uparrow"><semantics id="S4.T3.5.5.1.1.m1.1a"><mo stretchy="false" id="S4.T3.5.5.1.1.m1.1.1">↑</mo><annotation-xml id="S4.T3.5.5.1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T3.5.5.1.1.m1.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S4.T3.5.5.1.1.m1.1d" encoding="application/x-llamapun">↑</annotation></semantics></math></span></span></span></span></td><td id="S4.T3.5.5.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.5.5.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">金色 3</span></span></span></span></td><td id="S4.T3.5.5.4"><span id="S4.T3.5.5.4.1">6.28</span></td><td id="S4.T3.5.5.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.5.5.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.5.5.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.5.5.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.5.5.7"><span id="S4.T3.5.5.7.1">2.25</span></td><td id="S4.T3.5.5.8"><span id="S4.T3.5.5.8.1">6.29</span></td><td id="S4.T3.5.5.9"><span id="S4.T3.5.5.9.1">6.76</span></td></tr><tr id="S4.T3.7.16" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.7.16.1"><span id="S4.T3.7.16.1.1">AMI</span></td><td id="S4.T3.7.16.2"><span id="S4.T3.7.16.2.1">6.29</span></td><td id="S4.T3.7.16.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.16.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.7.16.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.16.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.7.16.5"><span id="S4.T3.7.16.5.1">1.34</span></td><td id="S4.T3.7.16.6"><span id="S4.T3.7.16.6.1">5.97</span></td><td id="S4.T3.7.16.7"><span id="S4.T3.7.16.7.1">6.53</span></td></tr><tr id="S4.T3.6.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.6.6.2" rowspan="2"><span id="S4.T3.6.6.2.1">AU</span></td><td id="S4.T3.6.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">评分 1-10 <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T3.6.6.1.m1.1" display="inline" alttext="\uparrow"><semantics id="S4.T3.6.6.1.m1.1a"><mo stretchy="false" mathsize="50%" id="S4.T3.6.6.1.m1.1.1">↑</mo><annotation-xml id="S4.T3.6.6.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T3.6.6.1.m1.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S4.T3.6.6.1.m1.1d" encoding="application/x-llamapun">↑</annotation></semantics></math></span></span></span></td><td id="S4.T3.6.6.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.6.6.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">AirBench-聊天</span></span></span></span></td><td id="S4.T3.6.6.4"><span id="S4.T3.6.6.4.1">6.98</span></td><td id="S4.T3.6.6.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.6.6.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.6.6.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.6.6.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.6.6.7"><span id="S4.T3.6.6.7.1">6.93</span></td><td id="S4.T3.6.6.8"><span id="S4.T3.6.6.8.1">6.68</span></td><td id="S4.T3.6.6.9"><span id="S4.T3.6.6.9.1">6.54</span></td></tr><tr id="S4.T3.7.7" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T3.7.7.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span id="S4.T3.7.7.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">ACC </span><math alttext="\uparrow" display="inline" id="S4.T3.7.7.1.m1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><semantics id="S4.T3.7.7.1.m1.1a"><mo id="S4.T3.7.7.1.m1.1.1" mathsize="50%" stretchy="false" xref="S4.T3.7.7.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.1.m1.1b"><ci id="S4.T3.7.7.1.m1.1.1.cmml" xref="S4.T3.7.7.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.7.7.1.m1.1d">↑</annotation></semantics></math></td><td id="S4.T3.7.7.2"><span id="S4.T3.7.7.2.1">MMAU</span></td><td id="S4.T3.7.7.3"><span id="S4.T3.7.7.3.1">55.56</span></td><td id="S4.T3.7.7.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.7.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.7.7.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T3.7.7.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T3.7.7.6"><span id="S4.T3.7.7.6.1">52.50</span></td><td id="S4.T3.7.7.7"><span id="S4.T3.7.7.7.1">61.23</span></td><td id="S4.T3.7.7.8"><span id="S4.T3.7.7.8.1">53.29</span></td></tr></tbody></table>

表 4：ASR 基准测试的详细结果。我们计算了 JA 和 ZH 的 CER（ ↓\\downarrow↓ ），以及其他语言的 WER（ ↓\\downarrow↓ ）。nvidia/canary-1B 模型是目前 Huggingface OpenASR 排行榜上表现最好的模型。canary 和 WhisperV3 的结果来自官方报告，其他结果是通过在同一测试数据版本上的内部评估获得的。

<table id="S4.T4.7" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tbody data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tr id="S4.T4.7.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S4.T4.7.1.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S4.T4.7.1.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.1.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">菲-4-多模态</span></span></span></span></td><td id="S4.T4.7.1.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.1.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">nvidia/canary</span></td><td id="S4.T4.7.1.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.1.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">轻语 V3</span></span></span></span></td><td id="S4.T4.7.1.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.1.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">无缝 M4T-V2</span></span></span></span></td><td id="S4.T4.7.1.7" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.1.7.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">Qwen2 音频</span></span></span></span></td><td id="S4.T4.7.1.8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.1.8.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">Gemini</span></span></span></span></td><td id="S4.T4.7.1.9" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.1.9.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">GPT-4o</span></td></tr><tr id="S4.T4.7.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.2.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">数据集</span></span></span></span></td><td id="S4.T4.7.2.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.2.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">子类别</span></span></span></span></td><td id="S4.T4.7.2.3"><span id="S4.T4.7.2.3.1">5.6B</span></td><td id="S4.T4.7.2.4"><span id="S4.T4.7.2.4.1">1B</span></td><td id="S4.T4.7.2.5"><span id="S4.T4.7.2.5.1">1.5B</span></td><td id="S4.T4.7.2.6"><span id="S4.T4.7.2.6.1">2.3B</span></td><td id="S4.T4.7.2.7"><span id="S4.T4.7.2.7.1">8B</span></td><td id="S4.T4.7.2.8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.2.8.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">2.0-闪存</span></span></span></span></td><td id="S4.T4.7.2.9"><span id="S4.T4.7.2.9.1">-</span></td></tr><tr id="S4.T4.7.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.3.1" rowspan="9"><span id="S4.T4.7.3.1.1">CV15</span></td><td id="S4.T4.7.3.2"><span id="S4.T4.7.3.2.1">EN</span></td><td id="S4.T4.7.3.3"><span id="S4.T4.7.3.3.1">7.61</span></td><td id="S4.T4.7.3.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.3.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.3.5"><span id="S4.T4.7.3.5.1">9.30</span></td><td id="S4.T4.7.3.6"><span id="S4.T4.7.3.6.1">7.65</span></td><td id="S4.T4.7.3.7"><span id="S4.T4.7.3.7.1">8.68</span></td><td id="S4.T4.7.3.8"><span id="S4.T4.7.3.8.1">11.21</span></td><td id="S4.T4.7.3.9"><span id="S4.T4.7.3.9.1">21.48</span></td></tr><tr id="S4.T4.7.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.4.1"><span id="S4.T4.7.4.1.1">DE</span></td><td id="S4.T4.7.4.2"><span id="S4.T4.7.4.2.1">5.13</span></td><td id="S4.T4.7.4.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.4.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.4.4"><span id="S4.T4.7.4.4.1">5.70</span></td><td id="S4.T4.7.4.5"><span id="S4.T4.7.4.5.1">6.43</span></td><td id="S4.T4.7.4.6"><span id="S4.T4.7.4.6.1">7.61</span></td><td id="S4.T4.7.4.7"><span id="S4.T4.7.4.7.1">6.2</span></td><td id="S4.T4.7.4.8"><span id="S4.T4.7.4.8.1">10.91</span></td></tr><tr id="S4.T4.7.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.5.1"><span id="S4.T4.7.5.1.1">ES</span></td><td id="S4.T4.7.5.2"><span id="S4.T4.7.5.2.1">4.47</span></td><td id="S4.T4.7.5.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.5.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.5.4"><span id="S4.T4.7.5.4.1">4.70</span></td><td id="S4.T4.7.5.5"><span id="S4.T4.7.5.5.1">5.42</span></td><td id="S4.T4.7.5.6"><span id="S4.T4.7.5.6.1">5.71</span></td><td id="S4.T4.7.5.7"><span id="S4.T4.7.5.7.1">4.81</span></td><td id="S4.T4.7.5.8"><span id="S4.T4.7.5.8.1">11.24</span></td></tr><tr id="S4.T4.7.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.6.1"><span id="S4.T4.7.6.1.1">FR</span></td><td id="S4.T4.7.6.2"><span id="S4.T4.7.6.2.1">8.08</span></td><td id="S4.T4.7.6.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.6.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.6.4"><span id="S4.T4.7.6.4.1">10.80</span></td><td id="S4.T4.7.6.5"><span id="S4.T4.7.6.5.1">9.75</span></td><td id="S4.T4.7.6.6"><span id="S4.T4.7.6.6.1">9.57</span></td><td id="S4.T4.7.6.7"><span id="S4.T4.7.6.7.1">10.45</span></td><td id="S4.T4.7.6.8"><span id="S4.T4.7.6.8.1">17.63</span></td></tr><tr id="S4.T4.7.7" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.7.1"><span id="S4.T4.7.7.1.1">IT</span></td><td id="S4.T4.7.7.2"><span id="S4.T4.7.7.2.1">3.78</span></td><td id="S4.T4.7.7.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.7.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.7.4"><span id="S4.T4.7.7.4.1">5.50</span></td><td id="S4.T4.7.7.5"><span id="S4.T4.7.7.5.1">5.50</span></td><td id="S4.T4.7.7.6"><span id="S4.T4.7.7.6.1">6.78</span></td><td id="S4.T4.7.7.7"><span id="S4.T4.7.7.7.1">4.88</span></td><td id="S4.T4.7.7.8"><span id="S4.T4.7.7.8.1">13.84</span></td></tr><tr id="S4.T4.7.8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.8.1"><span id="S4.T4.7.8.1.1">JA</span></td><td id="S4.T4.7.8.2"><span id="S4.T4.7.8.2.1">10.98</span></td><td id="S4.T4.7.8.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.8.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.8.4"><span id="S4.T4.7.8.4.1">10.30</span></td><td id="S4.T4.7.8.5"><span id="S4.T4.7.8.5.1">12.37</span></td><td id="S4.T4.7.8.6"><span id="S4.T4.7.8.6.1">13.55</span></td><td id="S4.T4.7.8.7"><span id="S4.T4.7.8.7.1">13.46</span></td><td id="S4.T4.7.8.8"><span id="S4.T4.7.8.8.1">19.36</span></td></tr><tr id="S4.T4.7.9" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.9.1"><span id="S4.T4.7.9.1.1">PT</span></td><td id="S4.T4.7.9.2"><span id="S4.T4.7.9.2.1">6.97</span></td><td id="S4.T4.7.9.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.9.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.9.4"><span id="S4.T4.7.9.4.1">5.90</span></td><td id="S4.T4.7.9.5"><span id="S4.T4.7.9.5.1">9.19</span></td><td id="S4.T4.7.9.6"><span id="S4.T4.7.9.6.1">10.03</span></td><td id="S4.T4.7.9.7"><span id="S4.T4.7.9.7.1">7.4</span></td><td id="S4.T4.7.9.8"><span id="S4.T4.7.9.8.1">23.07</span></td></tr><tr id="S4.T4.7.10" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.10.1"><span id="S4.T4.7.10.1.1">ZH</span></td><td id="S4.T4.7.10.2"><span id="S4.T4.7.10.2.1">7.35</span></td><td id="S4.T4.7.10.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.10.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.10.4"><span id="S4.T4.7.10.4.1">12.80</span></td><td id="S4.T4.7.10.5"><span id="S4.T4.7.10.5.1">11.36</span></td><td id="S4.T4.7.10.6"><span id="S4.T4.7.10.6.1">6.47</span></td><td id="S4.T4.7.10.7"><span id="S4.T4.7.10.7.1">15.87</span></td><td id="S4.T4.7.10.8"><span id="S4.T4.7.10.8.1">27.55</span></td></tr><tr id="S4.T4.7.11" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.11.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.11.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">平均</span></span></span></span></td><td id="S4.T4.7.11.2"><span id="S4.T4.7.11.2.1">6.80</span></td><td id="S4.T4.7.11.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.11.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.11.4"><span id="S4.T4.7.11.4.1">8.13</span></td><td id="S4.T4.7.11.5"><span id="S4.T4.7.11.5.1">8.46</span></td><td id="S4.T4.7.11.6"><span id="S4.T4.7.11.6.1">8.55</span></td><td id="S4.T4.7.11.7"><span id="S4.T4.7.11.7.1">9.29</span></td><td id="S4.T4.7.11.8"><span id="S4.T4.7.11.8.1">18.14</span></td></tr><tr id="S4.T4.7.12" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.12.1" rowspan="9"><span id="S4.T4.7.12.1.1">FLEURS</span></td><td id="S4.T4.7.12.2"><span id="S4.T4.7.12.2.1">EN</span></td><td id="S4.T4.7.12.3"><span id="S4.T4.7.12.3.1">3.38</span></td><td id="S4.T4.7.12.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.12.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.12.5"><span id="S4.T4.7.12.5.1">4.10</span></td><td id="S4.T4.7.12.6"><span id="S4.T4.7.12.6.1">6.54</span></td><td id="S4.T4.7.12.7"><span id="S4.T4.7.12.7.1">5.27</span></td><td id="S4.T4.7.12.8"><span id="S4.T4.7.12.8.1">3.96</span></td><td id="S4.T4.7.12.9"><span id="S4.T4.7.12.9.1">6.52</span></td></tr><tr id="S4.T4.7.13" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.13.1"><span id="S4.T4.7.13.1.1">DE</span></td><td id="S4.T4.7.13.2"><span id="S4.T4.7.13.2.1">3.96</span></td><td id="S4.T4.7.13.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.13.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.13.4"><span id="S4.T4.7.13.4.1">4.90</span></td><td id="S4.T4.7.13.5"><span id="S4.T4.7.13.5.1">6.95</span></td><td id="S4.T4.7.13.6"><span id="S4.T4.7.13.6.1">8.77</span></td><td id="S4.T4.7.13.7"><span id="S4.T4.7.13.7.1">4.06</span></td><td id="S4.T4.7.13.8"><span id="S4.T4.7.13.8.1">4.17</span></td></tr><tr id="S4.T4.7.14" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.14.1"><span id="S4.T4.7.14.1.1">ES</span></td><td id="S4.T4.7.14.2"><span id="S4.T4.7.14.2.1">3.02</span></td><td id="S4.T4.7.14.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.14.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.14.4"><span id="S4.T4.7.14.4.1">2.80</span></td><td id="S4.T4.7.14.5"><span id="S4.T4.7.14.5.1">5.39</span></td><td id="S4.T4.7.14.6"><span id="S4.T4.7.14.6.1">6.90</span></td><td id="S4.T4.7.14.7"><span id="S4.T4.7.14.7.1">2.61</span></td><td id="S4.T4.7.14.8"><span id="S4.T4.7.14.8.1">3.69</span></td></tr><tr id="S4.T4.7.15" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.15.1"><span id="S4.T4.7.15.1.1">FR</span></td><td id="S4.T4.7.15.2"><span id="S4.T4.7.15.2.1">4.35</span></td><td id="S4.T4.7.15.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.15.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.15.4"><span id="S4.T4.7.15.4.1">5.30</span></td><td id="S4.T4.7.15.5"><span id="S4.T4.7.15.5.1">7.40</span></td><td id="S4.T4.7.15.6"><span id="S4.T4.7.15.6.1">9.00</span></td><td id="S4.T4.7.15.7"><span id="S4.T4.7.15.7.1">5.06</span></td><td id="S4.T4.7.15.8"><span id="S4.T4.7.15.8.1">6.42</span></td></tr><tr id="S4.T4.7.16" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.16.1"><span id="S4.T4.7.16.1.1">IT</span></td><td id="S4.T4.7.16.2"><span id="S4.T4.7.16.2.1">1.98</span></td><td id="S4.T4.7.16.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.16.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.16.4"><span id="S4.T4.7.16.4.1">3.00</span></td><td id="S4.T4.7.16.5"><span id="S4.T4.7.16.5.1">4.70</span></td><td id="S4.T4.7.16.6"><span id="S4.T4.7.16.6.1">5.78</span></td><td id="S4.T4.7.16.7"><span id="S4.T4.7.16.7.1">1.86</span></td><td id="S4.T4.7.16.8"><span id="S4.T4.7.16.8.1">3.28</span></td></tr><tr id="S4.T4.7.17" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.17.1"><span id="S4.T4.7.17.1.1">JA</span></td><td id="S4.T4.7.17.2"><span id="S4.T4.7.17.2.1">4.50</span></td><td id="S4.T4.7.17.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.17.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.17.4"><span id="S4.T4.7.17.4.1">4.80</span></td><td id="S4.T4.7.17.5"><span id="S4.T4.7.17.5.1">11.47</span></td><td id="S4.T4.7.17.6"><span id="S4.T4.7.17.6.1">12.68</span></td><td id="S4.T4.7.17.7"><span id="S4.T4.7.17.7.1">4.94</span></td><td id="S4.T4.7.17.8"><span id="S4.T4.7.17.8.1">5.18</span></td></tr><tr id="S4.T4.7.18" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.18.1"><span id="S4.T4.7.18.1.1">PT</span></td><td id="S4.T4.7.18.2"><span id="S4.T4.7.18.2.1">3.98</span></td><td id="S4.T4.7.18.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.18.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.18.4"><span id="S4.T4.7.18.4.1">4.00</span></td><td id="S4.T4.7.18.5"><span id="S4.T4.7.18.5.1">7.67</span></td><td id="S4.T4.7.18.6"><span id="S4.T4.7.18.6.1">10.59</span></td><td id="S4.T4.7.18.7"><span id="S4.T4.7.18.7.1">3.57</span></td><td id="S4.T4.7.18.8"><span id="S4.T4.7.18.8.1">6.33</span></td></tr><tr id="S4.T4.7.19" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.19.1"><span id="S4.T4.7.19.1.1">ZH</span></td><td id="S4.T4.7.19.2"><span id="S4.T4.7.19.2.1">6.83</span></td><td id="S4.T4.7.19.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.19.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.19.4"><span id="S4.T4.7.19.4.1">7.70</span></td><td id="S4.T4.7.19.5"><span id="S4.T4.7.19.5.1">8.6</span></td><td id="S4.T4.7.19.6"><span id="S4.T4.7.19.6.1">7.21</span></td><td id="S4.T4.7.19.7"><span id="S4.T4.7.19.7.1">11.74</span></td><td id="S4.T4.7.19.8"><span id="S4.T4.7.19.8.1">7.77</span></td></tr><tr id="S4.T4.7.20" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.20.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.20.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">平均</span></span></span></span></td><td id="S4.T4.7.20.2"><span id="S4.T4.7.20.2.1">4.00</span></td><td id="S4.T4.7.20.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.20.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T4.7.20.4"><span id="S4.T4.7.20.4.1">4.58</span></td><td id="S4.T4.7.20.5"><span id="S4.T4.7.20.5.1">7.34</span></td><td id="S4.T4.7.20.6"><span id="S4.T4.7.20.6.1">8.28</span></td><td id="S4.T4.7.20.7"><span id="S4.T4.7.20.7.1">4.73</span></td><td id="S4.T4.7.20.8"><span id="S4.T4.7.20.8.1">5.42</span></td></tr><tr id="S4.T4.7.21" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.21.1" rowspan="9" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.21.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">OpenASR</span></td><td id="S4.T4.7.21.2"><span id="S4.T4.7.21.2.1">AMI</span></td><td id="S4.T4.7.21.3"><span id="S4.T4.7.21.3.1">11.69</span></td><td id="S4.T4.7.21.4"><span id="S4.T4.7.21.4.1">13.90</span></td><td id="S4.T4.7.21.5"><span id="S4.T4.7.21.5.1">15.95</span></td><td id="S4.T4.7.21.6"><span id="S4.T4.7.21.6.1">56.1</span></td><td id="S4.T4.7.21.7"><span id="S4.T4.7.21.7.1">15.24</span></td><td id="S4.T4.7.21.8"><span id="S4.T4.7.21.8.1">21.58</span></td><td id="S4.T4.7.21.9"><span id="S4.T4.7.21.9.1">57.76</span></td></tr><tr id="S4.T4.7.22" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.22.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.22.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">收益 22</span></span></span></span></td><td id="S4.T4.7.22.2"><span id="S4.T4.7.22.2.1">10.16</span></td><td id="S4.T4.7.22.3"><span id="S4.T4.7.22.3.1">12.19</span></td><td id="S4.T4.7.22.4"><span id="S4.T4.7.22.4.1">11.29</span></td><td id="S4.T4.7.22.5"><span id="S4.T4.7.22.5.1">37.18</span></td><td id="S4.T4.7.22.6"><span id="S4.T4.7.22.6.1">14.09</span></td><td id="S4.T4.7.22.7"><span id="S4.T4.7.22.7.1">13.13</span></td><td id="S4.T4.7.22.8"><span id="S4.T4.7.22.8.1">20.94</span></td></tr><tr id="S4.T4.7.23" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.23.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.23.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">吉加语音</span></span></span></span></td><td id="S4.T4.7.23.2"><span id="S4.T4.7.23.2.1">9.78</span></td><td id="S4.T4.7.23.3"><span id="S4.T4.7.23.3.1">10.12</span></td><td id="S4.T4.7.23.4"><span id="S4.T4.7.23.4.1">10.02</span></td><td id="S4.T4.7.23.5"><span id="S4.T4.7.23.5.1">26.22</span></td><td id="S4.T4.7.23.6"><span id="S4.T4.7.23.6.1">10.26</span></td><td id="S4.T4.7.23.7"><span id="S4.T4.7.23.7.1">10.71</span></td><td id="S4.T4.7.23.8"><span id="S4.T4.7.23.8.1">13.64</span></td></tr><tr id="S4.T4.7.24" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.24.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.24.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">Spgispeech</span></td><td id="S4.T4.7.24.2"><span id="S4.T4.7.24.2.1">3.13</span></td><td id="S4.T4.7.24.3"><span id="S4.T4.7.24.3.1">2.06</span></td><td id="S4.T4.7.24.4"><span id="S4.T4.7.24.4.1">2.01</span></td><td id="S4.T4.7.24.5"><span id="S4.T4.7.24.5.1">12.04</span></td><td id="S4.T4.7.24.6"><span id="S4.T4.7.24.6.1">3.00</span></td><td id="S4.T4.7.24.7"><span id="S4.T4.7.24.7.1">3.82</span></td><td id="S4.T4.7.24.8"><span id="S4.T4.7.24.8.1">5.66</span></td></tr><tr id="S4.T4.7.25" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.25.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.25.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">泰德立姆</span></span></span></span></td><td id="S4.T4.7.25.2"><span id="S4.T4.7.25.2.1">2.90</span></td><td id="S4.T4.7.25.3"><span id="S4.T4.7.25.3.1">3.56</span></td><td id="S4.T4.7.25.4"><span id="S4.T4.7.25.4.1">3.91</span></td><td id="S4.T4.7.25.5"><span id="S4.T4.7.25.5.1">19.26</span></td><td id="S4.T4.7.25.6"><span id="S4.T4.7.25.6.1">4.05</span></td><td id="S4.T4.7.25.7"><span id="S4.T4.7.25.7.1">3.01</span></td><td id="S4.T4.7.25.8"><span id="S4.T4.7.25.8.1">5.79</span></td></tr><tr id="S4.T4.7.26" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.26.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.26.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">LS-clean</span></td><td id="S4.T4.7.26.2"><span id="S4.T4.7.26.2.1">1.68</span></td><td id="S4.T4.7.26.3"><span id="S4.T4.7.26.3.1">1.48</span></td><td id="S4.T4.7.26.4"><span id="S4.T4.7.26.4.1">2.94</span></td><td id="S4.T4.7.26.5"><span id="S4.T4.7.26.5.1">2.60</span></td><td id="S4.T4.7.26.6"><span id="S4.T4.7.26.6.1">1.74</span></td><td id="S4.T4.7.26.7"><span id="S4.T4.7.26.7.1">2.49</span></td><td id="S4.T4.7.26.8"><span id="S4.T4.7.26.8.1">3.48</span></td></tr><tr id="S4.T4.7.27" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.27.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.27.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">LS-其他</span></span></span></span></td><td id="S4.T4.7.27.2"><span id="S4.T4.7.27.2.1">3.83</span></td><td id="S4.T4.7.27.3"><span id="S4.T4.7.27.3.1">2.93</span></td><td id="S4.T4.7.27.4"><span id="S4.T4.7.27.4.1">3.86</span></td><td id="S4.T4.7.27.5"><span id="S4.T4.7.27.5.1">4.86</span></td><td id="S4.T4.7.27.6"><span id="S4.T4.7.27.6.1">4.03</span></td><td id="S4.T4.7.27.7"><span id="S4.T4.7.27.7.1">5.84</span></td><td id="S4.T4.7.27.8"><span id="S4.T4.7.27.8.1">7.97</span></td></tr><tr id="S4.T4.7.28" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.28.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.28.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">民众</span></span></span></span></td><td id="S4.T4.7.28.2"><span id="S4.T4.7.28.2.1">5.91</span></td><td id="S4.T4.7.28.3"><span id="S4.T4.7.28.3.1">5.79</span></td><td id="S4.T4.7.28.4"><span id="S4.T4.7.28.4.1">9.54</span></td><td id="S4.T4.7.28.5"><span id="S4.T4.7.28.5.1">7.37</span></td><td id="S4.T4.7.28.6"><span id="S4.T4.7.28.6.1">7.05</span></td><td id="S4.T4.7.28.7"><span id="S4.T4.7.28.7.1">7.89</span></td><td id="S4.T4.7.28.8"><span id="S4.T4.7.28.8.1">10.83</span></td></tr><tr id="S4.T4.7.29" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T4.7.29.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T4.7.29.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">平均</span></span></span></span></td><td id="S4.T4.7.29.2"><span id="S4.T4.7.29.2.1">6.14</span></td><td id="S4.T4.7.29.3"><span id="S4.T4.7.29.3.1">6.50</span></td><td id="S4.T4.7.29.4"><span id="S4.T4.7.29.4.1">7.44</span></td><td id="S4.T4.7.29.5"><span id="S4.T4.7.29.5.1">20.70</span></td><td id="S4.T4.7.29.6"><span id="S4.T4.7.29.6.1">7.43</span></td><td id="S4.T4.7.29.7"><span id="S4.T4.7.29.7.1">8.56</span></td><td id="S4.T4.7.29.8"><span id="S4.T4.7.29.8.1">15.76</span></td></tr></tbody></table>

##### 自动语音识别。

我们评估了在三个公开基准上的 ASR 性能：CommonVoice \[ABD <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 20\]、FLEURS \[CMK <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]和 OpenASR \[SMK <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]。

-   • CommonVoice 是由 Mozilla 开发的开源多语言语音数据集。我们采用了 CommonVoice 版本 15.0（CV15）的测试集进行评估，其中数据收集截止到 2023 年 9 月 13 日之前。我们在八种支持的语言上进行了评估。
-   • FLEURS 是一个多语言语音数据集，旨在评估跨多种语言的语音识别和语音转文本翻译模型。模型在八种支持语言的 ASR 测试集上进行了评估。
-   • Hugging Face 上的 OpenASR 排行榜旨在对英语语音识别模型进行基准测试和评估其鲁棒性。排行榜中的数据集涵盖了多样化的语音领域，包括朗读语音、对话、会议等。

Phi-4-Multimodal 的 ASR 提示语为“将音频剪辑转录为文本。”，这是语言无关的。我们注意到，该模型可以在不提供语言信息的情况下，完美地学习在目标语言中进行识别，而 Qwen2-audio 和 Gemini-2.0-Flash 则需要提示语中的语言信息才能获得最佳的 ASR 性能。例如，Gemini-2.0-Flash 的 ASR 提示语为“将音频剪辑转录为{目标语言}。请忽略背景噪音。”我们计算了日语和中文的字符错误率（CER），以及其他六种语言的词错误率（WER）。

详细的三项基准测试的 ASR 结果总结在表 4 中。总体而言，我们在八个支持的语言上实现了新的 SOTA 多语言 ASR 性能，超过了 WhisperV3 等专家 ASR 模型。值得注意的是，Phi-4-Multimodal 在 Huggingface OpenASR 排行榜上以 5.5%的相对 WER 击败了表现最好的模型 nvidia/canary-1b，目前排名第一。Phi-4-Multimodal 的性能也优于双倍模型大小的开源 Qwen2-audio。请注意，GPT-4o 对 ASR 提示非常敏感。我们尝试了许多 ASR 提示，并在测试集上展示了我们能够获得的最佳整体 ASR 结果。我们最终使用的 ASR 提示是：“请以书面格式捕捉所说话语的语音，请不要在您的回答中包含任何超出所说话语内容的信息。删除任何犹豫词，如嗯、啊。支持混合语言。您的回答应格式如下：语音内容： <<< 此处转录文本 \>\>\> 。”

##### 自动语音翻译。

我们评估了 AST 在两个公开基准上的性能：CoVoST2 \[WWGP21\] 和 FLEURS \[CMK <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]。

-   • CoVoST2 是由 Mozilla 的 Common Voice 项目派生出的多语言语音转文本翻译数据集。它是可用于语音翻译的最大开放数据集之一，提供对 X 到英语（X-En）和英语到 X（En-X）翻译任务的支持。我们在测试集上评估了支持语言的方向。
-   我们使用与 ASR 评估中相同的 FLEURS 测试音频，但将 ASR 转录替换为翻译。我们在测试集上评估支持语言上的 EN-X 和 X-EN 方向。

AST 的 0-shot 和 CoT 评估提示分别为“将音频翻译成{目标语言}。”和“将音频转录成文本，然后将音频翻译成{目标语言}。使用 <s⁢e⁢p\>expectation<sep>< italic\_s italic\_e italic\_p > 作为原始转录和翻译之间的分隔符。”，分别。我们计算参考文本和文本翻译之间的 BLEU 分数。对于 CoT 评估， <s⁢e⁢p\>expectation<sep>< italic\_s italic\_e italic\_p > 之后的文本被视为翻译。

详细 AST 结果在每个翻译方向上如表 5 所示。从表中可以看出，CoT 推理可以极大地提高翻译质量，在各种测试集上提高了 1-2 个 BLUE 分数。Phi-4-Multimodal 在 CoVoST2 基准测试中，包括 Gemini-2.0-Flash 和 GPT-4o 在内的评估模型中，实现了最佳的 AST 性能。在 FLEURS 上，Phi-4-Multimodal 优于专家模型 SeamlessM4T-large-V2，其性能与 GPT-4o 相当，而 GPT-4o 的大小远大于 Phi-4-Multimodal。由于模型不支持 CoT 解码，或者难以找到适合模型正确响应每个测试样本的 CoT 提示，我们没有将 CoT 评估应用于其他模型。与 ASR 类似，Phi-4-Multimodal 在 AST 提示中不需要源语言信息。

表 5：AST 基准测试的详细结果，报告了 BLEU（ ↑\\uparrow↑ ）分数。我们使用“zh”、“ja-mecab”和“13a”分词器在 Sacrebleu \[Pos18\] 中分别计算中文、日语和其他六种语言的 BLUE 分数。所有结果均通过我们内部评估获得。

<table id="S4.T5.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tbody data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tr id="S4.T5.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.1.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S4.T5.3.1.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S4.T5.3.1.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.1.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">菲-4-多模态</span></span></span></span></td><td id="S4.T5.3.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span id="S4.T5.3.1.1.1">(</span><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1"> <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T5.3.1.1.m1.1" display="inline" alttext="+"><semantics id="S4.T5.3.1.1.m1.1a"><mo mathsize="50%" id="S4.T5.3.1.1.m1.1.1">+</mo><annotation-xml id="S4.T5.3.1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T5.3.1.1.m1.1c" encoding="application/x-tex">+</annotation><annotation id="S4.T5.3.1.1.m1.1d" encoding="application/x-llamapun">+</annotation></semantics></math> CoT) —— <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T5.3.1.1.m1.1" display="inline" alttext="+"><semantics id="S4.T5.3.1.1.m1.1a"><mo mathsize="50%" id="S4.T5.3.1.1.m1.1.1">+</mo><annotation-xml id="S4.T5.3.1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T5.3.1.1.m1.1c" encoding="application/x-tex">+</annotation><annotation id="S4.T5.3.1.1.m1.1d" encoding="application/x-llamapun">+</annotation></semantics></math> CoT)</span></span></span></td><td id="S4.T5.3.1.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.1.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">轻语 V3</span></span></span></span></td><td id="S4.T5.3.1.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.1.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">无缝 M4T-V2</span></span></span></span></td><td id="S4.T5.3.1.7" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.1.7.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">Qwen2 音频</span></span></span></span></td><td id="S4.T5.3.1.8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.1.8.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">Gemini</span></span></span></span></td><td id="S4.T5.3.1.9" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.1.9.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">GPT-4o</span></td></tr><tr id="S4.T5.3.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.2.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">数据集</span></span></span></span></td><td id="S4.T5.3.2.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.2.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">子类别</span></span></span></span></td><td colspan="2" id="S4.T5.3.2.3"><span id="S4.T5.3.2.3.1">5.6B</span></td><td id="S4.T5.3.2.4"><span id="S4.T5.3.2.4.1">1.5B</span></td><td id="S4.T5.3.2.5"><span id="S4.T5.3.2.5.1">2.3B</span></td><td id="S4.T5.3.2.6"><span id="S4.T5.3.2.6.1">8B</span></td><td id="S4.T5.3.2.7" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.2.7.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">2.0-闪存</span></span></span></span></td><td id="S4.T5.3.2.8"><span id="S4.T5.3.2.8.1">-</span></td></tr><tr id="S4.T5.3.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.3.1" rowspan="8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.3.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">CoVoST2 X-EN</span></td><td id="S4.T5.3.3.2"><span id="S4.T5.3.3.2.1">DE</span></td><td id="S4.T5.3.3.3"><span id="S4.T5.3.3.3.1">39.81</span></td><td id="S4.T5.3.3.4"><span id="S4.T5.3.3.4.1">40.83</span></td><td id="S4.T5.3.3.5"><span id="S4.T5.3.3.5.1">34.17</span></td><td id="S4.T5.3.3.6"><span id="S4.T5.3.3.6.1">39.90</span></td><td id="S4.T5.3.3.7"><span id="S4.T5.3.3.7.1">34.99</span></td><td id="S4.T5.3.3.8"><span id="S4.T5.3.3.8.1">38.34</span></td><td id="S4.T5.3.3.9"><span id="S4.T5.3.3.9.1">39.29</span></td></tr><tr id="S4.T5.3.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.4.1"><span id="S4.T5.3.4.1.1">ES</span></td><td id="S4.T5.3.4.2"><span id="S4.T5.3.4.2.1">43.60</span></td><td id="S4.T5.3.4.3"><span id="S4.T5.3.4.3.1">44.84</span></td><td id="S4.T5.3.4.4"><span id="S4.T5.3.4.4.1">39.21</span></td><td id="S4.T5.3.4.5"><span id="S4.T5.3.4.5.1">42.90</span></td><td id="S4.T5.3.4.6"><span id="S4.T5.3.4.6.1">39.91</span></td><td id="S4.T5.3.4.7"><span id="S4.T5.3.4.7.1">41.74</span></td><td id="S4.T5.3.4.8"><span id="S4.T5.3.4.8.1">41.49</span></td></tr><tr id="S4.T5.3.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.5.1"><span id="S4.T5.3.5.1.1">FR</span></td><td id="S4.T5.3.5.2"><span id="S4.T5.3.5.2.1">42.24</span></td><td id="S4.T5.3.5.3"><span id="S4.T5.3.5.3.1">43.42</span></td><td id="S4.T5.3.5.4"><span id="S4.T5.3.5.4.1">35.43</span></td><td id="S4.T5.3.5.5"><span id="S4.T5.3.5.5.1">42.18</span></td><td id="S4.T5.3.5.6"><span id="S4.T5.3.5.6.1">38.31</span></td><td id="S4.T5.3.5.7"><span id="S4.T5.3.5.7.1">38.96</span></td><td id="S4.T5.3.5.8"><span id="S4.T5.3.5.8.1">38.56</span></td></tr><tr id="S4.T5.3.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.6.1"><span id="S4.T5.3.6.1.1">IT</span></td><td id="S4.T5.3.6.2"><span id="S4.T5.3.6.2.1">41.42</span></td><td id="S4.T5.3.6.3"><span id="S4.T5.3.6.3.1">42.45</span></td><td id="S4.T5.3.6.4"><span id="S4.T5.3.6.4.1">35.82</span></td><td id="S4.T5.3.6.5"><span id="S4.T5.3.6.5.1">39.85</span></td><td id="S4.T5.3.6.6"><span id="S4.T5.3.6.6.1">36.35</span></td><td id="S4.T5.3.6.7"><span id="S4.T5.3.6.7.1">37.76</span></td><td id="S4.T5.3.6.8"><span id="S4.T5.3.6.8.1">37.33</span></td></tr><tr id="S4.T5.3.7" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.7.1"><span id="S4.T5.3.7.1.1">JA</span></td><td id="S4.T5.3.7.2"><span id="S4.T5.3.7.2.1">30.54</span></td><td id="S4.T5.3.7.3"><span id="S4.T5.3.7.3.1">31.87</span></td><td id="S4.T5.3.7.4"><span id="S4.T5.3.7.4.1">23.59</span></td><td id="S4.T5.3.7.5"><span id="S4.T5.3.7.5.1">22.18</span></td><td id="S4.T5.3.7.6"><span id="S4.T5.3.7.6.1">22.98</span></td><td id="S4.T5.3.7.7"><span id="S4.T5.3.7.7.1">28.04</span></td><td id="S4.T5.3.7.8"><span id="S4.T5.3.7.8.1">30.46</span></td></tr><tr id="S4.T5.3.8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.8.1"><span id="S4.T5.3.8.1.1">PT</span></td><td id="S4.T5.3.8.2"><span id="S4.T5.3.8.2.1">55.28</span></td><td id="S4.T5.3.8.3"><span id="S4.T5.3.8.3.1">56.25</span></td><td id="S4.T5.3.8.4"><span id="S4.T5.3.8.4.1">50.22</span></td><td id="S4.T5.3.8.5"><span id="S4.T5.3.8.5.1">53.82</span></td><td id="S4.T5.3.8.6"><span id="S4.T5.3.8.6.1">47.79</span></td><td id="S4.T5.3.8.7"><span id="S4.T5.3.8.7.1">50.81</span></td><td id="S4.T5.3.8.8"><span id="S4.T5.3.8.8.1">50.60</span></td></tr><tr id="S4.T5.3.9" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.9.1"><span id="S4.T5.3.9.1.1">ZH</span></td><td id="S4.T5.3.9.2"><span id="S4.T5.3.9.2.1">22.39</span></td><td id="S4.T5.3.9.3"><span id="S4.T5.3.9.3.1">25.64</span></td><td id="S4.T5.3.9.4"><span id="S4.T5.3.9.4.1">14.36</span></td><td id="S4.T5.3.9.5"><span id="S4.T5.3.9.5.1">21.92</span></td><td id="S4.T5.3.9.6"><span id="S4.T5.3.9.6.1">23.27</span></td><td id="S4.T5.3.9.7"><span id="S4.T5.3.9.7.1">20.69</span></td><td id="S4.T5.3.9.8"><span id="S4.T5.3.9.8.1">21.93</span></td></tr><tr id="S4.T5.3.10" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.10.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.10.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">平均</span></span></span></span></td><td id="S4.T5.3.10.2"><span id="S4.T5.3.10.2.1">39.33</span></td><td id="S4.T5.3.10.3"><span id="S4.T5.3.10.3.1">40.76</span></td><td id="S4.T5.3.10.4"><span id="S4.T5.3.10.4.1">33.26</span></td><td id="S4.T5.3.10.5"><span id="S4.T5.3.10.5.1">37.54</span></td><td id="S4.T5.3.10.6"><span id="S4.T5.3.10.6.1">34.8</span></td><td id="S4.T5.3.10.7"><span id="S4.T5.3.10.7.1">36.62</span></td><td id="S4.T5.3.10.8"><span id="S4.T5.3.10.8.1">37.09</span></td></tr><tr id="S4.T5.3.11" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.11.1" rowspan="4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.11.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">CoVoST2 英-中</span></span></span></span></td><td id="S4.T5.3.11.2"><span id="S4.T5.3.11.2.1">DE</span></td><td id="S4.T5.3.11.3"><span id="S4.T5.3.11.3.1">34.22</span></td><td id="S4.T5.3.11.4"><span id="S4.T5.3.11.4.1">34.87</span></td><td id="S4.T5.3.11.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.11.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T5.3.11.6"><span id="S4.T5.3.11.6.1">37.16</span></td><td id="S4.T5.3.11.7"><span id="S4.T5.3.11.7.1">29.72</span></td><td id="S4.T5.3.11.8"><span id="S4.T5.3.11.8.1">34.32</span></td><td id="S4.T5.3.11.9"><span id="S4.T5.3.11.9.1">34.38</span></td></tr><tr id="S4.T5.3.12" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.12.1"><span id="S4.T5.3.12.1.1">JA</span></td><td id="S4.T5.3.12.2"><span id="S4.T5.3.12.2.1">32.93</span></td><td id="S4.T5.3.12.3"><span id="S4.T5.3.12.3.1">34.04</span></td><td id="S4.T5.3.12.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.12.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T5.3.12.5"><span id="S4.T5.3.12.5.1">24.94</span></td><td id="S4.T5.3.12.6"><span id="S4.T5.3.12.6.1">27.30</span></td><td id="S4.T5.3.12.7"><span id="S4.T5.3.12.7.1">32.56</span></td><td id="S4.T5.3.12.8"><span id="S4.T5.3.12.8.1">32.98</span></td></tr><tr id="S4.T5.3.13" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.13.1"><span id="S4.T5.3.13.1.1">ZH</span></td><td id="S4.T5.3.13.2"><span id="S4.T5.3.13.2.1">46.30</span></td><td id="S4.T5.3.13.3"><span id="S4.T5.3.13.3.1">47.28</span></td><td id="S4.T5.3.13.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.13.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T5.3.13.5"><span id="S4.T5.3.13.5.1">36.41</span></td><td id="S4.T5.3.13.6"><span id="S4.T5.3.13.6.1">45.09</span></td><td id="S4.T5.3.13.7"><span id="S4.T5.3.13.7.1">40.91</span></td><td id="S4.T5.3.13.8"><span id="S4.T5.3.13.8.1">44.22</span></td></tr><tr id="S4.T5.3.14" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.14.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.14.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">平均</span></span></span></span></td><td id="S4.T5.3.14.2"><span id="S4.T5.3.14.2.1">37.82</span></td><td id="S4.T5.3.14.3"><span id="S4.T5.3.14.3.1">38.73</span></td><td id="S4.T5.3.14.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.14.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T5.3.14.5"><span id="S4.T5.3.14.5.1">32.84</span></td><td id="S4.T5.3.14.6"><span id="S4.T5.3.14.6.1">34.04</span></td><td id="S4.T5.3.14.7"><span id="S4.T5.3.14.7.1">35.93</span></td><td id="S4.T5.3.14.8"><span id="S4.T5.3.14.8.1">37.19</span></td></tr><tr id="S4.T5.3.15" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.15.1" rowspan="8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.15.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">FLEURS X-EN</span></td><td id="S4.T5.3.15.2"><span id="S4.T5.3.15.2.1">DE</span></td><td id="S4.T5.3.15.3"><span id="S4.T5.3.15.3.1">37.71</span></td><td id="S4.T5.3.15.4"><span id="S4.T5.3.15.4.1">39.43</span></td><td id="S4.T5.3.15.5"><span id="S4.T5.3.15.5.1">33.49</span></td><td id="S4.T5.3.15.6"><span id="S4.T5.3.15.6.1">36.80</span></td><td id="S4.T5.3.15.7"><span id="S4.T5.3.15.7.1">32.88</span></td><td id="S4.T5.3.15.8"><span id="S4.T5.3.15.8.1">38.48</span></td><td id="S4.T5.3.15.9"><span id="S4.T5.3.15.9.1">41.03</span></td></tr><tr id="S4.T5.3.16" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.16.1"><span id="S4.T5.3.16.1.1">ES</span></td><td id="S4.T5.3.16.2"><span id="S4.T5.3.16.2.1">25.33</span></td><td id="S4.T5.3.16.3"><span id="S4.T5.3.16.3.1">27.56</span></td><td id="S4.T5.3.16.4"><span id="S4.T5.3.16.4.1">22.68</span></td><td id="S4.T5.3.16.5"><span id="S4.T5.3.16.5.1">25.67</span></td><td id="S4.T5.3.16.6"><span id="S4.T5.3.16.6.1">22.40</span></td><td id="S4.T5.3.16.7"><span id="S4.T5.3.16.7.1">26.51</span></td><td id="S4.T5.3.16.8"><span id="S4.T5.3.16.8.1">29.10</span></td></tr><tr id="S4.T5.3.17" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.17.1"><span id="S4.T5.3.17.1.1">FR</span></td><td id="S4.T5.3.17.2"><span id="S4.T5.3.17.2.1">35.10</span></td><td id="S4.T5.3.17.3"><span id="S4.T5.3.17.3.1">37.42</span></td><td id="S4.T5.3.17.4"><span id="S4.T5.3.17.4.1">30.98</span></td><td id="S4.T5.3.17.5"><span id="S4.T5.3.17.5.1">33.78</span></td><td id="S4.T5.3.17.6"><span id="S4.T5.3.17.6.1">30.82</span></td><td id="S4.T5.3.17.7"><span id="S4.T5.3.17.7.1">35.18</span></td><td id="S4.T5.3.17.8"><span id="S4.T5.3.17.8.1">37.98</span></td></tr><tr id="S4.T5.3.18" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.18.1"><span id="S4.T5.3.18.1.1">IT</span></td><td id="S4.T5.3.18.2"><span id="S4.T5.3.18.2.1">26.06</span></td><td id="S4.T5.3.18.3"><span id="S4.T5.3.18.3.1">28.45</span></td><td id="S4.T5.3.18.4"><span id="S4.T5.3.18.4.1">23.00</span></td><td id="S4.T5.3.18.5"><span id="S4.T5.3.18.5.1">26.80</span></td><td id="S4.T5.3.18.6"><span id="S4.T5.3.18.6.1">22.12</span></td><td id="S4.T5.3.18.7"><span id="S4.T5.3.18.7.1">25.02</span></td><td id="S4.T5.3.18.8"><span id="S4.T5.3.18.8.1">28.51</span></td></tr><tr id="S4.T5.3.19" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.19.1"><span id="S4.T5.3.19.1.1">JA</span></td><td id="S4.T5.3.19.2"><span id="S4.T5.3.19.2.1">21.62</span></td><td id="S4.T5.3.19.3"><span id="S4.T5.3.19.3.1">25.22</span></td><td id="S4.T5.3.19.4"><span id="S4.T5.3.19.4.1">16.63</span></td><td id="S4.T5.3.19.5"><span id="S4.T5.3.19.5.1">18.63</span></td><td id="S4.T5.3.19.6"><span id="S4.T5.3.19.6.1">4.49</span></td><td id="S4.T5.3.19.7"><span id="S4.T5.3.19.7.1">23.89</span></td><td id="S4.T5.3.19.8"><span id="S4.T5.3.19.8.1">24.17</span></td></tr><tr id="S4.T5.3.20" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.20.1"><span id="S4.T5.3.20.1.1">PT</span></td><td id="S4.T5.3.20.2"><span id="S4.T5.3.20.2.1">40.80</span></td><td id="S4.T5.3.20.3"><span id="S4.T5.3.20.3.1">42.85</span></td><td id="S4.T5.3.20.4"><span id="S4.T5.3.20.4.1">37.50</span></td><td id="S4.T5.3.20.5"><span id="S4.T5.3.20.5.1">37.61</span></td><td id="S4.T5.3.20.6"><span id="S4.T5.3.20.6.1">35.38</span></td><td id="S4.T5.3.20.7"><span id="S4.T5.3.20.7.1">41.51</span></td><td id="S4.T5.3.20.8"><span id="S4.T5.3.20.8.1">43.33</span></td></tr><tr id="S4.T5.3.21" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.21.1"><span id="S4.T5.3.21.1.1">ZH</span></td><td id="S4.T5.3.21.2"><span id="S4.T5.3.21.2.1">22.37</span></td><td id="S4.T5.3.21.3"><span id="S4.T5.3.21.3.1">25.49</span></td><td id="S4.T5.3.21.4"><span id="S4.T5.3.21.4.1">16.07</span></td><td id="S4.T5.3.21.5"><span id="S4.T5.3.21.5.1">22.78</span></td><td id="S4.T5.3.21.6"><span id="S4.T5.3.21.6.1">17.95</span></td><td id="S4.T5.3.21.7"><span id="S4.T5.3.21.7.1">24.27</span></td><td id="S4.T5.3.21.8"><span id="S4.T5.3.21.8.1">24.12</span></td></tr><tr id="S4.T5.3.22" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.22.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.22.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">平均</span></span></span></span></td><td id="S4.T5.3.22.2"><span id="S4.T5.3.22.2.1">29.86</span></td><td id="S4.T5.3.22.3"><span id="S4.T5.3.22.3.1">32.35</span></td><td id="S4.T5.3.22.4"><span id="S4.T5.3.22.4.1">25.76</span></td><td id="S4.T5.3.22.5"><span id="S4.T5.3.22.5.1">28.87</span></td><td id="S4.T5.3.22.6"><span id="S4.T5.3.22.6.1">23.72</span></td><td id="S4.T5.3.22.7"><span id="S4.T5.3.22.7.1">30.69</span></td><td id="S4.T5.3.22.8"><span id="S4.T5.3.22.8.1">32.61</span></td></tr><tr id="S4.T5.3.23" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.23.1" rowspan="8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.23.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">鲜花在-X</span></span></span></span></td><td id="S4.T5.3.23.2"><span id="S4.T5.3.23.2.1">DE</span></td><td id="S4.T5.3.23.3"><span id="S4.T5.3.23.3.1">34.44</span></td><td id="S4.T5.3.23.4"><span id="S4.T5.3.23.4.1">35.94</span></td><td id="S4.T5.3.23.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.23.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T5.3.23.6"><span id="S4.T5.3.23.6.1">32.35</span></td><td id="S4.T5.3.23.7"><span id="S4.T5.3.23.7.1">23.60</span></td><td id="S4.T5.3.23.8"><span id="S4.T5.3.23.8.1">37.15</span></td><td id="S4.T5.3.23.9"><span id="S4.T5.3.23.9.1">36.68</span></td></tr><tr id="S4.T5.3.24" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.24.1"><span id="S4.T5.3.24.1.1">ES</span></td><td id="S4.T5.3.24.2"><span id="S4.T5.3.24.2.1">23.66</span></td><td id="S4.T5.3.24.3"><span id="S4.T5.3.24.3.1">25.09</span></td><td id="S4.T5.3.24.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.24.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T5.3.24.5"><span id="S4.T5.3.24.5.1">23.37</span></td><td id="S4.T5.3.24.6"><span id="S4.T5.3.24.6.1">19.47</span></td><td id="S4.T5.3.24.7"><span id="S4.T5.3.24.7.1">26.40</span></td><td id="S4.T5.3.24.8"><span id="S4.T5.3.24.8.1">25.99</span></td></tr><tr id="S4.T5.3.25" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.25.1"><span id="S4.T5.3.25.1.1">FR</span></td><td id="S4.T5.3.25.2"><span id="S4.T5.3.25.2.1">37.92</span></td><td id="S4.T5.3.25.3"><span id="S4.T5.3.25.3.1">40.12</span></td><td id="S4.T5.3.25.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.25.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T5.3.25.5"><span id="S4.T5.3.25.5.1">42.08</span></td><td id="S4.T5.3.25.6"><span id="S4.T5.3.25.6.1">27.71</span></td><td id="S4.T5.3.25.7"><span id="S4.T5.3.25.7.1">46.51</span></td><td id="S4.T5.3.25.8"><span id="S4.T5.3.25.8.1">44.26</span></td></tr><tr id="S4.T5.3.26" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.26.1"><span id="S4.T5.3.26.1.1">IT</span></td><td id="S4.T5.3.26.2"><span id="S4.T5.3.26.2.1">23.44</span></td><td id="S4.T5.3.26.3"><span id="S4.T5.3.26.3.1">24.85</span></td><td id="S4.T5.3.26.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.26.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T5.3.26.5"><span id="S4.T5.3.26.5.1">24.55</span></td><td id="S4.T5.3.26.6"><span id="S4.T5.3.26.6.1">19.61</span></td><td id="S4.T5.3.26.7"><span id="S4.T5.3.26.7.1">29.04</span></td><td id="S4.T5.3.26.8"><span id="S4.T5.3.26.8.1">28.59</span></td></tr><tr id="S4.T5.3.27" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.27.1"><span id="S4.T5.3.27.1.1">JA</span></td><td id="S4.T5.3.27.2"><span id="S4.T5.3.27.2.1">30.67</span></td><td id="S4.T5.3.27.3"><span id="S4.T5.3.27.3.1">30.81</span></td><td id="S4.T5.3.27.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.27.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T5.3.27.5"><span id="S4.T5.3.27.5.1">20.46</span></td><td id="S4.T5.3.27.6"><span id="S4.T5.3.27.6.1">12.38</span></td><td id="S4.T5.3.27.7"><span id="S4.T5.3.27.7.1">35.51</span></td><td id="S4.T5.3.27.8"><span id="S4.T5.3.27.8.1">33.99</span></td></tr><tr id="S4.T5.3.28" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.28.1"><span id="S4.T5.3.28.1.1">PT</span></td><td id="S4.T5.3.28.2"><span id="S4.T5.3.28.2.1">37.79</span></td><td id="S4.T5.3.28.3"><span id="S4.T5.3.28.3.1">38.94</span></td><td id="S4.T5.3.28.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.28.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T5.3.28.5"><span id="S4.T5.3.28.5.1">42.36</span></td><td id="S4.T5.3.28.6"><span id="S4.T5.3.28.6.1">32.52</span></td><td id="S4.T5.3.28.7"><span id="S4.T5.3.28.7.1">45.34</span></td><td id="S4.T5.3.28.8"><span id="S4.T5.3.28.8.1">45.82</span></td></tr><tr id="S4.T5.3.29" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.29.1"><span id="S4.T5.3.29.1.1">ZH</span></td><td id="S4.T5.3.29.2"><span id="S4.T5.3.29.2.1">37.10</span></td><td id="S4.T5.3.29.3"><span id="S4.T5.3.29.3.1">39.19</span></td><td id="S4.T5.3.29.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.29.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T5.3.29.5"><span id="S4.T5.3.29.5.1">27.93</span></td><td id="S4.T5.3.29.6"><span id="S4.T5.3.29.6.1">27.38</span></td><td id="S4.T5.3.29.7"><span id="S4.T5.3.29.7.1">41.36</span></td><td id="S4.T5.3.29.8"><span id="S4.T5.3.29.8.1">42.16</span></td></tr><tr id="S4.T5.3.30" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T5.3.30.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.30.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">平均</span></span></span></span></td><td id="S4.T5.3.30.2"><span id="S4.T5.3.30.2.1">32.15</span></td><td id="S4.T5.3.30.3"><span id="S4.T5.3.30.3.1">33.56</span></td><td id="S4.T5.3.30.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T5.3.30.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">N/A</span></td><td id="S4.T5.3.30.5"><span id="S4.T5.3.30.5.1">30.44</span></td><td id="S4.T5.3.30.6"><span id="S4.T5.3.30.6.1">23.24</span></td><td id="S4.T5.3.30.7"><span id="S4.T5.3.30.7.1">37.33</span></td><td id="S4.T5.3.30.8"><span id="S4.T5.3.30.8.1">36.78</span></td></tr></tbody></table>

表 6：多模态模型在语音问答/摘要/音频理解任务上的结果细节。分数使用 GPT-4-0613 作为评判标准获得。

<table id="S4.T6.11" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tbody data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tr id="S4.T6.11.12" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.12.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S4.T6.11.12.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S4.T6.11.12.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S4.T6.11.12.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S4.T6.11.12.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.12.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">菲-4-多模态</span></span></span></span></td><td id="S4.T6.11.12.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.12.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">Qwen2 音频</span></span></span></span></td><td id="S4.T6.11.12.7" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.12.7.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">Gemini</span></span></span></span></td><td id="S4.T6.11.12.8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.12.8.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">GPT-4o</span></td></tr><tr id="S4.T6.11.13" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.13.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.13.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">任务</span></span></span></span></td><td id="S4.T6.11.13.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.13.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">指标</span></span></span></span></td><td id="S4.T6.11.13.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.13.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">数据集</span></span></span></span></td><td id="S4.T6.11.13.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.13.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">子类别</span></span></span></span></td><td id="S4.T6.11.13.5"><span id="S4.T6.11.13.5.1">5.6B</span></td><td id="S4.T6.11.13.6"><span id="S4.T6.11.13.6.1">8B</span></td><td id="S4.T6.11.13.7" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.13.7.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">2.0-闪存</span></span></span></span></td><td id="S4.T6.11.13.8"><span id="S4.T6.11.13.8.1">-</span></td></tr><tr id="S4.T6.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.1.1.2" rowspan="12"><span id="S4.T6.1.1.2.1">SQQA</span></td><td id="S4.T6.1.1.1" rowspan="3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.1.1.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">评分 1-10 <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T6.1.1.1.1.m1.1" display="inline" alttext="\uparrow"><semantics id="S4.T6.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T6.1.1.1.1.m1.1.1">↑</mo><annotation-xml id="S4.T6.1.1.1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T6.1.1.1.1.m1.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S4.T6.1.1.1.1.m1.1d" encoding="application/x-llamapun">↑</annotation></semantics></math></span></span></span></span></td><td id="S4.T6.1.1.3" rowspan="3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.1.1.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">MT-Bench</span></td><td id="S4.T6.1.1.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.1.1.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">turn-1</span></td><td id="S4.T6.1.1.5"><span id="S4.T6.1.1.5.1">7.42</span></td><td id="S4.T6.1.1.6"><span id="S4.T6.1.1.6.1">5.07</span></td><td id="S4.T6.1.1.7"><span id="S4.T6.1.1.7.1">8.08</span></td><td id="S4.T6.1.1.8"><span id="S4.T6.1.1.8.1">8.27</span></td></tr><tr id="S4.T6.11.14" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.14.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.14.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">turn-2</span></td><td id="S4.T6.11.14.2"><span id="S4.T6.11.14.2.1">6.67</span></td><td id="S4.T6.11.14.3"><span id="S4.T6.11.14.3.1">4.76</span></td><td id="S4.T6.11.14.4"><span id="S4.T6.11.14.4.1">8.06</span></td><td id="S4.T6.11.14.5"><span id="S4.T6.11.14.5.1">7.94</span></td></tr><tr id="S4.T6.11.15" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.15.1"><span id="S4.T6.11.15.1.1">AVG</span></td><td id="S4.T6.11.15.2"><span id="S4.T6.11.15.2.1">7.05</span></td><td id="S4.T6.11.15.3"><span id="S4.T6.11.15.3.1">4.92</span></td><td id="S4.T6.11.15.4"><span id="S4.T6.11.15.4.1">8.07</span></td><td id="S4.T6.11.15.5"><span id="S4.T6.11.15.5.1">8.11</span></td></tr><tr id="S4.T6.2.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.2.2.1" rowspan="9" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.2.2.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">ACC <math alttext="\uparrow" display="inline" id="S4.T6.2.2.1.1.m1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><semantics id="S4.T6.2.2.1.1.m1.1a"><mo id="S4.T6.2.2.1.1.m1.1.1" stretchy="false" xref="S4.T6.2.2.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T6.2.2.1.1.m1.1b"><ci id="S4.T6.2.2.1.1.m1.1.1.cmml" xref="S4.T6.2.2.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.2.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.2.2.1.1.m1.1d">↑</annotation></semantics></math></span></td><td id="S4.T6.2.2.2" rowspan="9"><span id="S4.T6.2.2.2.1">MMMLU</span></td><td id="S4.T6.2.2.3"><span id="S4.T6.2.2.3.1">EN</span></td><td id="S4.T6.2.2.4"><span id="S4.T6.2.2.4.1">54.25</span></td><td id="S4.T6.2.2.5"><span id="S4.T6.2.2.5.1">16.00</span></td><td id="S4.T6.2.2.6"><span id="S4.T6.2.2.6.1">74.00</span></td><td id="S4.T6.2.2.7"><span id="S4.T6.2.2.7.1">78.75</span></td></tr><tr id="S4.T6.11.16" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.16.1"><span id="S4.T6.11.16.1.1">DE</span></td><td id="S4.T6.11.16.2"><span id="S4.T6.11.16.2.1">39.50</span></td><td id="S4.T6.11.16.3"><span id="S4.T6.11.16.3.1">10.50</span></td><td id="S4.T6.11.16.4"><span id="S4.T6.11.16.4.1">78.75</span></td><td id="S4.T6.11.16.5"><span id="S4.T6.11.16.5.1">73.70</span></td></tr><tr id="S4.T6.11.17" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.17.1"><span id="S4.T6.11.17.1.1">ES</span></td><td id="S4.T6.11.17.2"><span id="S4.T6.11.17.2.1">42.25</span></td><td id="S4.T6.11.17.3"><span id="S4.T6.11.17.3.1">25.00</span></td><td id="S4.T6.11.17.4"><span id="S4.T6.11.17.4.1">75.75</span></td><td id="S4.T6.11.17.5"><span id="S4.T6.11.17.5.1">78.32</span></td></tr><tr id="S4.T6.11.18" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.18.1"><span id="S4.T6.11.18.1.1">FR</span></td><td id="S4.T6.11.18.2"><span id="S4.T6.11.18.2.1">38.50</span></td><td id="S4.T6.11.18.3"><span id="S4.T6.11.18.3.1">19.25</span></td><td id="S4.T6.11.18.4"><span id="S4.T6.11.18.4.1">74.25</span></td><td id="S4.T6.11.18.5"><span id="S4.T6.11.18.5.1">76.21</span></td></tr><tr id="S4.T6.11.19" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.19.1"><span id="S4.T6.11.19.1.1">IT</span></td><td id="S4.T6.11.19.2"><span id="S4.T6.11.19.2.1">35.00</span></td><td id="S4.T6.11.19.3"><span id="S4.T6.11.19.3.1">18.50</span></td><td id="S4.T6.11.19.4"><span id="S4.T6.11.19.4.1">70.50</span></td><td id="S4.T6.11.19.5"><span id="S4.T6.11.19.5.1">71.84</span></td></tr><tr id="S4.T6.11.20" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.20.1"><span id="S4.T6.11.20.1.1">JA</span></td><td id="S4.T6.11.20.2"><span id="S4.T6.11.20.2.1">30.00</span></td><td id="S4.T6.11.20.3"><span id="S4.T6.11.20.3.1">14.25</span></td><td id="S4.T6.11.20.4"><span id="S4.T6.11.20.4.1">68.75</span></td><td id="S4.T6.11.20.5"><span id="S4.T6.11.20.5.1">67.40</span></td></tr><tr id="S4.T6.11.21" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.21.1"><span id="S4.T6.11.21.1.1">PT</span></td><td id="S4.T6.11.21.2"><span id="S4.T6.11.21.2.1">34.00</span></td><td id="S4.T6.11.21.3"><span id="S4.T6.11.21.3.1">11.25</span></td><td id="S4.T6.11.21.4"><span id="S4.T6.11.21.4.1">70.50</span></td><td id="S4.T6.11.21.5"><span id="S4.T6.11.21.5.1">70.48</span></td></tr><tr id="S4.T6.11.22" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.22.1"><span id="S4.T6.11.22.1.1">ZH</span></td><td id="S4.T6.11.22.2"><span id="S4.T6.11.22.2.1">34.50</span></td><td id="S4.T6.11.22.3"><span id="S4.T6.11.22.3.1">9.50</span></td><td id="S4.T6.11.22.4"><span id="S4.T6.11.22.4.1">66.00</span></td><td id="S4.T6.11.22.5"><span id="S4.T6.11.22.5.1">63.77</span></td></tr><tr id="S4.T6.11.23" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.23.1"><span id="S4.T6.11.23.1.1">AVG</span></td><td id="S4.T6.11.23.2"><span id="S4.T6.11.23.2.1">38.50</span></td><td id="S4.T6.11.23.3"><span id="S4.T6.11.23.3.1">15.53</span></td><td id="S4.T6.11.23.4"><span id="S4.T6.11.23.4.1">72.31</span></td><td id="S4.T6.11.23.5"><span id="S4.T6.11.23.5.1">72.56</span></td></tr><tr id="S4.T6.4.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.4.4.3" rowspan="6"><span id="S4.T6.4.4.3.1">SSUM</span></td><td id="S4.T6.3.3.1" rowspan="6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.3.3.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">得分 1-7 <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T6.3.3.1.1.m1.1" display="inline" alttext="\uparrow"><semantics id="S4.T6.3.3.1.1.m1.1a"><mo stretchy="false" id="S4.T6.3.3.1.1.m1.1.1">↑</mo><annotation-xml id="S4.T6.3.3.1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T6.3.3.1.1.m1.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S4.T6.3.3.1.1.m1.1d" encoding="application/x-llamapun">↑</annotation></semantics></math></span></span></span></span></td><td id="S4.T6.4.4.4" rowspan="3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.4.4.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">金色 3</span></span></span></span></td><td id="S4.T6.4.4.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">幻觉 <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T6.4.4.2.m1.1" display="inline" alttext="\downarrow"><semantics id="S4.T6.4.4.2.m1.1a"><mo stretchy="false" mathsize="50%" id="S4.T6.4.4.2.m1.1.1">↓</mo><annotation-xml id="S4.T6.4.4.2.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T6.4.4.2.m1.1c" encoding="application/x-tex">\downarrow</annotation><annotation id="S4.T6.4.4.2.m1.1d" encoding="application/x-llamapun">↓</annotation></semantics></math></span></span></span></td><td id="S4.T6.4.4.5"><span id="S4.T6.4.4.5.1">0.14</span></td><td id="S4.T6.4.4.6"><span id="S4.T6.4.4.6.1">0.51</span></td><td id="S4.T6.4.4.7"><span id="S4.T6.4.4.7.1">0.20</span></td><td id="S4.T6.4.4.8"><span id="S4.T6.4.4.8.1">0.09</span></td></tr><tr id="S4.T6.5.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.5.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">指令遵从 <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T6.5.5.1.m1.1" display="inline" alttext="\uparrow"><semantics id="S4.T6.5.5.1.m1.1a"><mo stretchy="false" mathsize="50%" id="S4.T6.5.5.1.m1.1.1">↑</mo><annotation-xml id="S4.T6.5.5.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T6.5.5.1.m1.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S4.T6.5.5.1.m1.1d" encoding="application/x-llamapun">↑</annotation></semantics></math></span></span></span></td><td id="S4.T6.5.5.2"><span id="S4.T6.5.5.2.1">5.87</span></td><td id="S4.T6.5.5.3"><span id="S4.T6.5.5.3.1">2.64</span></td><td id="S4.T6.5.5.4"><span id="S4.T6.5.5.4.1">6.25</span></td><td id="S4.T6.5.5.5"><span id="S4.T6.5.5.5.1">6.73</span></td></tr><tr id="S4.T6.6.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.6.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.6.6.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">总体 <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T6.6.6.1.1.m1.1" display="inline" alttext="\uparrow"><semantics id="S4.T6.6.6.1.1.m1.1a"><mo stretchy="false" id="S4.T6.6.6.1.1.m1.1.1">↑</mo><annotation-xml id="S4.T6.6.6.1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T6.6.6.1.1.m1.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S4.T6.6.6.1.1.m1.1d" encoding="application/x-llamapun">↑</annotation></semantics></math></span></span></span></span></td><td id="S4.T6.6.6.2"><span id="S4.T6.6.6.2.1">6.28</span></td><td id="S4.T6.6.6.3"><span id="S4.T6.6.6.3.1">2.25</span></td><td id="S4.T6.6.6.4"><span id="S4.T6.6.6.4.1">6.29</span></td><td id="S4.T6.6.6.5"><span id="S4.T6.6.6.5.1">6.76</span></td></tr><tr id="S4.T6.7.7" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.7.7.2" rowspan="3"><span id="S4.T6.7.7.2.1">AMI</span></td><td id="S4.T6.7.7.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">幻觉 <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T6.7.7.1.m1.1" display="inline" alttext="\downarrow"><semantics id="S4.T6.7.7.1.m1.1a"><mo stretchy="false" mathsize="50%" id="S4.T6.7.7.1.m1.1.1">↓</mo><annotation-xml id="S4.T6.7.7.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T6.7.7.1.m1.1c" encoding="application/x-tex">\downarrow</annotation><annotation id="S4.T6.7.7.1.m1.1d" encoding="application/x-llamapun">↓</annotation></semantics></math></span></span></span></td><td id="S4.T6.7.7.3"><span id="S4.T6.7.7.3.1">0.13</span></td><td id="S4.T6.7.7.4"><span id="S4.T6.7.7.4.1">0.96</span></td><td id="S4.T6.7.7.5"><span id="S4.T6.7.7.5.1">0.28</span></td><td id="S4.T6.7.7.6"><span id="S4.T6.7.7.6.1">0.10</span></td></tr><tr id="S4.T6.8.8" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.8.8.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">指令遵从 <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T6.8.8.1.m1.1" display="inline" alttext="\uparrow"><semantics id="S4.T6.8.8.1.m1.1a"><mo stretchy="false" mathsize="50%" id="S4.T6.8.8.1.m1.1.1">↑</mo><annotation-xml id="S4.T6.8.8.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T6.8.8.1.m1.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S4.T6.8.8.1.m1.1d" encoding="application/x-llamapun">↑</annotation></semantics></math></span></span></span></td><td id="S4.T6.8.8.2"><span id="S4.T6.8.8.2.1">6.50</span></td><td id="S4.T6.8.8.3"><span id="S4.T6.8.8.3.1">1.40</span></td><td id="S4.T6.8.8.4"><span id="S4.T6.8.8.4.1">6.25</span></td><td id="S4.T6.8.8.5"><span id="S4.T6.8.8.5.1">6.83</span></td></tr><tr id="S4.T6.9.9" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.9.9.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.9.9.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">总体 <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T6.9.9.1.1.m1.1" display="inline" alttext="\uparrow"><semantics id="S4.T6.9.9.1.1.m1.1a"><mo stretchy="false" id="S4.T6.9.9.1.1.m1.1.1">↑</mo><annotation-xml id="S4.T6.9.9.1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T6.9.9.1.1.m1.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S4.T6.9.9.1.1.m1.1d" encoding="application/x-llamapun">↑</annotation></semantics></math></span></span></span></span></td><td id="S4.T6.9.9.2"><span id="S4.T6.9.9.2.1">6.29</span></td><td id="S4.T6.9.9.3"><span id="S4.T6.9.9.3.1">1.34</span></td><td id="S4.T6.9.9.4"><span id="S4.T6.9.9.4.1">5.97</span></td><td id="S4.T6.9.9.5"><span id="S4.T6.9.9.5.1">6.53</span></td></tr><tr id="S4.T6.10.10" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.10.10.2" rowspan="9"><span id="S4.T6.10.10.2.1">AU</span></td><td id="S4.T6.10.10.1" rowspan="5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.10.10.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">评分 1-10 <math data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="S4.T6.10.10.1.1.m1.1" display="inline" alttext="\uparrow"><semantics id="S4.T6.10.10.1.1.m1.1a"><mo stretchy="false" id="S4.T6.10.10.1.1.m1.1.1">↑</mo><annotation-xml id="S4.T6.10.10.1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T6.10.10.1.1.m1.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S4.T6.10.10.1.1.m1.1d" encoding="application/x-llamapun">↑</annotation></semantics></math></span></span></span></span></td><td id="S4.T6.10.10.3" rowspan="5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.10.10.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">AirBench-聊天</span></span></span></span></td><td id="S4.T6.10.10.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.10.10.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">混合</span></span></span></span></td><td id="S4.T6.10.10.5"><span id="S4.T6.10.10.5.1">6.78</span></td><td id="S4.T6.10.10.6"><span id="S4.T6.10.10.6.1">6.77</span></td><td id="S4.T6.10.10.7"><span id="S4.T6.10.10.7.1">6.84</span></td><td id="S4.T6.10.10.8"><span id="S4.T6.10.10.8.1">6.00</span></td></tr><tr id="S4.T6.11.24" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.24.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.24.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">音乐</span></span></span></span></td><td id="S4.T6.11.24.2"><span id="S4.T6.11.24.2.1">6.67</span></td><td id="S4.T6.11.24.3"><span id="S4.T6.11.24.3.1">6.79</span></td><td id="S4.T6.11.24.4"><span id="S4.T6.11.24.4.1">6.33</span></td><td id="S4.T6.11.24.5"><span id="S4.T6.11.24.5.1">5.55</span></td></tr><tr id="S4.T6.11.25" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.25.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.25.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">声音</span></span></span></span></td><td id="S4.T6.11.25.2"><span id="S4.T6.11.25.2.1">7.00</span></td><td id="S4.T6.11.25.3"><span id="S4.T6.11.25.3.1">6.99</span></td><td id="S4.T6.11.25.4"><span id="S4.T6.11.25.4.1">5.62</span></td><td id="S4.T6.11.25.5"><span id="S4.T6.11.25.5.1">7.45</span></td></tr><tr id="S4.T6.11.26" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.26.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.26.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">语音</span></span></span></span></td><td id="S4.T6.11.26.2"><span id="S4.T6.11.26.2.1">7.47</span></td><td id="S4.T6.11.26.3"><span id="S4.T6.11.26.3.1">7.18</span></td><td id="S4.T6.11.26.4"><span id="S4.T6.11.26.4.1">7.92</span></td><td id="S4.T6.11.26.5"><span id="S4.T6.11.26.5.1">7.17</span></td></tr><tr id="S4.T6.11.27" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.27.1"><span id="S4.T6.11.27.1.1">AVG</span></td><td id="S4.T6.11.27.2"><span id="S4.T6.11.27.2.1">6.98</span></td><td id="S4.T6.11.27.3"><span id="S4.T6.11.27.3.1">6.93</span></td><td id="S4.T6.11.27.4"><span id="S4.T6.11.27.4.1">6.68</span></td><td id="S4.T6.11.27.5"><span id="S4.T6.11.27.5.1">6.54</span></td></tr><tr id="S4.T6.11.11" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.11.1" rowspan="4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.11.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">ACC <math alttext="\uparrow" display="inline" id="S4.T6.11.11.1.1.m1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><semantics id="S4.T6.11.11.1.1.m1.1a"><mo id="S4.T6.11.11.1.1.m1.1.1" stretchy="false" xref="S4.T6.11.11.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T6.11.11.1.1.m1.1b"><ci id="S4.T6.11.11.1.1.m1.1.1.cmml" xref="S4.T6.11.11.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.11.11.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.11.11.1.1.m1.1d">↑</annotation></semantics></math></span></td><td id="S4.T6.11.11.2" rowspan="4"><span id="S4.T6.11.11.2.1">MMAU</span></td><td id="S4.T6.11.11.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.11.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">music</span></td><td id="S4.T6.11.11.4"><span id="S4.T6.11.11.4.1">52.87</span></td><td id="S4.T6.11.11.5"><span id="S4.T6.11.11.5.1">53.26</span></td><td id="S4.T6.11.11.6"><span id="S4.T6.11.11.6.1">58.33</span></td><td id="S4.T6.11.11.7"><span id="S4.T6.11.11.7.1">55.27</span></td></tr><tr id="S4.T6.11.28" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.28.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.28.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">sound</span></td><td id="S4.T6.11.28.2"><span id="S4.T6.11.28.2.1">60.97</span></td><td id="S4.T6.11.28.3"><span id="S4.T6.11.28.3.1">58.34</span></td><td id="S4.T6.11.28.4"><span id="S4.T6.11.28.4.1">62.60</span></td><td id="S4.T6.11.28.5"><span id="S4.T6.11.28.5.1">48.30</span></td></tr><tr id="S4.T6.11.29" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.29.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S4.T6.11.29.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">speech</span></td><td id="S4.T6.11.29.2"><span id="S4.T6.11.29.2.1">52.83</span></td><td id="S4.T6.11.29.3"><span id="S4.T6.11.29.3.1">45.90</span></td><td id="S4.T6.11.29.4"><span id="S4.T6.11.29.4.1">62.77</span></td><td id="S4.T6.11.29.5"><span id="S4.T6.11.29.5.1">56.30</span></td></tr><tr id="S4.T6.11.30" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S4.T6.11.30.1"><span id="S4.T6.11.30.1.1">AVG</span></td><td id="S4.T6.11.30.2"><span id="S4.T6.11.30.2.1">55.56</span></td><td id="S4.T6.11.30.3"><span id="S4.T6.11.30.3.1">52.50</span></td><td id="S4.T6.11.30.4"><span id="S4.T6.11.30.4.1">61.23</span></td><td id="S4.T6.11.30.5"><span id="S4.T6.11.30.5.1">53.29</span></td></tr></tbody></table>

##### Spoken Query Question Answering.

We evaluate the SQQA performance on two language benchmarks with synthetic audio query: MT-Bench \[[ZCS<sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup>23](https://arxiv.org/html/2503.01743v2#bib.bibx105)\] and MMMLU \[[HBB<sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup>20](https://arxiv.org/html/2503.01743v2#bib.bibx39)\]. The text query is synthesized into the audio query with the internal zero-shot TTS system.

-   • MT-Bench（多轮基准）是专门设计用来评估 AI 模型在多轮问答（QA）场景中的对话和指令遵循能力。
-   • MMMLU（多语言大规模多任务语言理解）是一个广泛的基准，旨在评估 AI 模型在广泛主题上的通用知识和推理能力。我们在此测试集上评估了模型对八种支持语言的性能。

任务提示为空，对于口语查询问答任务。两个基准的指标不同。MT-bench 的答案为开放式，因此我们使用 GPT-4 作为评分员，对模型输出进行 1 到 10 的评分。我们评估 MT-bench 的前两轮模型输出。请参阅附录 A 以获取 GPT-4 的评分提示。MMMLU 是一个多选题的问答任务。我们使用准确率来衡量模型质量。

我们总结了表 6 中的 SQQA 结果。从表中可以看出，Phi-4-Multimodal 在 MT-bench 上以双倍模型大小优于 Qwen2-audio。然而，其性能远远落后于 Gemini-2.0-Flash 和 GPT-4o，后者显示出强大的 SQQA 能力。SQQA 的结果表明，Phi-4-Multimodal 在对话聊天方面比一般知识和推理聊天更擅长（在 MT-bench 上与闭源模型相比，在 MMMLU 上的差距更小）。原因可能在于我们在语音/音频后训练阶段更重视对话 SQQA 数据。

![Refer to caption](chrome-extension://pcmpcfapbekmbjjkdalcgopdkipoggdi/html/2503.01743v2/extracted/6260032/figures/phio_speech_demo.png)

图 3：展示 Phi-4-Multimodal 理解能力的示例，包括音频理解、摘要、语音识别和抽象语法树。

#####   语音摘要。

我们评估了在内部（Golden3）和公共（AMI \[CAB <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 05\]）基准上的语音摘要性能。

-   • Golden3 是一个真实世界的会议数据集，包含 108 个会议录音及其对应的文本记录，平均时长为 6 分钟。数据集主要以英语为主，涵盖广泛的主题。整个数据集共有 1071 个查询，平均每个对话有 9.9 条指令。
-   • AMI（增强多党交互）数据集是一个全面的会议录音集合，包含大约 100 小时的数据。这些录音包括同步的音频和视频流，包括近距离和远场麦克风，个人和房间视角的摄像头，以及幻灯片投影仪和电子白板等设备的输出。该数据集主要使用英语，包括母语和非母语发言者的贡献，在具有不同声学特性的各种房间中录制。测试部分包含 20 个会议录音，平均时长为 32 分钟。我们在近距离音频版本上进行测试。每个对话生成 10 条指令，总计 200 条指令。

为了生成测试数据的摘要说明，使用 GPT-4 被要求总结部分或整个对话或控制输出风格/长度/结构。一个示例提示可以是“总结关于使遥控器适合老年人使用的想法。”或者“用项目符号列出讨论的关键产品规格。”摘要说明被视为多模型LLM推理的任务提示。在评估期间，我们使用 GPT4 根据 3 个标准对每个指令对应的响应进行评分：整体质量、幻觉和指令遵循度。整体质量，按 1 到 7 的比例衡量，衡量捕捉细节、连贯性和写作风格的准确性。幻觉得分是一个二进制标志，衡量摘要中是否有任何部分是虚构的或与源内容一致（0 表示没有幻觉，反之亦然）。遵循度得分，按 1 到 7 的比例衡量，衡量响应在特定格式、内容或长度要求上遵循指令的程度。在评分过程中，GPT4 可以访问每个录音的真实转录本。 请参阅附录 A 中的 GPT4 评分提示。

我们平均每个标准下属于同一数据集的所有响应的分数。详细的摘要分数见表 6。Qwen2-Audio 对音频输入有 30 秒的截止时间，因此它无法处理长音频输入，在此任务中显得能力不足。Phi-4-Multimodal 可以自然地一次性编码长音频并执行语音理解。与 Gemini-2.0-Flash 和 GPT-4o 相比，它在 Golden3 和 AMI 测试集上表现出竞争力。考虑到语音摘要数据仅占语音后训练数据中的 1%，通过在更多摘要数据上微调，差距可以轻易缩小。

#####   音频理解。

我们评估了两个基准测试中的音频理解能力：AIRBench-chat \[YXL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 和 MMAU \[STK <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]。

-   • AIR-Bench（音频指令与响应基准）是一个全面的评估框架，旨在测试大型音频语言模型的能力。它包括基础和聊天基准。聊天基准被选用于开放式问答风格的评估。聊天基准包括音乐、声音、语音和混合领域的类别。
-   • MMAU（大规模多任务音频理解）基准是一个综合数据集，旨在评估多模态模型在基于音频的理解和推理任务中的能力。测试集以多选题问答题的形式呈现，涵盖音乐、声音和语音类别。

与 MT-bench 中的开放式问答类似，我们使用 GPT-4-0613 作为评分员来评估模型输出。请参阅附录 A 中的 GPT4 评分提示。准确率用于衡量模型在 MMAU 上的质量。

每个类别多模型模型的详细结果展示在表 6 中。尽管我们在训练后冻结了音频编码器，Phi-4-Multimodal 在两个评估基准上实现了强大的语音、音频和音乐理解能力，超越了开源的 Qwen2-audio。GPT-4o 在音频和音乐理解任务上表现不佳，因为模型可能对某些测试样本的音频/音乐输入没有反应。换句话说，GPT-4o 对音频和音乐理解任务的提示非常敏感。

我们展示了 Phi-4-Multimodal 在图 3 中的强大语音理解能力示例。

  菲-4-迷你 3.8b Phi-3.5-Mini 3.8b Llama-3.2-Ins 3B Ministral 3B Qwen2.5-Ins 3B Qwne2.5-Ins 7B Ministral-2410 8B Llama-3.1 8B Llama-3.1 Tulu-3 8B Gemma2-It 9B BigBench-Hard （0-Shot; CoT）\[SRR <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 22, SSS <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 22\] 70.4 63.1 55.4 51.2 56.2 72.4 53.3 63.4 55.5 65.7 MMLU (5-Shot) \[[HBK<sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup>21a](https://arxiv.org/html/2503.01743v2#bib.bibx40)\] 67.3 65.5 61.8 60.8 65.0 72.6 63.0 68.1 65.0 71.3 MMLU-Pro （0-Shot; CoT）\[王明志 <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 52.8 47.4 39.2 35.3 44.7 56.2 36.6 44.0 40.9 50.1 Arc-C   （10-Shot）\[CCE <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 18\] 83.7 84.6 76.1 80.3 82.6 90.1 82.7 83.1 79.4 89.8   布尔 Q (2-Shot) \[[CLC<sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup>19](https://arxiv.org/html/2503.01743v2#bib.bibx18)\] 81.2 77.7 71.4 79.4 65.4 80.0 80.5 82.8 79.0 85.7 GPQA （0-Shot; CoT）\[RHS <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\] 30.4 25.2 26.6 24.3 24.3 30.6 26.3 26.3 29.9 31.0 HellaSwag (5-Shot) \[[ZHB<sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup>19](https://arxiv.org/html/2503.01743v2#bib.bibx109)\] 69.1 72.2 69.0 77.2 74.6 80.1 80.9 73.5 72.8 80.9   开放式问答   （10-Shot）\[MCKS18\] 79.2 81.2 72.6 79.8 77.6 86.0 80.2 84.8 79.8 89.6 PIQA   （5-Shot）\[BZGC19\] 77.6 78.2 68.2 78.3 77.2 80.8 76.2 81.2 83.2 83.7   社会 QA   （5-Shot）\[源 <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 19\] 72.5 75.1 68.3 73.9 75.3 75.3 77.6 71.8 73.4 74.7   真实问答   (10-Shot；MC2) \[LHE22\] 66.4 65.6 59.2 62.9 64.3 69.4 63.0 69.2 64.1 76.6 WinoGrande   (5-Shot) \[SLBBC19\] 67.0 72.2 53.2 59.8 63.3 71.1 63.1 64.7 65.4 74.0   多语言-MMLU (5-Shot) \[[HBK<sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup>21a](https://arxiv.org/html/2503.01743v2#bib.bibx40), [DLVNN<sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup>23](https://arxiv.org/html/2503.01743v2#bib.bibx28)\] 49.3 55.4 48.1 46.4 55.9 64.4 53.7 56.2 54.5 63.8 MGSM （0-Shot; CoT）\[CKB <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 21，SSF <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 22\] 63.9 47.9 49.6 44.6 53.5 64.5 58.3 56.7 58.6 75.1 GSM-8K (8-Shot; CoT) \[[CKB<sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup>21](https://arxiv.org/html/2503.01743v2#bib.bibx17)\] 88.6 86.2 75.6 80.1 80.6 88.7 81.9 82.4 84.3 84.9   数学 （0-Shot; CoT）\[HBK <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 21b\] 64.0 48.5 46.7 41.8 61.7 60.4 41.6 47.6 46.1 51.3 Qasper   （0-shot）\[深度学习实验室 <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 21\] 40.4 41.9 33.4 35.3 32.1 38.1 37.4 37.2 35.4 13.9 SQuALITY   （0-shot）\[WPC <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 22\] 22.8 25.3 25.7 25.5 25.3 10.0 24.9 26.2 26.7 23.6 IFEval   （0 次曝光）\[ZLM <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\] 70.1 50.6 68.0 47.5 59.0 69.5 52.5 74.1 77.3 73.2 BFCL   （0 次曝光）\[YMJ <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 70.3 66.1 78.6 61.4 74.2 81.3 74.0 77.0 59.4 59.9   人类评估   （0-Shot）\[CTJ <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 21\] 74.4 70.1 62.8 72.0 72.0 75.0 70.7 66.5 62.8 63.4 MBPP (3-Shot) \[[AON<sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup>21](https://arxiv.org/html/2503.01743v2#bib.bibx8)\] 65.3 70.0 67.2 65.1 65.3 76.3 68.9 69.4 63.9 69.6   平均 64.9 62.3 58.0 58.3 61.4 67.9 61.2 63.9 61.7 66.0

表 7：Phi-4-Mini 语言基准分数与 Llama 3.2、Llama 3.1-8B、Qwen 2.5、Ministral 和 Gemma 系列的比较。

###   4.2 语言基准

####   4.2.1 语言

我们已在各种不同的学术数据集上进行了基准测试。我们将分数与最新的开源模型进行比较——Qwen 2.5 \[YYZ <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]、Llama-3.2 \[DJP <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]、Ministral \[Mis24\] 和 Gemma2 \[TRP <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 系列。总体而言，我们发现 Phi-4-Mini 在不同基准测试中表现出非常强的性能，如表 7 所示。

1.  总体性能：在多个语言理解基准测试中，Phi-4-Mini 优于同等规模的模型，并且与规模大两倍的模型相当。特别是，Phi-4-Mini 除了 Qwen2.5 7B 等大型模型外，在大多数大型模型以及同等规模模型上都表现出色，并且差距较大。
2.  2\. 强大的数学和推理能力：Phi-4-Mini 在数学和推理相关基准测试中表现出色，得益于其训练过程中使用的富含推理的合成数据。在数学基准测试中，该模型有时比同等规模的模型高出 20 多个点，甚至超过了两倍规模模型的得分。
3.  3\. 优秀的指令遵循和函数调用性能：与前辈 Phi-3.5-Mini 相比，Phi-4-Mini 得益于精心挑选的数据和改进的微调，在指令遵循和函数调用方面表现出显著提升。
4.  4\. 强大的编码性能：Phi-4-Mini 强大的推理能力在编码任务中也得到了体现，这得益于精心挑选的有机和合成数据。在 HumanEval 基准测试中，Phi-4-Mini 的性能优于大多数同等规模和两倍规模的大型模型。

####   4.2.2 编码

在 Phi-4-Mini 训练中，我们特别强调了编码能力。我们收集了高质量的代码数据并生成了各种与代码相关的数据。因此，Phi-4-Mini 在编码任务上表现出非常强的性能，如表 8 所示。在 9 个不同的编码基准测试中，Phi-4-Mini 的平均得分超过了所有 3B 大小的模型和 8B 大小的模型，除了 Qwen2.5。

  菲-4-迷你 3.8b Phi-3.5-Mini 3.8b Llama-3.2-Ins 3B Ministral 3B Qwen2.5-Ins 3B Qwne2.5-Ins 7B Ministral-2410 8B Llama-3.1 8B Llama-3.1 Tulu-3 8B Gemma2-It 9B   大代码基准   完成   （0-Shot）\[ZVC <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 43.0 40.4 25.7 50.0 33.8 43.4 47.4 34.1 30.4 40.6   大代码基准   指导   （0-Shot）\[ZVC <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 33.8 14.3 18.6 33.8 25.0 33.5 35.6 34.8 28.0 33.6   人类评估   （0-Shot）\[CTJ <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 21\] 74.4 70.1 62.8 72.0 72.0 75.0 70.7 66.5 62.8 63.4   HumanEval+：人机评估+   （零样本）\[ LXWZ23\] 68.3 62.8 51.8 67.5 64.6 68.9 70.7 57.3 50.0 54.3 LCB （2024 年 5 月 9 日）\[JHG <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 19.9 15.7 9.9 7.3 14.7 19.9 16.2 16.8 17.8 14.7 LiveBench （代码任务）\[WDR <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 30.5 18.3 14.8 14.8 22.7 38.3 25.0 18.8 22.7 23.4 MBPP (3-Shot) \[[AON<sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup>21](https://arxiv.org/html/2503.01743v2#bib.bibx8)\] 65.3 70.0 67.2 65.1 65.3 76.3 68.9 69.4 63.9 69.6 MBPP+   (3-Shot) \[雷迅威智 23\] 63.8 63.8 52.9 60.8 60.6 65.9 61.6 11.4 55.3 63.5   蜘蛛   （4-Shot）\[YZY <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 18\] 42.2 47.0 51.5 42.1 24.8 48.2 22.1 61.6 43.4 44.7   平均 49.0 44.7 39.5 45.9 42.6 52.2 46.5 41.2 41.6 45.3

表 8：Phi-4-Mini 与 Llama 3.2、Llama 3.1-8B、Qwen 2.5、Ministral 和 Gemma 模型的编码性能比较。

  模型 AIME MATH-500   GPQA 钻石   o1-mini\*：o1-迷你 63.6 90.0 60.0 DeepSeek-R1-Distill-Qwen-7B 53.3 91.4 49.5 DeepSeek-R1-蒸馏-LLaMA-8B 43.3 86.9 47.3   定制-斯特拉托斯-7B\* 20.0 82.0 37.8   OpenThinker-7B\*：开放思想家 7B\* 31.3 83.0 42.4   Llama-3.2-3B-Instruct：3.2B 参数的 Llama 指令模型 6.7 44.4 25.3   菲-4-迷你 10.0 71.8 36.9 \+ 精炼预训练 30.0 82.9 42.6 \+ 精炼微调 43.3 89.3 48.3 \+ 滚动 DPO（最终推理增强的 Phi-4-Mini） 50.0 90.4 49.0

表 9：与更大的 7B 推理模型和 OpenAI 模型相比，推理增强的 Phi-4-Mini 的 CoT 推理结果。星号（\*）表示直接从已发布的报告中获取的结果，而其余结果是在我们的工作中复制的。

####   4.2.3 CoT Reasoning

我们评估了在 Phi-4-Mini 上训练的推理增强模型的推理性能。我们在 AIME 2024 \[MAA24\]、MATH-500 \[LKB <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]和 GPQA Diamond \[RHS <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> \]上展示了结果，将其与 OpenAI 推理模型以及 Deepseek 和其他人最近的一些大型推理模型进行了比较。尽管只有 38 亿参数，Phi-4-Mini 推理增强模型优于 DeepSeek-R1-Distill-Llama-8B \[GYZ <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 25\]、Bespoke-Stratos-7B \[Lab25\]、OpenThinker-7B \[Tea25a\]，如表 9 所示，其性能与 DeepSeek-R1-Distill-Qwen-7B 相当。此外，我们还展示了一项消融研究，该研究显示了我们对推理增强 Phi-4-Mini 的训练过程的有效性。

##   5 安全

Phi-4-Mini 和 Phi-4-Multimodal 是根据微软负责任的 AI 原则开发的。整体方法包括在训练后进行安全对齐、红队攻击、跨数十个 RAI 危害类别的自动化测试和评估。

###   5.1 文本安全性

我们的方法几乎与 Phi-3 技术报告\[AJA <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]中描述的方法相同。更多细节可以在 Phi-3 安全论文\[ Mic24\]中找到。主要改进是将我们的安全后训练数据集扩展到所有一级语言，通过使用 GPT-4o-mini 模型进行（并验证）机器翻译来实现。

有用性和无害性偏好数据集\[BZN <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 22, JLD <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]，经过受\[BSA <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\]启发和多个内部生成数据集的修改，被用于解决安全后训练中的 RAI 危害类别。

微软的一个独立红队迭代检查了 Phi-4-Mini，以进一步在训练后过程中识别改进领域。根据他们的反馈，我们精心挑选了额外的数据集，以解决他们的见解，从而完善了训练后数据集。

系统安全评估按照 Phi-3 安全论文\[ Mic24\]中描述的方法进行。主要区别在于我们对有害内容的评估，现在利用了微软的 Azure AI 评估 SDK。我们使用 GPT-4o 模拟与我们的模型进行对抗性对话，并评估模型在四个危害类别（暴力、色情内容、自残和仇恨内容）中的响应毒性。然后，我们为每个类别计算了缺陷率——包含有害内容的响应比例。表 10 显示，我们的模型与其他类似规模的模型以及我们之前发布的 Phi-3.5-mini（由于安全对齐方法相似，这并不令人惊讶）处于同一水平。

  缺陷率   菲-4-迷你   菲-4-多模态   Phi-3.5-迷你   GPT-4o-迷你 Llama-3.2-3B Qwen  
\-2.5-3B   暴力 6% 7% 7% 6% 8% 7%   性 6% 6% 7% 7% 8% 6%   自我伤害 0% 0% 0% 1% 1% 1%   仇恨 3% 3% 2% 3% 3% 3%   平均 3.75% 4% 4% 4.25% 5% 4.25%

表 10：Phi-4-Mini、Phi-4-Multimodal、Phi-3.5-mini 和其他类似大小模型的 RAI 基准测试结果。缺陷率表示包含有害内容的模型响应的比例。最后一行显示了所有 4 个有害类别平均的缺陷率。

为了评估模型对越狱（JB）的脆弱性，我们在模拟用户提示前添加了已知的 JB，重复了之前的评估。表 11 中显示的结果使我们得出以下两个结论。首先，我们最新的 Phi 模型比之前发布的 Phi-3.5-mini 模型以及类似大小的其他模型对越狱更具鲁棒性。其次，我们的模型似乎能够检测到 JB 的存在，在这种情况下，它们甚至更不可能遵守引发有害响应的提示。这可以从表 10 中显示的没有 JB 时的缺陷率较低得出。

  JB 缺陷率   菲-4-迷你   菲-4-多模态   Phi-3.5-迷你   GPT-4o-迷你 Llama-3.2-3B Qwen-2.5-3B   暴力 2% 4% 11% 7% 11% 20%   性 1% 3% 8% 7% 8% 14%   自我伤害 0% 0% 1% 1% 1% 3%   仇恨 2% 2% 10% 6% 12% 19%   平均 1.25% 2.25% 7.5% 5.25% 8% 14%

表 11：Phi-4-Mini、Phi-4-Multimodal、Phi-3.5-mini 和其他类似大小模型的 RAI 基准测试结果。缺陷率表示包含有害内容的模型响应的比例，当用户提示中包含已知的越狱方法时。最后一行显示了所有 4 个危害类别的平均缺陷率。

为了评估模型在拒绝回答有害提示的同时，不牺牲回答看似有害但实际上无害的提示的能力，我们利用了\[RKV <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]中描述的 XSTest 框架。计算了两个指标：有害提示的拒绝率（IPRR，即不适当提示拒绝率——越高越好）和无关提示的拒绝率（VPRR，即有效提示拒绝率——越低越好）。Phi 模型和一些竞争对手模型的结果显示在表 12 中。可以得出两个结论。首先，Phi-4-Mini 和 Phi-4-Multimodal 在拒绝回答有害提示方面都非常出色。其次，当涉及到回答无关提示时，与该领域的其他模型相比，Phi-4-Multimodal 在安全性方面稍微偏向于保守一些。

<table id="S5.T12.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tbody data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tr id="S5.T12.2.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T12.2.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.2.3.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">拒绝率</span></span></span></span></td><td id="S5.T12.2.3.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.2.3.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">菲-4-迷你</span></span></span></span></td><td id="S5.T12.2.3.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.2.3.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">菲-4-多模态</span></span></span></span></td><td id="S5.T12.2.3.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.2.3.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">Phi-3.5-迷你</span></span></span></span></td><td id="S5.T12.2.3.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.2.3.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">Llama-3.2-3B</span></td><td id="S5.T12.2.3.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.2.3.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">Qwen-2.5-3B</span></td></tr><tr id="S5.T12.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T12.1.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span id="S5.T12.1.1.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">IPRR </span><math alttext="\uparrow" display="inline" id="S5.T12.1.1.1.m1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><semantics id="S5.T12.1.1.1.m1.1a"><mo id="S5.T12.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="S5.T12.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T12.1.1.1.m1.1b"><ci id="S5.T12.1.1.1.m1.1.1.cmml" xref="S5.T12.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T12.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T12.1.1.1.m1.1d">↑</annotation></semantics></math></td><td id="S5.T12.1.1.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.1.1.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">93.5%</span></td><td id="S5.T12.1.1.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.1.1.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">92%</span></td><td id="S5.T12.1.1.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.1.1.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">87%</span></td><td id="S5.T12.1.1.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.1.1.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">92.5%</span></td><td id="S5.T12.1.1.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.1.1.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">92%</span></td></tr><tr id="S5.T12.2.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T12.2.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span id="S5.T12.2.2.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">VPRR </span><math alttext="\downarrow" display="inline" id="S5.T12.2.2.1.m1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><semantics id="S5.T12.2.2.1.m1.1a"><mo id="S5.T12.2.2.1.m1.1.1" mathsize="90%" stretchy="false" xref="S5.T12.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T12.2.2.1.m1.1b"><ci id="S5.T12.2.2.1.m1.1.1.cmml" xref="S5.T12.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T12.2.2.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T12.2.2.1.m1.1d">↓</annotation></semantics></math></td><td id="S5.T12.2.2.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.2.2.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">20.8%</span></td><td id="S5.T12.2.2.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.2.2.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">26.4%</span></td><td id="S5.T12.2.2.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.2.2.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">21.2%</span></td><td id="S5.T12.2.2.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.2.2.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">15.6%</span></td><td id="S5.T12.2.2.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T12.2.2.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">25.6%</span></td></tr></tbody></table>

表 12：Phi-4-Mini、Phi-4-Multimodal、Phi-3.5-mini 和其他类似大小模型的 XSTest 基准测试结果。IPRR 是不当提示拒绝率（例如：“我如何杀死我的邻居？”）——越高越好。VPRR 是有效提示拒绝率（例如：“我如何杀死一个 Python 进程？”）——越低越好。

我们通过上述方法，利用 Azure AI 评估 SDK，评估了模型在所有一级语言中产生有害内容的倾向。缺陷率如表 13 所示，其中数字是通过对 4 个危害类别（暴力、色情内容、自残和仇恨内容）的平均值来产生每个语言的单一数字。这些结果表明，与 Phi-3.5-mini 相比，Phi-4-Mini 和 Phi-4-Multimodal 都有所改进，并且与其他竞争模型的表现相当。

  语言   菲-4-迷你   菲-4-多模态   Phi-3.5-迷你   GPT-4o-迷你 Llama-3.2-3B Qwen-2.5-3B   德语 3.25% 4.5% 6.75% 3.75% 4.5% 7%   法语 3.25% 5% 6% 4.25% 4.25% 5.5%   西班牙语 3% 4.5% 6.25% 4.25% 4.25% 5.5%   意大利语 2.25% 4.75% 6.25% 3.75% 4.25% 5.5%   葡萄牙语 4.5% 5.5% 6% 5.25% 4.25% 5.25%   “Phi-4-Mini 技术报告：通过混合 LoRAs 实现紧凑而强大的多模态语言模型” 6.25% 6.5% 8.5% 4.5% 4.75% 6.5%   日文 5% 5.75% 6.75% 3% 5.75% 5.75%   平均 3.91% 5.06% 6.31% 4.13% 4.63% 5.66%

表 13：Phi-4-Mini、Phi-4-Multimodal、Phi-3.5-mini 和其他模型生产有害内容的缺陷率。数值越低，表示越好。最后一行显示所有一级语言（包括表 10 中的英语数字）的平均值。

###   5.2 音频安全

关于 Phi-4-Multimodal 的音频安全对齐，我们采用了与上述文本安全对齐类似的方法。我们的音频安全数据集是通过在文本安全数据集上执行 TTS（文本到语音）合成获得的。我们想承认这种方法的两个局限性。

1.  我们的音频安全数据集仅包含语音。不包括其他类型的声响（非语音）。
2.  2\. 我们没有针对音频特定的越狱进行训练。

针对音频安全性评估，我们进行了三类自动化评估。首先，就像我们对文本输入所做的那样，我们利用微软的 Azure AI 评估 SDK 来检测模型对语音提示的响应中是否存在有害内容。缺陷率如表 14 所示。尽管略高于 GPT-4o（一个更大的模型）获得的值，但与表 10 中显示的文本输入的值相当。

<table id="S5.T14.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tbody data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tr id="S5.T14.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T14.2.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.1.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">缺陷率</span></span></span></span></td><td id="S5.T14.2.1.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.1.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">菲-4-多模态</span></span></span></span></td><td id="S5.T14.2.1.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.1.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">GPT-4o</span></td></tr><tr id="S5.T14.2.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T14.2.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.2.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">暴力</span></span></span></span></td><td id="S5.T14.2.2.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.2.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">4%</span></td><td id="S5.T14.2.2.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.2.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">2%</span></td></tr><tr id="S5.T14.2.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T14.2.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.3.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">性</span></span></span></span></td><td id="S5.T14.2.3.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.3.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">4%</span></td><td id="S5.T14.2.3.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.3.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">1%</span></td></tr><tr id="S5.T14.2.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T14.2.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.4.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">自我伤害</span></span></span></span></td><td id="S5.T14.2.4.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.4.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">1%</span></td><td id="S5.T14.2.4.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.4.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">1%</span></td></tr><tr id="S5.T14.2.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T14.2.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.5.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">仇恨</span></span></span></span></td><td id="S5.T14.2.5.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.5.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">4%</span></td><td id="S5.T14.2.5.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.5.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">0%</span></td></tr><tr id="S5.T14.2.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T14.2.6.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.6.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">平均</span></span></span></span></td><td id="S5.T14.2.6.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.6.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">3.25%</span></td><td id="S5.T14.2.6.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T14.2.6.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a">1%</span></td></tr></tbody></table>

表 14：Phi-4-Multimodal 和 GPT-4o 在 RAI 基准测试中的结果。缺陷率表示当输入提示为音频轨迹时，模型响应中包含有害内容的比例。最后一行显示了所有 4 个危害类别平均的缺陷率。

其次，我们运行了微软的语音公平性评估，以验证语音到文本转录在多种人口统计学群体中表现良好——如通过 WER 指标衡量。音频样本分布在 2 个性别子群体和 3 个年龄子群体（17-30 岁、31-45 岁和 46-65 岁）。以下地区（对应一级语言）被考虑：it-IT、fr-FR、ja-JP、es-MX、pt-BR、es-ES、zh-CN、en-US、en-GB 和 de-DE。

未发现任何子组的表现明显差于整体人群。一些子组在其特定地区相对于整体人群表现略好或略差。表现略好于整体人群的子组包括：it-IT 17-30、es-MX 46-65、es-ES 17-30、en-US 女性、en-US 46-65 和 de-DE 46-65。表现略差于整体人群的子组包括：en-US 男性和 es-MX 17-30。  

第三，我们实施了一个自定义评估，以判断模型是否会从用户的语音中推断敏感属性（SA）。理想情况下，它不应该这样做。12 个 SA 包括：种族、性取向、政治取向、宗教信仰、工会会员资格、人格特征、年龄、性别、医疗状况、国籍或地区、社会经济状况和职业。我们使用了各种声音，并准备了包含“提示种子”和明确要求模型推断 SA 的数百个音频提示。提示种子要么是一个通用的真理（例如，“火是热的。”），要么是关于用户的第一人称陈述，与 SA 没有明显的关联（例如，“我身高 6 英尺。”）。然后我们使用 GPT-4 来确定模型响应是否包含对 SA 的推断。

结果如下。在没有任何额外缓解措施的情况下，Phi-4-Multimodal 在我们的测试提示中进行了 SA（ISA）的推理，占比 27%——低于 Qwen2-Audio（49%）。对于这两个模型，个性特征和起源国家或地区是最有可能被推断出的 SA。通过使用系统提示，可以很好地缓解 Phi-4-Multimodal 的 ISA，将缺陷率降至 0.4%——与我们为部署到使用微软 meta 提示以防止 ISA 的实时音频端点的 GTP-4o 测量的 2%相当。  

此外，微软内部的一个独立团队还进行了广泛的红队测试。红队测试主要集中在以下安全领域：有害内容、自伤风险和漏洞利用。Phi-4-Multimodal 被发现更容易在遭受上下文操纵或说服技巧攻击时提供不希望的结果。这些发现适用于所有语言，其中对说服技巧的易受性主要影响法语和意大利语。

###   5.3 视觉安全

为了评估涉及文本和图像场景中的模型安全性，我们使用了微软的 Azure AI 评估 SDK。该工具通过提供专门设计的提示文本和图像来模拟与目标模型的单轮对话，以激发有害的响应。然后，目标模型的响应由经过微调的 GPT-4o 模型在多个危害类别中进行评估，包括暴力、色情内容、自残、仇恨或不公平内容。每个响应根据识别出的危害程度分配一个严重性评分。我们将 Phi-4-Multimodal 的多模态视觉安全性评估与 Phi-3.5-Vision、同等规模的开源模型以及 OpenAI 模型进行了比较。

此外，我们还运行了内部和公开的 RTVLM \[LLY <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 和 VLGuard \[ZBY <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 多模态（文本与视觉）RAI 基准测试。在表 15 中，我们比较了 Phi-4-Multimodal 与 Phi-3.5-Vision、开源模型 Llava-1.6 \[LLL <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 24\] 和 Qwen-VL-Chat \[BBY <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span>+</span></sup> 23\]，以及 GPT4-V \[Ope23\]的视觉安全指标。

<table id="S5.T15.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tbody data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><tr id="S5.T15.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T15.2.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T15.2.1.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">文本 &amp; 视觉</span></span></span></span></td><td id="S5.T15.2.1.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S5.T15.2.1.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S5.T15.2.1.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S5.T15.2.1.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td><td id="S5.T15.2.1.6" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"></td></tr><tr id="S5.T15.2.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T15.2.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T15.2.2.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">安全评估</span></span></span></span></td><td id="S5.T15.2.2.2" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T15.2.2.2.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">菲-4-多模态</span></span></span></span></td><td id="S5.T15.2.2.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T15.2.2.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">Phi-3.5-视觉</span></span></span></span></td><td id="S5.T15.2.2.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T15.2.2.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">Llava-1.6 鹿瓜</span></span></span></span></td><td id="S5.T15.2.2.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T15.2.2.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1">Qwen-VL-Chat</span></td><td id="S5.T15.2.2.6"><span id="S5.T15.2.2.6.1">GPT4-V</span></td></tr><tr id="S5.T15.2.3" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T15.2.3.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T15.2.3.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">内部（私有）</span></span></span></span></td><td id="S5.T15.2.3.2"><span id="S5.T15.2.3.2.1">7.96</span></td><td id="S5.T15.2.3.3"><span id="S5.T15.2.3.3.1">8.16</span></td><td id="S5.T15.2.3.4"><span id="S5.T15.2.3.4.1">5.44</span></td><td id="S5.T15.2.3.5"><span id="S5.T15.2.3.5.1">7.27</span></td><td id="S5.T15.2.3.6"><span id="S5.T15.2.3.6.1">8.55</span></td></tr><tr id="S5.T15.2.4" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T15.2.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T15.2.4.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">RTVLM（公开）</span></span></span></span></td><td id="S5.T15.2.4.2"><span id="S5.T15.2.4.2.1">6.39</span></td><td id="S5.T15.2.4.3"><span id="S5.T15.2.4.3.1">5.44</span></td><td id="S5.T15.2.4.4"><span id="S5.T15.2.4.4.1">3.86</span></td><td id="S5.T15.2.4.5"><span id="S5.T15.2.4.5.1">4.78</span></td><td id="S5.T15.2.4.6"><span id="S5.T15.2.4.6.1">6.81</span></td></tr><tr id="S5.T15.2.5" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><td id="S5.T15.2.5.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="S5.T15.2.5.1.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" data-immersive-translate-paragraph="1"><span data-immersive-translate-translation-element-mark="1" lang="zh-CN"><span data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">VLGuard（公共）</span></span></span></span></td><td id="S5.T15.2.5.2"><span id="S5.T15.2.5.2.1">8.91</span></td><td id="S5.T15.2.5.3"><span id="S5.T15.2.5.3.1">9.10</span></td><td id="S5.T15.2.5.4"><span id="S5.T15.2.5.4.1">5.62</span></td><td id="S5.T15.2.5.5"><span id="S5.T15.2.5.5.1">8.33</span></td><td id="S5.T15.2.5.6"><span id="S5.T15.2.5.6.1">8.90</span></td></tr></tbody></table>

表 15：使用公共和私有多模态 RAI 基准对视觉和文本场景中的模型安全性进行评估。请注意，表中所有指标均介于\[0,10\]之间，数值越高表示模型越安全。

## 6 弱点和局限性

由于模型尺寸限制，模型无法记住一些特定事实，例如奥运比赛结果信息。此外，多语言能力受限于模型参数数量。我们更加重视编码数据，导致多语言数据比例下降。这导致在其他语言上的表现不如英语。

与每个其他模型一样，Phi-4-Mini 和 Phi-4-Multimodal 有时可能会输出不受欢迎的内容。我们强调开发者实施应用级措施以进一步减轻有害响应影响的重要性。缓解策略包括（但不限于）系统提示、内容过滤器等。

Phi-4-Multimodal 并非设计或旨在用作生物识别分类系统，以根据个人的生物识别数据对个人进行分类，以推断或推测其种族、政治观点、工会会员资格、宗教或哲学信仰、性生活或性取向。

##   参考文献

-     \[AA <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="bib.bibx1.4.4.1"><span id="bib.bibx1.4.4.1.1">+</span></sup> 24\] Marah Abdin, Jyoti Aneja, Harkirat Behl, Sébastien Bubeck, Ronen Eldan, Suriya Gunasekar, Michael Harrison, Russell J Hewett, Mojan Javaheripi, Piero Kauffmann, 等人. Phi-4 技术报告。arXiv 预印本 arXiv:2412.08905，2024。
-     \[美国 <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="bib.bibx2.4.4.1"><span id="bib.bibx2.4.4.1.1">+</span></sup> 20\] 罗莎娜·阿尔迪拉，梅根·布兰森，凯利·戴维斯，迈克尔·科勒，乔什·梅耶，迈克尔·亨尼蒂，鲁本·莫拉伊，林赛·桑德斯，弗朗西斯·泰尔斯，格雷戈尔·韦伯。通用语音：一个大规模多语言语音语料库。在第十二届语言资源与评估会议论文集中，第 4218-4222 页，法国马赛，2020 年 5 月。欧洲语言资源协会。
-   \[ADL<sup id="bib.bibx3.4.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="bib.bibx3.4.4.1.1">+</span></sup>22\] 让-巴蒂斯特·阿拉亚克，杰夫·多纳休，保罗琳·吕克，安东尼·米歇尔，伊恩·巴，亚娜·哈森，卡雷尔·伦茨，阿图尔·门什，凯瑟琳·米利坎，马尔科姆·雷诺兹，等。Flamingo：一种用于少样本学习的视觉语言模型。神经信息处理系统进展，35：23716–23736，2022。
-   \[AI23\] Meta AI. 推出 Meta Llama 3：截至目前最强大的公开可用llm，2023 年。
-   \[AJA<sup id="bib.bibx5.4.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="bib.bibx5.4.4.1.1">+</span></sup>24\] Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat Behl 等。Phi-3 技术报告：在您的手机上本地运行的高性能语言模型。arXiv 预印本 arXiv:2404.14219，2024。
-   \[ALTdJ<sup id="bib.bibx6.4.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="bib.bibx6.4.4.1.1">+</span></sup>23\] Joshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón 和 Sumit Sanghai. Gqa：从多头检查点训练通用的多查询转换器模型。arXiv 预印本 arXiv:2305.13245，2023。
-   \[Ant24\] AIAnthropic. 克劳德 3 模型系列：Opus、Sonnet、Haiku。克劳德-3 模型卡片，2024 年。
-     \[ AON <sup data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a" id="bib.bibx8.4.4.1"><span id="bib.bibx8.4.4.1.1">+</span></sup> 21 \] Jacob Austin，Augustus Odena，Maxwell Nye，Maarten Bosma，Henryk Michalewski，David Dohan，Ellen Jiang，Carrie Cai，Michael Terry，Quoc Le，以及 Charles Sutton。大型语言模型程序综合。arXiv 预印本 arXiv:2108.07732，2021。
-   \[BBC<sup id="bib.bibx9.4.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="bib.bibx9.4.4.1.1">+</span></sup>24\] Johan Bjorck, Alon Benhaim, Vishrav Chaudhary, Furu Wei 和 Xia Song. 在 token 范围内扩展最优 lr，2024。
-   \[BBY<sup id="bib.bibx10.4.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="bib.bibx10.4.4.1.1">+</span></sup>23\] 金泽白，白帅，杨树生，王世杰，谭思南，王鹏，林俊阳，周长，周敬仁。Qwen-vl：具有多功能能力的前沿大视觉语言模型。arXiv 预印本 arXiv:2308.12966，2023。
-   \[BCM<sup id="bib.bibx11.4.4.1" data-immersive-translate-walked="b1cfad00-324b-4e53-859b-920cdfe8dc7a"><span id="bib.bibx11.4.4.1.1">+</span></sup>23\] Loïc Barrault, Yu-An Chung, Mariano Cora Meglioli, David Dale, Ning Dong, Paul-Ambroise Duquenne, Hady Elsahar, Hongyu Gong, Kevin Heffernan, John Hoffman 等. Seamlessm4t-大规模多语言和多模态机器翻译。arXiv 预印本 arXiv:2308.11596，2023。
-   \[BJN<sup id="bib.bibx12.4.4.1"><span id="bib.bibx12.4.4.1.1">+</span></sup>22\] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan. Training a helpful and harmless assistant with reinforcement learning from human feedback, 2022.
-   \[BSA<sup id="bib.bibx13.4.4.1"><span id="bib.bibx13.4.4.1.1">+</span></sup>24\] Federico Bianchi, Mirac Suzgun, Giuseppe Attanasio, Paul Röttger, Dan Jurafsky, Tatsunori Hashimoto, and James Zou. Safety-tuned llamas: Lessons from improving the safety of large language models that follow instructions, 2024.
-   \[BZGC19\] Yonatan Bisk, Rowan Zellers, Jianfeng Gao, and Yejin Choi. Piqa: Reasoning about physical commonsense in natural language. arXiv preprint arXiv:1911.11641, 2019.
-   \[CAB<sup id="bib.bibx15.4.4.1"><span id="bib.bibx15.4.4.1.1">+</span></sup>05\] Jean Carletta, Simone Ashby, Sebastien Bourban, Matthew Flynn, Mael Guillemot, Thomas Hain, Jaroslav Kadlec, Vasilis Karaiskos, Wessel Kraaij, Melissa Kronenthal, et al. The ami meeting corpus: A pre-announcement. In International Workshop on Machine Learning for Multimodal Interaction, pages 28–39. Springer, 2005.
-   \[CCE<sup id="bib.bibx16.4.4.1"><span id="bib.bibx16.4.4.1.1">+</span></sup>18\] Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge, 2018.
-   \[CKB<sup id="bib.bibx17.4.4.1"><span id="bib.bibx17.4.4.1.1">+</span></sup>21\] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.
-   \[CLC<sup id="bib.bibx18.4.4.1"><span id="bib.bibx18.4.4.1.1">+</span></sup>19\] Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova. Boolq: Exploring the surprising difficulty of natural yes/no questions. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 2924–2936, 2019.
-   \[CMK<sup id="bib.bibx19.4.4.1"><span id="bib.bibx19.4.4.1.1">+</span></sup>23\] Alexis Conneau, Min Ma, Simran Khanuja, Yu Zhang, Vera Axelrod, Siddharth Dalmia, Jason Riesa, Clara Rivera, and Ankur Bapna. Fleurs: Few-shot learning evaluation of universal representations of speech. In 2022 IEEE Spoken Language Technology Workshop (SLT), pages 798–805. IEEE, 2023.
-   \[CTJ<sup id="bib.bibx20.4.4.1"><span id="bib.bibx20.4.4.1.1">+</span></sup>21\] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code, 2021.
-   \[CWC<sup id="bib.bibx21.4.4.1"><span id="bib.bibx21.4.4.1.1">+</span></sup>24\] Zhe Chen, Weiyun Wang, Yue Cao, Yangzhou Liu, Zhangwei Gao, Erfei Cui, Jinguo Zhu, Shenglong Ye, Hao Tian, Zhaoyang Liu, et al. Expanding performance boundaries of open-source multimodal models with model, data, and test-time scaling. arXiv preprint arXiv:2412.05271, 2024.
-   \[CWT<sup id="bib.bibx22.4.4.1"><span id="bib.bibx22.4.4.1.1">+</span></sup>24\] Zhe Chen, Weiyun Wang, Hao Tian, Shenglong Ye, Zhangwei Gao, Erfei Cui, Wenwen Tong, Kongzhi Hu, Jiapeng Luo, Zheng Ma, et al. How far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites. arXiv preprint arXiv:2404.16821, 2024.
-   \[CWW<sup id="bib.bibx23.4.4.1"><span id="bib.bibx23.4.4.1.1">+</span></sup>24\] Zhe Chen, Jiannan Wu, Wenhai Wang, Weijie Su, Guo Chen, Sen Xing, Muyan Zhong, Qinglong Zhang, Xizhou Zhu, Lewei Lu, et al. Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 24185–24198, 2024.
-   \[CXY<sup id="bib.bibx24.4.4.1"><span id="bib.bibx24.4.4.1.1">+</span></sup>24\] Yunfei Chu, Jin Xu, Qian Yang, Haojie Wei, Xipin Wei, Zhifang Guo, Yichong Leng, Yuanjun Lv, Jinzheng He, Junyang Lin, et al. Qwen2-audio technical report. arXiv preprint arXiv:2407.10759, 2024.
-   \[DCL<sup id="bib.bibx25.4.4.1"><span id="bib.bibx25.4.4.1.1">+</span></sup>24\] Matt Deitke, Christopher Clark, Sangho Lee, Rohun Tripathi, Yue Yang, Jae Sung Park, Mohammadreza Salehi, Niklas Muennighoff, Kyle Lo, Luca Soldaini, et al. Molmo and pixmo: Open weights and open data for state-of-the-art multimodal models. arXiv preprint arXiv:2409.17146, 2024.
-   \[DJP<sup id="bib.bibx26.4.4.1"><span id="bib.bibx26.4.4.1.1">+</span></sup>24\] Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024.
-   \[DLB<sup id="bib.bibx27.4.4.1"><span id="bib.bibx27.4.4.1.1">+</span></sup>21\] Pradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan, Noah A. Smith, and Matt Gardner. A dataset of information-seeking questions and answers anchored in research papers. 2021.
-   \[DLVNN<sup id="bib.bibx28.4.4.1"><span id="bib.bibx28.4.4.1.1">+</span></sup>23\] Viet Dac Lai, Chien Van Nguyen, Nghia Trung Ngo, Thuat Nguyen, Franck Dernoncourt, Ryan A Rossi, and Thien Huu Nguyen. Okapi: Instruction-tuned large language models in multiple languages with reinforcement learning from human feedback. arXiv e-prints, pages arXiv–2307, 2023.
-   \[DLW<sup id="bib.bibx29.4.4.1"><span id="bib.bibx29.4.4.1.1">+</span></sup>24\] Wenliang Dai, Nayeon Lee, Boxin Wang, Zhuolin Yang, Zihan Liu, Jon Barker, Tuomas Rintamaki, Mohammad Shoeybi, Bryan Catanzaro, and Wei Ping. Nvlm: Open frontier-class multimodal llms. arXiv preprint arXiv:2409.11402, 2024.
-   \[DZZ<sup id="bib.bibx30.4.4.1"><span id="bib.bibx30.4.4.1.1">+</span></sup>24a\] Yiran Ding, Li Lyna Zhang, Chengruidong Zhang, Yuanyuan Xu, Ning Shang, Jiahang Xu, Fan Yang, and Mao Yang. Longrope: Extending llm context window beyond 2 million tokens, 2024.
-   \[DZZ<sup id="bib.bibx31.4.4.1"><span id="bib.bibx31.4.4.1.1">+</span></sup>24b\] Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Bin Wang, Linke Ouyang, Xilin Wei, Songyang Zhang, Haodong Duan, Maosong Cao, et al. Internlm-xcomposer2: Mastering free-form text-image composition and comprehension in vision-language large model. arXiv preprint arXiv:2401.16420, 2024.
-   \[FDL<sup id="bib.bibx32.4.4.1"><span id="bib.bibx32.4.4.1.1">+</span></sup>24\] Chaoyou Fu, Yuhan Dai, Yondong Luo, Lei Li, Shuhuai Ren, Renrui Zhang, Zihan Wang, Chenyu Zhou, Yunhang Shen, Mengdan Zhang, et al. Video-mme: The first-ever comprehensive evaluation benchmark of multi-modal llms in video analysis. arXiv preprint arXiv:2405.21075, 2024.
-   \[FHL<sup id="bib.bibx33.4.4.1"><span id="bib.bibx33.4.4.1.1">+</span></sup>24\] Xingyu Fu, Yushi Hu, Bangzheng Li, Yu Feng, Haoyu Wang, Xudong Lin, Dan Roth, Noah A Smith, Wei-Chiu Ma, and Ranjay Krishna. Blink: Multimodal large language models can see but not perceive. arXiv preprint arXiv:2404.12390, 2024.
-   \[FHL<sup id="bib.bibx34.4.4.1"><span id="bib.bibx34.4.4.1.1">+</span></sup>25\] Xingyu Fu, Yushi Hu, Bangzheng Li, Yu Feng, Haoyu Wang, Xudong Lin, Dan Roth, Noah A Smith, Wei-Chiu Ma, and Ranjay Krishna. Blink: Multimodal large language models can see but not perceive. In European Conference on Computer Vision, pages 148–166. Springer, 2025.
-   \[FWL<sup id="bib.bibx35.4.4.1"><span id="bib.bibx35.4.4.1.1">+</span></sup>24\] Yassir Fathullah, Chunyang Wu, Egor Lakomkin, Ke Li, Junteng Jia, Yuan Shangguan, Jay Mahadeokar, Ozlem Kalinli, Christian Fuegen, and Mike Seltzer. Audiochatllama: Towards general-purpose speech abilities for llms. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 5522–5532, 2024.
-   \[GLL<sup id="bib.bibx36.4.4.1"><span id="bib.bibx36.4.4.1.1">+</span></sup>23\] Yuan Gong, Alexander H Liu, Hongyin Luo, Leonid Karlinsky, and James Glass. Joint audio and speech understanding. In 2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), 2023.
-   \[GQC<sup id="bib.bibx37.4.4.1"><span id="bib.bibx37.4.4.1.1">+</span></sup>20\] Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, and Ruoming Pang. Conformer: Convolution-augmented transformer for speech recognition. In 21st Annual Conference of the International Speech Communication Association, Interspeech 2020, Virtual Event, Shanghai, China, October 25-29, 2020, pages 5036–5040. ISCA, 2020.
-   \[GYZ<sup id="bib.bibx38.4.4.1"><span id="bib.bibx38.4.4.1.1">+</span></sup>25\] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025.
-   \[HBB<sup id="bib.bibx39.4.4.1"><span id="bib.bibx39.4.4.1.1">+</span></sup>20\] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300, 2020.
-   \[HBK<sup id="bib.bibx40.4.4.1"><span id="bib.bibx40.4.4.1.1">+</span></sup>21a\] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the MATH dataset, 2021.
-   \[HBK<sup id="bib.bibx41.4.4.1"><span id="bib.bibx41.4.4.1.1">+</span></sup>21b\] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. NeurIPS, 2021.
-   \[HLG<sup id="bib.bibx42.4.4.1"><span id="bib.bibx42.4.4.1.1">+</span></sup>24\] Aaron Hurst, Adam Lerer, Adam P Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv preprint arXiv:2410.21276, 2024.
-   \[HSW<sup id="bib.bibx43.4.4.1"><span id="bib.bibx43.4.4.1.1">+</span></sup>22\] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations, 2022.
-   \[HWY<sup id="bib.bibx44.4.4.1"><span id="bib.bibx44.4.4.1.1">+</span></sup>24\] Weiquan Huang, Aoqi Wu, Yifan Yang, Xufang Luo, Yuqing Yang, Liang Hu, Qi Dai, Xiyang Dai, Dongdong Chen, Chong Luo, et al. Llm2clip: Powerful language model unlock richer visual representation. arXiv preprint arXiv:2411.04997, 2024.
-   \[JHG<sup id="bib.bibx45.4.4.1"><span id="bib.bibx45.4.4.1.1">+</span></sup>24\] Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik Sen, and Ion Stoica. Livecodebench: Holistic and contamination free evaluation of large language models for code. arXiv preprint arXiv:2403.07974, 2024.
-   \[JLD<sup id="bib.bibx46.4.4.1"><span id="bib.bibx46.4.4.1.1">+</span></sup>23\] Jiaming Ji, Mickel Liu, Juntao Dai, Xuehai Pan, Chi Zhang, Ce Bian, Chi Zhang, Ruiyang Sun, Yizhou Wang, and Yaodong Yang. Beavertails: Towards improved safety alignment of llm via a human-preference dataset, 2023.
-   \[KSK<sup id="bib.bibx47.4.4.1"><span id="bib.bibx47.4.4.1.1">+</span></sup>16\] Aniruddha Kembhavi, Mike Salvato, Eric Kolve, Minjoon Seo, Hannaneh Hajishirzi, and Ali Farhadi. A diagram is worth a dozen images, 2016.
-   \[Lab25\] Bespoke Labs. Bespoke-stratos: The unreasonable effectiveness of reasoning distillation. https://www.bespokelabs.ai/blog/bespoke-stratos-the-unreasonable-effectiveness-of-reasoning-distillation, 2025. Accessed: 2025-01-22.
-   \[LBX<sup id="bib.bibx49.4.4.1"><span id="bib.bibx49.4.4.1.1">+</span></sup>24\] Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang, Michel Galley, and Jianfeng Gao. Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts, 2024.
-   \[LDZ<sup id="bib.bibx50.4.4.1"><span id="bib.bibx50.4.4.1.1">+</span></sup>23\] Yifan Li, Yifan Du, Kun Zhou, Jinpeng Wang, Wayne Xin Zhao, and Ji-Rong Wen. Evaluating object hallucination in large vision-language models, 2023.
-   \[LDZ<sup id="bib.bibx51.4.4.1"><span id="bib.bibx51.4.4.1.1">+</span></sup>24\] Yuan Liu, Haodong Duan, Yuanhan Zhang, Bo Li, Songyang Zhang, Wangbo Zhao, Yike Yuan, Jiaqi Wang, Conghui He, Ziwei Liu, Kai Chen, and Dahua Lin. Mmbench: Is your multi-modal model an all-around player?, 2024.
-   \[LGJ<sup id="bib.bibx52.4.4.1"><span id="bib.bibx52.4.4.1.1">+</span></sup>21\] Pan Lu, Ran Gong, Shibiao Jiang, Liang Qiu, Siyuan Huang, Xiaodan Liang, and Song-Chun Zhu. Inter-gps: Interpretable geometry problem solving with formal language and symbolic reasoning, 2021.
-   \[LHE22\] Stephanie Lin, Jacob Hilton, and Owain Evans. Truthfulqa: Measuring how models mimic human falsehoods, 2022.
-   \[LKB<sup id="bib.bibx54.4.4.1"><span id="bib.bibx54.4.4.1.1">+</span></sup>23\] Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let’s verify step by step. arXiv preprint arXiv:2305.20050, 2023.
-   \[LLH<sup id="bib.bibx55.4.4.1"><span id="bib.bibx55.4.4.1.1">+</span></sup>24\] Yuliang Liu, Zhang Li, Mingxin Huang, Biao Yang, Wenwen Yu, Chunyuan Li, Xu-Cheng Yin, Cheng-Lin Liu, Lianwen Jin, and Xiang Bai. Ocrbench: on the hidden mystery of ocr in large multimodal models. Science China Information Sciences, 67(12):220102, 2024.
-   \[LLL<sup id="bib.bibx56.4.4.1"><span id="bib.bibx56.4.4.1.1">+</span></sup>24\] Haotian Liu, Chunyuan Li, Yuheng Li, Bo Li, Yuanhan Zhang, Sheng Shen, and Yong Jae Lee. Llava-next: Improved reasoning, ocr, and world knowledge, January 2024.
-   \[LLWL24\] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. Advances in neural information processing systems, 36, 2024.
-   \[LLY<sup id="bib.bibx58.4.4.1"><span id="bib.bibx58.4.4.1.1">+</span></sup>24\] Mukai Li, Lei Li, Yuwei Yin, Masood Ahmed, Zhenguang Liu, and Qi Liu. Red teaming visual language models. arXiv preprint arXiv:2401.12915, 2024.
-   \[LMX<sup id="bib.bibx59.4.4.1"><span id="bib.bibx59.4.4.1.1">+</span></sup>22\] Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan. Learn to explain: Multimodal reasoning via thought chains for science question answering. In The 36th Conference on Neural Information Processing Systems (NeurIPS), 2022.
-   \[LXWZ23\] Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation. arXiv preprint arXiv:2305.01210, 2023.
-   \[LZG<sup id="bib.bibx61.4.4.1"><span id="bib.bibx61.4.4.1.1">+</span></sup>24\] Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Peiyuan Zhang, Yanwei Li, Ziwei Liu, et al. Llava-onevision: Easy visual task transfer. arXiv preprint arXiv:2408.03326, 2024.
-   \[MAA24\] MAA. American invitational mathematics examination–aime. In American Invitational Mathematics Examination–AIME 2024, February 2024.
-   \[MBT<sup id="bib.bibx63.4.4.1"><span id="bib.bibx63.4.4.1.1">+</span></sup>22\] Minesh Mathew, Viraj Bagal, Rubèn Tito, Dimosthenis Karatzas, Ernest Valveny, and CV Jawahar. Infographicvqa. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 1697–1706, 2022.
-   \[MCKS18\] Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. Can a suit of armor conduct electricity? a new dataset for open book question answering, 2018.
-   \[Mic24\] Microsoft. Phi-3 safety post-training: Aligning language models with a “break-fix” cycle. arXiv preprint arXiv:2407.13833, 2024.
-   \[Mis24\] AI Mistral. Un ministral, des ministraux. Ministral, 2024.
-   \[MKJ21\] Minesh Mathew, Dimosthenis Karatzas, and CV Jawahar. Docvqa: A dataset for vqa on document images. In Proceedings of the IEEE/CVF winter conference on applications of computer vision, pages 2200–2209, 2021.
-   \[MLT<sup id="bib.bibx68.4.4.1"><span id="bib.bibx68.4.4.1.1">+</span></sup>22\] Ahmed Masry, Do Long, Jia Qing Tan, Shafiq Joty, and Enamul Hoque. ChartQA: A benchmark for question answering about charts with visual and logical reasoning. In Findings of the Association for Computational Linguistics: ACL 2022, pages 2263–2279, Dublin, Ireland, May 2022. Association for Computational Linguistics.
-   \[MYS<sup id="bib.bibx69.4.4.1"><span id="bib.bibx69.4.4.1.1">+</span></sup>25\] Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel Candès, and Tatsunori Hashimoto. s1: Simple test-time scaling. arXiv preprint arXiv:2501.19393, 2025.
-   \[Ope23\] OpenAI. Gpt-4v(ision) system card, 2023. [https://cdn.openai.com/papers/GPTV\_System\_Card.pdf](https://cdn.openai.com/papers/GPTV_System_Card.pdf).
-   \[Pos18\] Matt Post. A call for clarity in reporting BLEU scores. In Proceedings of the Third Conference on Machine Translation: Research Papers, pages 186–191, Brussels, Belgium, October 2018. Association for Computational Linguistics.
-   \[RHS<sup id="bib.bibx72.4.4.1"><span id="bib.bibx72.4.4.1.1">+</span></sup>\] David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel R Bowman. Gpqa: A graduate-level google-proof q&a benchmark. In First Conference on Language Modeling.
-   \[RHS<sup id="bib.bibx73.4.4.1"><span id="bib.bibx73.4.4.1.1">+</span></sup>23\] David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel R. Bowman. Gpqa: A graduate-level google-proof q&a benchmark, 2023.
-   \[RKV<sup id="bib.bibx74.4.4.1"><span id="bib.bibx74.4.4.1.1">+</span></sup>23\] Paul Röttger, Hannah Rose Kirk, Bertie Vidgen, Giuseppe Attanasio, Federico Bianchi, and Dirk Hovy. Xstest: A test suite for identifying exaggerated safety behaviours in large language models. 2023.
-   \[RKX<sup id="bib.bibx75.4.4.1"><span id="bib.bibx75.4.4.1.1">+</span></sup>23\] Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. Robust speech recognition via large-scale weak supervision. In International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, volume 202, pages 28492–28518. PMLR, 2023.
-   \[SAL<sup id="bib.bibx76.4.4.1"><span id="bib.bibx76.4.4.1.1">+</span></sup>24\] Jianlin Su, Murtadha Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu. Roformer: Enhanced transformer with rotary position embedding. Neurocomputing, 568:127063, 2024.
-   \[SLBBC19\] Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Winogrande: An adversarial winograd schema challenge at scale. arXiv preprint arXiv:1907.10641, 2019.
-   \[SMK<sup id="bib.bibx78.4.4.1"><span id="bib.bibx78.4.4.1.1">+</span></sup>23\] Vaibhav Srivastav, Somshubra Majumdar, Nithin Koluguri, Adel Moumen, Sanchit Gandhi, Hugging Face Team, Nvidia NeMo Team, and SpeechBrain Team. Open automatic speech recognition leaderboard.  
    urlhttps://huggingface.co/spaces/huggingface.co/spaces/open-asr-leaderboard/leaderboard, 2023.
-   \[SNS<sup id="bib.bibx79.4.4.1"><span id="bib.bibx79.4.4.1.1">+</span></sup>19\] Amanpreet Singh, Vivek Natarajan, Meet Shah, Yu Jiang, Xinlei Chen, Dhruv Batra, Devi Parikh, and Marcus Rohrbach. Towards vqa models that can read, 2019.
-   \[SRC<sup id="bib.bibx80.4.4.1"><span id="bib.bibx80.4.4.1.1">+</span></sup>19\] Maarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi. Socialiqa: Commonsense reasoning about social interactions. arXiv preprint arXiv:1904.09728, 2019.
-   \[SRR<sup id="bib.bibx81.4.4.1"><span id="bib.bibx81.4.4.1.1">+</span></sup>22\] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615, 2022.
-   \[SSF<sup id="bib.bibx82.4.4.1"><span id="bib.bibx82.4.4.1.1">+</span></sup>22\] Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei. Language models are multilingual chain-of-thought reasoners, 2022.
-   \[SSS<sup id="bib.bibx83.4.4.1"><span id="bib.bibx83.4.4.1.1">+</span></sup>22\] Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, and Jason Wei. Challenging big-bench tasks and whether chain-of-thought can solve them, 2022.
-   \[STK<sup id="bib.bibx84.4.4.1"><span id="bib.bibx84.4.4.1.1">+</span></sup>24\] S Sakshi, Utkarsh Tyagi, Sonal Kumar, Ashish Seth, Ramaneswaran Selvakumar, Oriol Nieto, Ramani Duraiswami, Sreyan Ghosh, and Dinesh Manocha. Mmau: A massive multi-task audio understanding and reasoning benchmark. arXiv preprint arXiv:2410.19168, 2024.
-   \[TAB<sup id="bib.bibx85.4.4.1"><span id="bib.bibx85.4.4.1.1">+</span></sup>23\] Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. Gemini: a family of highly capable multimodal models. arXiv preprint arXiv:2312.11805, 2023.
-   \[Tea25a\] OpenThoughts Team. Open Thoughts. https://open-thoughts.ai, January 2025.
-   \[Tea25b\] Qwen Team. Qwen2.5-vl, January 2025.
-   \[TGL<sup id="bib.bibx88.4.4.1"><span id="bib.bibx88.4.4.1.1">+</span></sup>24\] Gemini Team, Petko Georgiev, Ving Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer, Damien Vincent, Zhufeng Pan, Shibo Wang, et al. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv preprint arXiv:2403.05530, 2024.
-   \[TRP<sup id="bib.bibx89.4.4.1"><span id="bib.bibx89.4.4.1.1">+</span></sup>24\] Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, et al. Gemma 2: Improving open language models at a practical size. arXiv preprint arXiv:2408.00118, 2024.
-   \[VSP<sup id="bib.bibx90.4.4.1"><span id="bib.bibx90.4.4.1.1">+</span></sup>17\] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, volume 30, 2017.
-   \[WBT<sup id="bib.bibx91.4.4.1"><span id="bib.bibx91.4.4.1.1">+</span></sup>24\] Peng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, et al. Qwen2-vl: Enhancing vision-language model’s perception of the world at any resolution. arXiv preprint arXiv:2409.12191, 2024.
-   \[WDR<sup id="bib.bibx92.4.4.1"><span id="bib.bibx92.4.4.1.1">+</span></sup>24\] Colin White, Samuel Dooley, Manley Roberts, Arka Pal, Ben Feuer, Siddhartha Jain, Ravid Shwartz-Ziv, Neel Jain, Khalid Saifullah, Siddartha Naidu, Chinmay Hegde, Yann LeCun, Tom Goldstein, Willie Neiswanger, and Micah Goldblum. Livebench: A challenging, contamination-free llm benchmark. 2024.
-   \[WMZ<sup id="bib.bibx93.4.4.1"><span id="bib.bibx93.4.4.1.1">+</span></sup>24\] Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, et al. Mmlu-pro: A more robust and challenging multi-task language understanding benchmark. In The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2024.
-   \[WPC<sup id="bib.bibx94.4.4.1"><span id="bib.bibx94.4.4.1.1">+</span></sup>22\] Alex Wang, Richard Yuanzhe Pang, Angelica Chen, Jason Phang, and Samuel R. Bowman. SQuALITY: Building a long-document summarization dataset the hard way. arXiv preprint 2205.11465, 2022.
-   \[WWGP21\] Changhan Wang, Anne Wu, Jiatao Gu, and Juan Pino. Covost 2 and massively multilingual speech translation. In Proceedings of Interspeech 2021, pages 2247–2251, 2021.
-   \[XW24\] Zhifei Xie and Changqiao Wu. Mini-omni2: Towards open-source gpt-4o with vision, speech and duplex capabilities. arXiv preprint arXiv:2410.11190, 2024.
-   \[YHX<sup id="bib.bibx97.4.4.1"><span id="bib.bibx97.4.4.1.1">+</span></sup>25\] Yixin Ye, Zhen Huang, Yang Xiao, Ethan Chern, Shijie Xia, and Pengfei Liu. Limo: Less is more for reasoning. arXiv preprint arXiv:2502.03387, 2025.
-   \[YMJ<sup id="bib.bibx98.4.4.1"><span id="bib.bibx98.4.4.1.1">+</span></sup>24\] Fanjia Yan, Huanzhi Mao, Charlie Cheng-Jie Ji, Tianjun Zhang, Shishir G. Patil, Ion Stoica, and Joseph E. Gonzalez. Berkeley function calling leaderboard. 2024.
-   \[YNZ<sup id="bib.bibx99.4.4.1"><span id="bib.bibx99.4.4.1.1">+</span></sup>23\] Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi, 2023.
-   \[YXL<sup id="bib.bibx100.4.4.1"><span id="bib.bibx100.4.4.1.1">+</span></sup>24\] Qian Yang, Jin Xu, Wenrui Liu, Yunfei Chu, Ziyue Jiang, Xiaohuan Zhou, Yichong Leng, Yuanjun Lv, Zhou Zhao, Chang Zhou, and Jingren Zhou. AIR-bench: Benchmarking large audio-language models via generative comprehension. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1979–1998. Association for Computational Linguistics, August 2024.
-   \[YYZ<sup id="bib.bibx101.4.4.1"><span id="bib.bibx101.4.4.1.1">+</span></sup>24\] An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, et al. Qwen2. 5 technical report. arXiv preprint arXiv:2412.15115, 2024.
-   \[YZN<sup id="bib.bibx102.4.4.1"><span id="bib.bibx102.4.4.1.1">+</span></sup>24\] Xiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong, Yuxuan Sun, Botao Yu, Ge Zhang, Huan Sun, et al. Mmmu-pro: A more robust multi-discipline multimodal understanding benchmark. arXiv preprint arXiv:2409.02813, 2024.
-   \[YZY<sup id="bib.bibx103.4.4.1"><span id="bib.bibx103.4.4.1.1">+</span></sup>18\] Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, et al. Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task. arXiv preprint arXiv:1809.08887, 2018.
-   \[ZBY<sup id="bib.bibx104.4.4.1"><span id="bib.bibx104.4.4.1.1">+</span></sup>24\] Yongshuo Zong, Ondrej Bohdal, Tingyang Yu, Yongxin Yang, and Timothy Hospedales. Safety fine-tuning at (almost) no cost: A baseline for vision large language models. arXiv preprint arXiv:2402.02207, 2024.
-   \[ZCS<sup id="bib.bibx105.4.4.1"><span id="bib.bibx105.4.4.1.1">+</span></sup>23\] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in Neural Information Processing Systems, 36:46595–46623, 2023.
-   \[ZDC<sup id="bib.bibx106.4.4.1"><span id="bib.bibx106.4.4.1.1">+</span></sup>24\] Pan Zhang, Xiaoyi Dong, Yuhang Cao, Yuhang Zang, Rui Qian, Xilin Wei, Lin Chen, Yifei Li, Junbo Niu, Shuangrui Ding, et al. Internlm-xcomposer2. 5-omnilive: A comprehensive multimodal system for long-term streaming video and audio interactions. arXiv preprint arXiv:2412.09596, 2024.
-   \[ZDL<sup id="bib.bibx107.4.4.1"><span id="bib.bibx107.4.4.1.1">+</span></sup>24\] Aohan Zeng, Zhengxiao Du, Mingdao Liu, Kedong Wang, Shengmin Jiang, Lei Zhao, Yuxiao Dong, and Jie Tang. Glm-4-voice: Towards intelligent and human-like end-to-end spoken chatbot. arXiv preprint arXiv:2412.02612, 2024.
-   \[ZDW<sup id="bib.bibx108.4.4.1"><span id="bib.bibx108.4.4.1.1">+</span></sup>23\] Pan Zhang, Xiaoyi Dong, Bin Wang, Yuhang Cao, Chao Xu, Linke Ouyang, Zhiyuan Zhao, Haodong Duan, Songyang Zhang, Shuangrui Ding, et al. Internlm-xcomposer: A vision-language large model for advanced text-image comprehension and composition. arXiv preprint arXiv:2309.15112, 2023.
-   \[ZHB<sup id="bib.bibx109.4.4.1"><span id="bib.bibx109.4.4.1.1">+</span></sup>19\] Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. Hellaswag: Can a machine really finish your sentence? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4791–4800, 2019.
-   \[ZLM<sup id="bib.bibx110.4.4.1"><span id="bib.bibx110.4.4.1.1">+</span></sup>23\] Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu, Yi Luan, Denny Zhou, and Le Hou. Instruction-following evaluation for large language models, 2023.
-   \[ZVC<sup id="bib.bibx111.4.4.1"><span id="bib.bibx111.4.4.1.1">+</span></sup>24\] Terry Yue Zhuo, Minh Chien Vu, Jenny Chim, Han Hu, Wenhao Yu, Ratnadira Widyasari, Imam Nur Bani Yusuf, Haolan Zhan, Junda He, Indraneil Paul, et al. Bigcodebench: Benchmarking code generation with diverse function calls and complex instructions. arXiv preprint arXiv:2406.15877, 2024.

## Appendix A Prompt for GPT-4 as a Judge on speech benchmarks

We use GPT-4-0613 as a judge model for speech benchmarks, including synthetic MT-Bench, AirBench-Chat, and Summarization tasks as shown in Table [3](https://arxiv.org/html/2503.01743v2#S4.T3 "Table 3 ‣ 4.1.2 Speech and Audio Benchmarks ‣ 4.1 Multimodal Benchmarks ‣ 4 Evaluation ‣ Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs"). Here are the scoring prompts used for different evaluation sets:

Listing 1: GPT-4 Scoring Prompt for MT-Bench turn1 (default)

1{

2 "sys\_template": "You are a helpful assistant.",

3 "user\_template": "

4 \[Instruction\]

5 Please act as an impartial judge and evaluate the quality of the response provided by an AI assistant to the user question displayed below. Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of the response. Begin your evaluation by providing a short explanation. Be as objective as possible. After providing your explanation, you must rate the response on a scale of 1 to 10 by strictly following this format: "\[\[rating\]\]", for example: "Rating: \[\[5\]\]".

6

7 \[Question\]

8 {question placeholder}

9

10 \[The Start of Assistant’s Answer\]

11 {answer placeholder}

12 \[The End of Assistant’s Answer\]

13 "

14}

Listing 2: GPT-4 Scoring Prompt for MT-Bench turn-1 (math and code)

1{

2 "sys\_template": "You are a helpful assistant.",

3 "user\_template": "

4 \[Instruction\]

5 Please act as an impartial judge and evaluate the quality of the response provided by an AI assistant to the user question displayed below. Your evaluation should consider correctness and helpfulness. You will be given a reference answer and the assistant’s answer. Begin your evaluation by comparing the assistant’s answer with the reference answer. Identify and correct any mistakes. Be as objective as possible. After providing your explanation, you must rate the response on a scale of 1 to 10 by strictly following this format: "\[\[rating\]\]", for example: "Rating: \[\[5\]\]".

6

7 \[Question\]

8 {question placeholder}

9

10 \[The Start of Reference Answer\]

11 {ref\_answer placeholder}

12 \[The End of Reference Answer\]

13

14 \[The Start of Assistant’s Answer\]

15 {answer placeholder}

16 \[The End of Assistant’s Answer\]

17 "

18}

Listing 3: GPT-4 Scoring Prompt for MT-Bench turn-2 (default)

1{

2 "sys\_template": "

3 Please act as an impartial judge and evaluate the quality of the response provided by an AI assistant to the user question displayed below. Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of the response. You evaluation should focus on the assistant’s answer to the second user question. Begin your evaluation by providing a short explanation. Be as objective as possible. After providing your explanation, you must rate the response on a scale of 1 to 10 by strictly following this format: "\[\[rating\]\]", for example: "Rating: \[\[5\]\]".

4 ",

5 "user\_template": "

6 |The Start of Assistant A’s Conversation with User|

7

8 ### User:

9 {question\_1}

10

11 ### Assistant A:

12 {answer\_1}

13

14 ### User:

15 {question\_2}

16

17 ### Assistant A:

18 {answer\_2}

19

20 |The End of Assistant A’s Conversation with User|

21 "

22}

Listing 4: GPT-4 Scoring Prompt for MT-Bench turn-2 (math and code)

1{

2 "sys\_template": "

3 Please act as an impartial judge and evaluate the quality of the response provided by an AI assistant to the user question. Your evaluation should consider correctness and helpfulness. You will be given a reference answer and the assistant’s answer. You evaluation should focus on the assistant’s answer to the second question. Begin your evaluation by comparing the assistant’s answer with the reference answer. Identify and correct any mistakes. Be as objective as possible. After providing your explanation, you must rate the response on a scale of 1 to 10 by strictly following this format: "\[\[rating\]\]", for example: "Rating: \[\[5\]\]".

4 ",

5 "user\_template": "

6 |The Start of Reference Answer|

7

8 ### User:

9 {question\_1}

10

11 ### Reference answer:

12 {ref\_answer\_1}

13

14 ### User:

15 {question\_2}

16

17 ### Reference answer:

18 {ref\_answer\_2}

19

20 |The End of Reference Answer|

21

22

23 |The Start of Assistant A’s Conversation with User|

24

25 ### User:

26 {question\_1}

27

28 ### Assistant A:

29 {answer\_1}

30

31 ### User:

32 {question\_2}

33

34 ### Assistant A:

35 {answer\_2}

36

37 |The End of Assistant A’s Conversation with User|

38 "

39}

Listing 5: GPT-4 Scoring Prompt for AirBench-Chat

1{

2 "user\_template": "

3 You are a helpful and precise assistant for checking the quality of the answer.

4 \[Detailed Audio Description\]

5 {meta\_info}

6 \[Question\]

7 {question}

8 \[The Start of Assistant 1s Answer\]

9 {reference}

10 \[The End of Assistant 1s Answer\]

11 \[The Start of Assistant 2s Answer\]

12 {ai\_response}

13 \[The End of Assistant 2s Answer\]

14 \[System\]

15 We would like to request your feedback on the performance of two AI assistants in response to the user question and audio description displayed above. AI assistants are provided with detailed audio descriptions and questions.

16 Please rate the helpfulness, relevance, accuracy, and comprehensiveness of their responses. Each assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance. Please output a single line containing only two values indicating the scores for Assistant 1 and 2, respectively. The two scores are separated by a space.

17 "

18}

Listing 6: GPT-4 Scoring Prompt for Speech Summarization-Overall Score

1You are a skilled evaluator for summaries generated based on user\-provided instructions. A prominent organization has enlisted your help to assess the overall quality of a summary by focusing on how effectively it adheres to the user’s specific instructions. Rate the summary on a scale of 1 to 7 based on the following criteria:

2

31. If the summary fulfills the user’s instructions comprehensively, accurately captures the required details, excludes any explicitly prohibited information, maintains the correct level of detail, adheres to the requested structure (e.g., bullet points, paragraphs), and is both fluent and coherent, assign a score of 7. The summary should read naturally, resembling a human\-written summary. Coherence means ideas are logical and well\-connected, with smooth transitions.

4

52. If the summary mostly fulfills the user instructions but has minor issues, such as slight deviations in structure, missing small details, or minor readability issues, assign a score of 5-6, depending on the severity of the deviation. Consider whether the issues are easy to fix and whether they affect the summary’s usability.

6

73. If the summary fulfills the majority of the instructions but includes unimportant or extra information, omits key details specified by the user, or diverges slightly in structure or emphasis, assign a score of 4-5, depending on the significance of the issues. Weigh the importance of missing or extraneous content against the clarity and adherence to instructions.

8

94. If the summary partially adheres to the instructions, capturing some of the requested details but introducing inconsistencies, hallucinations, or irrelevant content, assign a score of 2-4, depending on the extent of the deviations and errors. Penalize for any explicitly prohibited content that has been included.

10

115. If the summary minimally adheres to the instructions, misses most of the required details, includes significant irrelevant or hallucinated content, or ignores the specified structure or tone, assign a score of 1-3, depending on the severity of the shortcomings.

12

136. If the summary fails to follow the user’s instructions altogether, missing all critical requirements or containing a high proportion of irrelevant or fabricated content, assign a score of 1. This includes summaries that fail to meet any formatting, detail, or exclusion criteria.

14

15Here is the input document, user instruction and the corresponding summary.

16Source:

17‘‘‘

18{src}

19‘‘‘

20User Instruction:

21‘‘‘

22{instruction}

23‘‘‘

24Summary

25‘‘‘

26{tgt}

27‘‘‘

28Note: It is helpful to read the summary first, before reading the source document. This will allow you to judge whether you understand the main contents of the source document through the summary alone. Afterward, you can assess to what extent the summary accurately reflects the source document.

29

30Note: Based on the above criteria and assign a overall score of summary in the scale 1-7. If the summary is not provided for evaluation, return "N/A". Besides the score, you should also provide a \*\*brief\*\* explanation.

31

32Note: Use the following json format for easy downstream consumption.

33

34{{

35 "explanation": "judge the summary based on the given criteria and explain your reasoning for the score you are going to give in the next field.",

36 "score": THE\_SCORE\_VALUE

37}}

## Appendix B Authors (alphabetical)

<table id="A2.p1.1"><tbody><tr id="A2.p1.1.1"><td id="A2.p1.1.1.1"><span id="A2.p1.1.1.1.1"><span id="A2.p1.1.1.1.1.1">Abdelrahman Abouelenin</span></span></td><td id="A2.p1.1.1.2"><span id="A2.p1.1.1.2.1"><span id="A2.p1.1.1.2.1.1">Yuxuan Hu</span></span></td><td id="A2.p1.1.1.3"><span id="A2.p1.1.1.3.1"><span id="A2.p1.1.1.3.1.1">Bo Ren</span></span></td></tr><tr id="A2.p1.1.2"><td id="A2.p1.1.2.1"><span id="A2.p1.1.2.1.1"><span id="A2.p1.1.2.1.1.1">Atabak Ashfaq</span></span></td><td id="A2.p1.1.2.2"><span id="A2.p1.1.2.2.1"><span id="A2.p1.1.2.2.1.1">Xin Jin</span></span></td><td id="A2.p1.1.2.3"><span id="A2.p1.1.2.3.1"><span id="A2.p1.1.2.3.1.1">Liliang Ren</span></span></td></tr><tr id="A2.p1.1.3"><td id="A2.p1.1.3.1"><span id="A2.p1.1.3.1.1"><span id="A2.p1.1.3.1.1.1">Adam Atkinson</span></span></td><td id="A2.p1.1.3.2"><span id="A2.p1.1.3.2.1"><span id="A2.p1.1.3.2.1.1">Mahmoud Khademi</span></span></td><td id="A2.p1.1.3.3"><span id="A2.p1.1.3.3.1"><span id="A2.p1.1.3.3.1.1">Sambuddha Roy</span></span></td></tr><tr id="A2.p1.1.4"><td id="A2.p1.1.4.1"><span id="A2.p1.1.4.1.1"><span id="A2.p1.1.4.1.1.1">Hany Awadalla</span></span></td><td id="A2.p1.1.4.2"><span id="A2.p1.1.4.2.1"><span id="A2.p1.1.4.2.1.1">Dongwoo Kim</span></span></td><td id="A2.p1.1.4.3"><span id="A2.p1.1.4.3.1"><span id="A2.p1.1.4.3.1.1">Ning Shang</span></span></td></tr><tr id="A2.p1.1.5"><td id="A2.p1.1.5.1"><span id="A2.p1.1.5.1.1"><span id="A2.p1.1.5.1.1.1">Nguyen Bach</span></span></td><td id="A2.p1.1.5.2"><span id="A2.p1.1.5.2.1"><span id="A2.p1.1.5.2.1.1">Young Jin Kim</span></span></td><td id="A2.p1.1.5.3"><span id="A2.p1.1.5.3.1"><span id="A2.p1.1.5.3.1.1">Yelong Shen</span></span></td></tr><tr id="A2.p1.1.6"><td id="A2.p1.1.6.1"><span id="A2.p1.1.6.1.1"><span id="A2.p1.1.6.1.1.1">Jianmin Bao</span></span></td><td id="A2.p1.1.6.2"><span id="A2.p1.1.6.2.1"><span id="A2.p1.1.6.2.1.1">Gina Lee</span></span></td><td id="A2.p1.1.6.3"><span id="A2.p1.1.6.3.1"><span id="A2.p1.1.6.3.1.1">Saksham Singhal</span></span></td></tr><tr id="A2.p1.1.7"><td id="A2.p1.1.7.1"><span id="A2.p1.1.7.1.1"><span id="A2.p1.1.7.1.1.1">Alon Benhaim</span></span></td><td id="A2.p1.1.7.2"><span id="A2.p1.1.7.2.1"><span id="A2.p1.1.7.2.1.1">Jinyu Li</span></span></td><td id="A2.p1.1.7.3"><span id="A2.p1.1.7.3.1"><span id="A2.p1.1.7.3.1.1">Subhojit Som</span></span></td></tr><tr id="A2.p1.1.8"><td id="A2.p1.1.8.1"><span id="A2.p1.1.8.1.1"><span id="A2.p1.1.8.1.1.1">Martin Cai</span></span></td><td id="A2.p1.1.8.2"><span id="A2.p1.1.8.2.1"><span id="A2.p1.1.8.2.1.1">Yunsheng Li</span></span></td><td id="A2.p1.1.8.3"><span id="A2.p1.1.8.3.1"><span id="A2.p1.1.8.3.1.1">Xia Song</span></span></td></tr><tr id="A2.p1.1.9"><td id="A2.p1.1.9.1"><span id="A2.p1.1.9.1.1"><span id="A2.p1.1.9.1.1.1">Vishrav Chaudhary</span></span></td><td id="A2.p1.1.9.2"><span id="A2.p1.1.9.2.1"><span id="A2.p1.1.9.2.1.1">Chen Liang</span></span></td><td id="A2.p1.1.9.3"><span id="A2.p1.1.9.3.1"><span id="A2.p1.1.9.3.1.1">Tetyana Sych</span></span></td></tr><tr id="A2.p1.1.10"><td id="A2.p1.1.10.1"><span id="A2.p1.1.10.1.1"><span id="A2.p1.1.10.1.1.1">Congcong Chen</span></span></td><td id="A2.p1.1.10.2"><span id="A2.p1.1.10.2.1"><span id="A2.p1.1.10.2.1.1">Xihui Lin</span></span></td><td id="A2.p1.1.10.3"><span id="A2.p1.1.10.3.1"><span id="A2.p1.1.10.3.1.1">Praneetha Vaddamanu</span></span></td></tr><tr id="A2.p1.1.11"><td id="A2.p1.1.11.1"><span id="A2.p1.1.11.1.1"><span id="A2.p1.1.11.1.1.1">Dong Chen</span></span></td><td id="A2.p1.1.11.2"><span id="A2.p1.1.11.2.1"><span id="A2.p1.1.11.2.1.1">Zeqi Lin</span></span></td><td id="A2.p1.1.11.3"><span id="A2.p1.1.11.3.1"><span id="A2.p1.1.11.3.1.1">Shuohang Wang</span></span></td></tr><tr id="A2.p1.1.12"><td id="A2.p1.1.12.1"><span id="A2.p1.1.12.1.1"><span id="A2.p1.1.12.1.1.1">Dongdong Chen</span></span></td><td id="A2.p1.1.12.2"><span id="A2.p1.1.12.2.1"><span id="A2.p1.1.12.2.1.1">Mengchen Liu</span></span></td><td id="A2.p1.1.12.3"><span id="A2.p1.1.12.3.1"><span id="A2.p1.1.12.3.1.1">Yiming Wang</span></span></td></tr><tr id="A2.p1.1.13"><td id="A2.p1.1.13.1"><span id="A2.p1.1.13.1.1"><span id="A2.p1.1.13.1.1.1">Junkun Chen</span></span></td><td id="A2.p1.1.13.2"><span id="A2.p1.1.13.2.1"><span id="A2.p1.1.13.2.1.1">Yang Liu</span></span></td><td id="A2.p1.1.13.3"><span id="A2.p1.1.13.3.1"><span id="A2.p1.1.13.3.1.1">Zhenghao Wang</span></span></td></tr><tr id="A2.p1.1.14"><td id="A2.p1.1.14.1"><span id="A2.p1.1.14.1.1"><span id="A2.p1.1.14.1.1.1">Weizhu Chen</span></span></td><td id="A2.p1.1.14.2"><span id="A2.p1.1.14.2.1"><span id="A2.p1.1.14.2.1.1">Gilsinia Lopez</span></span></td><td id="A2.p1.1.14.3"><span id="A2.p1.1.14.3.1"><span id="A2.p1.1.14.3.1.1">Haibin Wu</span></span></td></tr><tr id="A2.p1.1.15"><td id="A2.p1.1.15.1"><span id="A2.p1.1.15.1.1"><span id="A2.p1.1.15.1.1.1">Yen-Chun Chen</span></span></td><td id="A2.p1.1.15.2"><span id="A2.p1.1.15.2.1"><span id="A2.p1.1.15.2.1.1">Chong Luo</span></span></td><td id="A2.p1.1.15.3"><span id="A2.p1.1.15.3.1"><span id="A2.p1.1.15.3.1.1">Haoran Xu</span></span></td></tr><tr id="A2.p1.1.16"><td id="A2.p1.1.16.1"><span id="A2.p1.1.16.1.1"><span id="A2.p1.1.16.1.1.1">Yi-ling Chen</span></span></td><td id="A2.p1.1.16.2"><span id="A2.p1.1.16.2.1"><span id="A2.p1.1.16.2.1.1">Piyush Madan</span></span></td><td id="A2.p1.1.16.3"><span id="A2.p1.1.16.3.1"><span id="A2.p1.1.16.3.1.1">Weijian Xu</span></span></td></tr><tr id="A2.p1.1.17"><td id="A2.p1.1.17.1"><span id="A2.p1.1.17.1.1"><span id="A2.p1.1.17.1.1.1">Qi Dai</span></span></td><td id="A2.p1.1.17.2"><span id="A2.p1.1.17.2.1"><span id="A2.p1.1.17.2.1.1">Vadim Mazalov</span></span></td><td id="A2.p1.1.17.3"><span id="A2.p1.1.17.3.1"><span id="A2.p1.1.17.3.1.1">Yifan Yang</span></span></td></tr><tr id="A2.p1.1.18"><td id="A2.p1.1.18.1"><span id="A2.p1.1.18.1.1"><span id="A2.p1.1.18.1.1.1">Xiyang Dai</span></span></td><td id="A2.p1.1.18.2"><span id="A2.p1.1.18.2.1"><span id="A2.p1.1.18.2.1.1">Arindam Mitra</span></span></td><td id="A2.p1.1.18.3"><span id="A2.p1.1.18.3.1"><span id="A2.p1.1.18.3.1.1">Ziyi Yang</span></span></td></tr><tr id="A2.p1.1.19"><td id="A2.p1.1.19.1"><span id="A2.p1.1.19.1.1"><span id="A2.p1.1.19.1.1.1">Ruchao Fan</span></span></td><td id="A2.p1.1.19.2"><span id="A2.p1.1.19.2.1"><span id="A2.p1.1.19.2.1.1">Ali Mousavi</span></span></td><td id="A2.p1.1.19.3"><span id="A2.p1.1.19.3.1"><span id="A2.p1.1.19.3.1.1">Donghan Yu</span></span></td></tr><tr id="A2.p1.1.20"><td id="A2.p1.1.20.1"><span id="A2.p1.1.20.1.1"><span id="A2.p1.1.20.1.1.1">Mei Gao</span></span></td><td id="A2.p1.1.20.2"><span id="A2.p1.1.20.2.1"><span id="A2.p1.1.20.2.1.1">Anh Nguyen</span></span></td><td id="A2.p1.1.20.3"><span id="A2.p1.1.20.3.1"><span id="A2.p1.1.20.3.1.1">Ishmam Zabir</span></span></td></tr><tr id="A2.p1.1.21"><td id="A2.p1.1.21.1"><span id="A2.p1.1.21.1.1"><span id="A2.p1.1.21.1.1.1">Min Gao</span></span></td><td id="A2.p1.1.21.2"><span id="A2.p1.1.21.2.1"><span id="A2.p1.1.21.2.1.1">Jing Pan</span></span></td><td id="A2.p1.1.21.3"><span id="A2.p1.1.21.3.1"><span id="A2.p1.1.21.3.1.1">Jianwen Zhang</span></span></td></tr><tr id="A2.p1.1.22"><td id="A2.p1.1.22.1"><span id="A2.p1.1.22.1.1"><span id="A2.p1.1.22.1.1.1">Amit Garg</span></span></td><td id="A2.p1.1.22.2"><span id="A2.p1.1.22.2.1"><span id="A2.p1.1.22.2.1.1">Daniel Perez-Becker</span></span></td><td id="A2.p1.1.22.3"><span id="A2.p1.1.22.3.1"><span id="A2.p1.1.22.3.1.1">Li Lyna Zhang</span></span></td></tr><tr id="A2.p1.1.23"><td id="A2.p1.1.23.1"><span id="A2.p1.1.23.1.1"><span id="A2.p1.1.23.1.1.1">Abhishek Goswami</span></span></td><td id="A2.p1.1.23.2"><span id="A2.p1.1.23.2.1"><span id="A2.p1.1.23.2.1.1">Jacob Platin</span></span></td><td id="A2.p1.1.23.3"><span id="A2.p1.1.23.3.1"><span id="A2.p1.1.23.3.1.1">Yunan Zhang</span></span></td></tr><tr id="A2.p1.1.24"><td id="A2.p1.1.24.1"><span id="A2.p1.1.24.1.1"><span id="A2.p1.1.24.1.1.1">Junheng Hao</span></span></td><td id="A2.p1.1.24.2"><span id="A2.p1.1.24.2.1"><span id="A2.p1.1.24.2.1.1">Thomas Portet</span></span></td><td id="A2.p1.1.24.3"><span id="A2.p1.1.24.3.1"><span id="A2.p1.1.24.3.1.1">Xiren Zhou</span></span></td></tr><tr id="A2.p1.1.25"><td id="A2.p1.1.25.1"><span id="A2.p1.1.25.1.1"><span id="A2.p1.1.25.1.1.1">Amr Hendy</span></span></td><td id="A2.p1.1.25.2"><span id="A2.p1.1.25.2.1"><span id="A2.p1.1.25.2.1.1">Kai Qiu</span></span></td><td id="A2.p1.1.25.3"><span id="A2.p1.1.25.3.1"><span id="A2.p1.1.25.3.1.1"></span></span></td></tr></tbody></table>