---
论文名称: Multimodal Learning with Transformers A Survey
tags:
  - "#多模态机器学习"
  - "#Transformer"
摘要: Transformer是一种有希望的神经网络学习器，在各个机器学习任务中取得了巨大成功。得益于最近多模态应用和大数据的普及，基于 Transformer的多模态学习已成为人工智能研究的热点。本文对面向多模态数据的变换器技术进行了全面综述。本综述的主要内容如下：（1）多模态学习、变换器生态系统和多模态大数据时代的背景，（2）从几何拓扑的角度，对原始变换器、视觉变换器和多模态变换器进行了系统回顾，（3）通过两个重要范式，即预训练和针对特定多模态任务的任务，对多模态变换器应用进行了回顾，（4）总结了多模态变换器模型和应用共有的常见挑战和设计，（5）讨论了社区面临的开放问题和潜在的研究方向。
发布时间: 2023
链接: https://arxiv.org/abs/2206.06488
---
## 多模态学习与 Transformer： 调查

彭旭，朱夏天，和大卫·A·克利夫顿

###### 摘要

Transformer是一种有希望的神经网络学习器，在各个机器学习任务中取得了巨大成功。得益于最近多模态应用和大数据的普及，基于 Transformer的多模态学习已成为人工智能研究的热点。本文对面向多模态数据的变换器技术进行了全面综述。本综述的主要内容如下：（1）多模态学习、变换器生态系统和多模态大数据时代的背景，（2）从几何拓扑的角度，对原始变换器、视觉变换器和多模态变换器进行了系统回顾，（3）通过两个重要范式，即预训练和针对特定多模态任务的任务，对多模态变换器应用进行了回顾，（4）总结了多模态变换器模型和应用共有的常见挑战和设计，（5）讨论了社区面临的开放问题和潜在的研究方向。

索引术语： 多模态学习，Transformer，入门，分类法，深度学习，机器学习。

## 1引言

人工智能（AI）的最初灵感是模仿人类感知，例如，看到、听到、触摸、闻到。一般来说，一种模态通常与一个特定的传感器相关联，创建一个独特的通信渠道，如视觉和语言\[^1\]。在人类中，我们感官感知的一个基本机制是能够利用多种感知数据模态共同作用，以便在动态不受限制的情境下正确地与世界互动，每种模态都作为具有不同统计特性的独特信息源。例如，一张图片通过数千个像素展示了“大象在水中玩耍”的场景，而相应的文本则用离散的词语来描述这一刻。从根本上说，一个多模态 AI 系统需要摄取、解释和推理多模态信息源，以实现类似人类水平的感知能力。 多模态学习（MML）是一种构建能够从多模态数据中提取和关联信息的 AI 模型的一般方法 \[[1](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib1)\]。

本调查重点介绍了基于 Transformer 的多模态学习（如图 1 所示），受到其在建模不同模态（例如，语言、视觉、听觉）和任务（例如，语言翻译、图像识别、语音识别）方面的内在优势和可扩展性的启发，以及更少的模态特定架构假设（例如，视觉中的平移不变性和局部网格注意力偏差）\[3\]。具体来说，Transformer 的输入可以包含一个或多个标记序列，每个序列的属性（例如，模态标签、序列顺序）自然允许在不修改架构的情况下进行多模态学习\[MML\] \[4\]。 进一步，学习每个模态的特定性和模态间的相关性 可以通过控制自注意力机制的输入模式简单地实现。 关键的是，最近在多个学科领域出现了对 Transformer 架构的研究热潮，导致近年来开发了大量新颖的多模态学习方法，并在各个领域取得了显著且多样化的进展 <参考文献 id=16>\[\[4\], \[5\], \[6\], \[7\], \[8\]\]\]. 这要求及时回顾和总结代表性方法，以便研究人员能够理解跨相关学科的 MML 领域的全局图景，更重要的是，捕捉到当前成就以及主要挑战的整体结构图。

分类 为了提高可读性和跨不同学科的可及性 我们采用两级结构化分类法 基于应用和挑战维度分别。 这有几个好处： (1) 具有特定应用领域专业知识的学者 可找到 适用于他们各自研究领域的应用 在连接到其他相关领域之前。 (2) 不同领域开发的类似模型设计和架构 可以概括为一个基于公式的摘要视角，以便在不同应用中形成的各种模型的数学思想可以在共同的基础上进行关联和对比，跨越特定领域的限制。 关键在于，我们的分类法提供了一个有趣的立体视角，对个体作品进行观察 在应用特定性和公式通用性方面的见解。 希望这有助于打破领域边界 促进跨模态更有效的观点沟通和交流。 通过以提示建模策略（文献\[9, 10\]）为基础进行探究，我们还包括经典分类问题（例如，图像分类）——在传统的多模态学习调查中通常被视为单一模态学习应用——作为一个特殊的 MML 应用。这有可能显著丰富 MML，因为分类问题是文献中研究最为广泛的 AI 主题之一（文献\[13\]）。

范围 本调查将讨论 Transformer 架构的多模态特定设计，包括但不限于以下模态： RGB 图像 <引用 id=1>\[[5](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib5)\]，深度图像 <引用 id=3>\[[14](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib14)\]，多光谱图像 <引用 id=6>\[[15](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib15)\]，视频 <引用 id=8>\[[7](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib7)\]，音频/语音/音乐 <引用 id=10>\[[16](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib16)，[17](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib17)，[14](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib14)\]，表格 <引用 id=14>\[[18](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib18)\]，场景图/布局 <引用 id=16>\[[19](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib19)，[20](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib20)，[21](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib21)，[22](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib22)\]，姿态骨架 <引用 id=21>\[[23](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib23)\]，SQL <引用 id=23>\[[24](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib24)，[25](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib25)\]，食谱 <引用 id=26>\[[26](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib26)\]，编程语言 <引用 id=28>\[[27](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib27)\]，手语 <引用 id=30>\[[28](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib28)，[29](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib29)，[30](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib30)\]，点云 <引用 id=34>\[[31](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib31)\]，符号知识（图） <引用 id=36>\[[32](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib32)，[33](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib33)\]，多模态知识图谱 <引用 id=39>\[[34](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib34)\]，草图绘制 <引用 id=41>\[[35](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib35)，[36](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib36)，[37](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib37)，[38](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib38)\]，3D 对象/场景 <引用 id=46>\[[39](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib39)，[40](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib40)，[41](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib41)\]，文档 <引用 id=50>\[[42](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib42)，[43](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib43)\]，编程代码 <引用 id=53>\[[44](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib44)\]和抽象语法树（AST）——一种图 <引用 id=55>\[[45](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib45)\]，光流 <引用 id=57>\[[46](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib46)\]，医学知识（例如，诊断代码本体 <引用 id=61>\[[47](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib47)\]）。 请注意，本综述不会讨论那些仅将 Transformer 用作特征提取器而不涉及多模态设计的多模态论文。

相关调查 我们将本文与现有的综述联系起来 关于两个特定维度 MML 和 Transformer 的。 存在一些多模态学习调查文献\[[1](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib1), [11](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib11), [12](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib12)\]。特别是\[[1](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib1)\]提出了一种通过五个挑战构建的结构化、公认的分类法，我们也将它作为我们结构的一部分。与\[[1](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib1), [11](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib11)\]和\[[12](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib12)\]不同，它们回顾了通用机器学习模型，我们则专注于 Transformer 架构及其自注意力机制。最近出现了一些专门针对 Transformer 的调查，涵盖了包括通用 Transformer\[[48](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib48)\]、高效设计\[[49](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib49)\]、可视化\[[50](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib50)\]、计算机视觉任务\[[51](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib51), [52](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib52), [53](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib53), [54](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib54)\]、医学成像\[[55](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib55)\]、视频任务\[[56](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib56)\]以及视觉语言预训练\[[57](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib57)\]在内的各种重点。 在考虑 MML 时，尽管有\[[51](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib51)，[53](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib53)，[55](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib55)，[54](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib54)\]等文献，但它们的综述在范围、分类和覆盖面上都有些局限。据我们所知，只有少数关于视频语言预训练（VLP）\[[57](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib57)，[58](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib58)，[59](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib59)\]的调查与 MML 相关。然而，VLP 只是 MML 的一个子领域。在本综述中，我们仅关注多模态学习和 Transformer 的交集。

![Refer to caption](https://ar5iv.labs.arxiv.org/html/2206.06488/assets/figures/transformer.png)

图 1：Transformer 概述。\[[2](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib2)\]

特征 据我们所知，这篇论文是关于基于 Transformer 的多模态机器学习现状的第一篇全面综述。 本调查的主要特点包括

(1) 我们强调，Transformer 具有以模态无关的方式工作的优势。因此，它们与各种模态（以及模态的组合）兼容。为了支持这一观点，我们首次从几何拓扑的角度，对多模态环境中 Transformer 的内在特性进行了理解。我们建议将自注意力视为一种图式建模，该建模将输入序列（无论是单模态还是多模态）建模为一个全连接图。具体来说，自注意力将来自任意模态的任意标记的嵌入建模为图节点。

(2) 我们尽可能地以数学方式讨论多模态环境中 Transformers 的关键组件。

(3) 基于 Transformer，跨模态交互（例如，融合、对齐）本质上是通过自注意力及其变体来处理的。在本文中，我们从自注意力设计的角度，提取了基于 Transformer 的多模态学习（MML）实践的数学本质和公式。

贡献 在第二节中，我们介绍了多模态学习、Transformer 生态系统和多模态大数据时代的概览，以下是我们主要贡献的总结。

(1)在第 [3](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#S3 "3 Transformers ‣ Multimodal Learning with Transformers: A Survey") 节中，我们从几何拓扑的角度，对 Vanilla Transformer、Vision Transformer 和多模态 Transformer 进行了系统性的综述。

(2) 我们从两个互补的视角贡献了一个基于 Transformer 的多模态学习分类法，i。e，基于应用和基于挑战。在第4节中，我们通过两个重要范式对多模态 Transformer 应用进行了综述，i。e，用于多模态预训练和特定多模态任务。在第5节中，我们总结了各种多模态 Transformer 模型和应用共有的挑战和设计。

(3)在第 [6](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#S6 "6 Discussion and Outlook ‣ Multimodal Learning with Transformers: A Survey") 节中，我们讨论了基于 Transformer 的多模态学习（MML）的当前瓶颈、现有问题和潜在的研究方向。

## 2背景

### 2.1 多模态学习（MML）

MML（多模态学习）在近几十年里已成为一个重要的研究领域；一个早期的多模态应用——音频-视觉语音识别在 20 世纪 80 年代被研究过。MML 是人类社会的关键。我们人类所生活的世界是一个多模态环境，因此我们的观察和行为都是多模态的。例如，一个 AI 导航机器人需要多模态传感器来感知现实世界环境，例如，相机、激光雷达、雷达、超声波、GNSS、高清地图、里程表。此外，人类的行为、情感、事件、动作和幽默都是多模态的，因此各种以人为中心的多模态任务被广泛研究，包括多模态情感识别、多模态事件表示、理解多模态幽默、基于面部-身体-声音的视频人物聚类等。

感谢近年来互联网的发展和众多智能设备的广泛使用，越来越多的多模态数据正在通过互联网传输，因此越来越多的多模态应用场景正在出现。在现代社会，我们可以看到各种多模态应用，包括商业服务（例如，电子商务/商品检索 e。g., 视觉与语言导航（VLN）\[[71](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib71)\]，通信（例如，唇语阅读 \[[77](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib77)\]，手语翻译 \[[28](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib28), [29](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib29)\]），人机交互 \[[78](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib78)\]，医疗 AI \[[79](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib79), [80](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib80)\]，监控 AI \[[81](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib81)\]，等等。

此外，在深度学习时代，深度神经网络极大地推动了多模态学习（MML）的发展，Transformers \[2\] 是一个极具竞争力的架构家族，为 MML 带来了新的挑战和机遇。 特别是，大型语言模型及其多模态衍生品最近的成功\[[82](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib82)，[83](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib83)，[84](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib84)，[85](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib85)，[86](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib86)\]进一步展示了 Transformer 在多模态基础模型中的潜力。

### 2.2 2.2 Transformers：简史与里程碑

Transformer 正成为有希望的学习者。 普通 Transformer Transformer 从自注意力机制中受益，并且是针对序列特定表示学习的一个突破性模型，最初是为 NLP 提出的，在各种 NLP 任务上实现了最先进的水平。在普通 Transformer Transformer 取得巨大成功之后，提出了许多衍生模型，例如 BERT \[[4](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib4)\]、BART \[[87](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib87)\]、GPT \[[88](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib88)\]、Longformer \[[43](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib43)\]、Transformer-XL \[[89](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib89)\]、XLNet \[[90](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib90)\]。

Transformer 目前处于 NLP 领域的领先地位，这促使研究人员尝试将 Transformer 应用于其他模态，例如视觉领域。在早期对视觉领域的尝试中，一般流程是“CNN 特征 + 标准 Transformer 编码器”，研究人员通过预处理原始图像，将其调整到低分辨率并重塑为 1D 序列来实现 BERT 风格的预训练。

视觉 Transformer（ViT）\[[5](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#ref5)\]是一项开创性的工作，通过将 Transformer 的编码器应用于图像，提供了一种端到端的解决方案。ViT 及其变体已被广泛应用于各种计算机视觉任务，包括低级任务\[[92](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#ref92)\]、识别\[[93](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#ref93)\]、检测\[[94](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#ref94)\]、分割\[[95](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#ref95)\]等，并且在监督\[[93](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#ref93)\]和无监督\[[96](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#ref96), [97](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#ref97), [98](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#ref98)\]视觉学习方面都表现出良好的效果。此外，一些最近发布的作品为 ViT 提供了进一步的理论理解，例如，其内部表示的鲁棒性\[[99](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#ref99)\]，其潜在表示传播的连续行为\[[100](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#ref100), [101](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#ref101)\]。

受 Transformer 巨大成功的启发，VideoBERT\[[7](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib7)\]是一项突破性工作，它是第一个将 Transformer 扩展到多模态任务的工作。VideoBERT 展示了 Transformer 在多模态环境中的巨大潜力。 在 VideoBERT 之后，许多基于 Transformer 的多模态预训练模型（例如，ViLBERT\[102\]、LXMERT\[103\]、VisualBERT\[104\]、VL-BERT\[105\]、UNITER\[106\]、CBT\[107\]、Unicoder-VL\[108\]、B2T2\[109\]、VLP\[110\]、12-in-1\[111\]、Oscar\[112\]、Pixel-BERT\[113\]、ActBERT\[114\]、ImageBERT\[115\]、HERO\[116\]、UniVL\[117\]）已成为机器学习领域越来越受关注的研究课题。

2021 年，CLIP <引用 id=0>\[<引用 id=1>9\] 被提出。这是一个新的里程碑，它使用多模态预训练将分类作为检索任务，使预训练模型能够处理零样本识别。 因此，CLIP 是一种成功的实践，充分利用大规模多模态预训练来实现零样本学习。 近期，CLIP 的概念得到了进一步研究 例如。基于 CLIP 预训练模型的零样本语义分割 \[[118](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib118)\]，ALIGN \[[119](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib119)\]，CLIP-TD \[[120](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib120)\]，ALBEF \[[121](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib121)\] 和 CoCa \[[122](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib122)\]。

### 2.3 多模态大数据

在过去十年中，随着社交媒体和在线零售等互联网应用的快速发展，大量多模态数据集被提出，例如概念图说 e。g，例如，概念图说 \[[123](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib123)\]，COCO \[[124](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib124)\]，VQA \[[125](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib125)\]，视觉基因组 \[[126](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib126)\]，SBU 图说 \[[127](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib127)\]，Cooking312K \[[7](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib7)\]，LAIT \[[115](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib115)\]，e-SNLI-VE \[[128](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib128)\]， 架构 \[[129](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib129)\] 对抗性视觉问答 \[[130](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib130)\]，OTT-QA \[[18](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib18)\]，多模态问答（MMQA）\[[131](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib131)\]，VALUE \[[132](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib132)\]，时尚 IQ \[[133](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib133)\] LRS2-BBC \[[134](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib134)\]，ActivityNet \[[135](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib135)\]，VisDial \[[136](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib136)\]。

一些最近发布的多模态数据集中出现的新趋势包括：

(1) 数据规模更大。最近发布的各种数据集都是百万规模，e。g。，产品 1M \[[137](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib137)\]，概念 12M \[[138](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib138)\]，RUC-CAS-WenLan \[[139](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib139)\] (30M)，HowToVQA69M \[[140](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib140)\]，HowTo100M \[[141](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib141)\]，ALT200M \[[142](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib142)\]，LAION-400M \[[143](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib143)\]。

(2) 更多模态。除了视觉、文本和音频等通用模态之外，还出现了更多样化的模态，e。g。例如，Pano-AVQA \[[144](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib144)\] – 第一个大规模空间和视听问答数据集，针对 360∘superscript360360^{\\circ} 视频的 YouTube-360 (YT-360) \[[145](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib145)\]（ 360∘superscript360360^{\\circ} 视频），AIST++ \[[146](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib146)\]（一个包含 3D 舞蹈动作和音乐的新的多模态数据集），Artemis \[[147](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib147)\]（视觉艺术的情感语言）。特别是，MultiBench \[[148](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib148)\] 提供了一个包含 10 种模态的数据集。

\[3\] 更多场景。 除了常见的标题和问答数据集之外， 更多应用和场景已被研究，例如，CIRR \[1\]（真实图像），Product1M \[2\]，民宿（BnB）\[3\]（视觉和语言导航），M3A \[4\]（金融数据集），X-World \[5\]（自动驾驶）。

(4) 任务更难。 除了直接的任务之外， 更多抽象的多模态任务被提出 e.例如., MultiMET \[[153](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib153)\]（一个用于隐喻理解的跨模态数据集），Hateful Memes \[[154](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib154)\]（跨模态迷因中的仇恨言论）。

(5) 指令视频越来越受欢迎，例如烹饪视频 YouCookII \[[155](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib155)\]。将一系列指令与某人执行任务的视频对齐是强大的预训练先验任务示例 \[[156](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib156), [7](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib7)\]。 前置任务是为迫使模型通过解决它们来学习表示而预先设计的问题。

与其它深度神经网络架构类似，Transformer 也“数据饥渴”。因此，它们的高容量模型和多模态大数据基础共同创造了基于 Transformer 的多模态机器学习的繁荣。例如，大数据为 VLP Transformer 模型带来了零样本学习能力。

## 3 Transformer

在本节中，我们使用数学公式来回顾了标准Transformer \[[2](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib2)\]、视觉 Transformer \[[5](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib5)\]和多模态 Transformer 的关键技术，包括标记化输入、自注意力、多头注意力、基本的 Transformer 层/块等。等等。我们强调，标准Transformer 可以从几何拓扑的角度来理解\[[157](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib157)\]，因为由于自注意力机制，对于来自任何模态的每个标记化输入，标准自注意力（Transformer）可以将其建模为拓扑几何空间中的全连接图\[[158](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib158)\]。与其他深度网络（例如，CNN 受限于对齐的网格空间/矩阵）相比，Transformer 本质上具有更通用和灵活的建模空间。这是 Transformer 在多模态任务中的一个显著优势。 章节[3.1](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#S3.SS1 "3.1 Vanilla Transformer ‣ 3 Transformers ‣ Multimodal Learning with Transformers: A Survey")、[3.2](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#S3.SS2 "3.2 Vision Transformer ‣ 3 Transformers ‣ Multimodal Learning with Transformers: A Survey")和[3.3](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#S3.SS3 "3.3 Multimodal Transformers ‣ 3 Transformers ‣ Multimodal Learning with Transformers: A Survey")将分别回顾Vanilla Transformer、Vision Transformer 和多模态 Transformer 的关键设计。

### 3.1 基础 Transformer

纯 Transformer 具有编码器-解码器结构，是 Transformer 研究领域的起源。它接受标记化输入（见第 3.1.1 节）。其编码器和解码器都由 Transformer 层/块堆叠而成，如图 1 所示。每个块有两个子层，即 i.e.，一个多头自注意力（MHSA）层（见第 3.1.2 节）和一个位置感知的全连接前馈网络（FFN）（见第 3.1.3 节）。为了帮助梯度反向传播，MHSA 和 FFN 都使用残差连接（\[159\]）（给定输入 xx ，任何映射 f(⋅)f(\\cdot) 的残差连接定义为 x←f(x)+xx\\leftarrow f(x)+x ），然后是归一化层。因此，假设输入张量为 𝐙\\mathbf{Z} ，MHSA 和 FFN 子层的输出可以表示为：

<table id="S3.E1"><tbody><tr><td></td><td><math id="S3.E1.m1.2" alttext="\mathbf{Z}\leftarrow N({sublayer}(\mathbf{Z})+\mathbf{Z})," display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.3" xref="S3.E1.m1.2.2.1.1.3.cmml">𝐙</mi><mo stretchy="false" id="S3.E1.m1.2.2.1.1.2" xref="S3.E1.m1.2.2.1.1.2.cmml">←</mo><mrow id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.2.cmml"></mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml"></mo><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.1a" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml"></mo><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.2.4" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.4.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.1b" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml"></mo><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.2.5" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.1c" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml"></mo><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.2.6" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.1d" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml"></mo><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.2.7" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.7.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.1e" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml"></mo><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.2.8" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.1f" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml"></mo><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.2.9" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.9.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.1g" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml"></mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.2.10.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.10.2.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">𝐙</mi><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.10.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.cmml">+</mo><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.3.cmml">𝐙</mi></mrow><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1"><ci id="S3.E1.m1.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.2">←</ci><ci id="S3.E1.m1.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.3">𝐙</ci><apply id="S3.E1.m1.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1"><times id="S3.E1.m1.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.2"></times><ci id="S3.E1.m1.2.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.3">𝑁</ci><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1"><plus id="S3.E1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1"></plus><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2"><times id="S3.E1.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.1"></times><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.2">𝑠</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.3">𝑢</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.2.4.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.4">𝑏</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.2.5.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.5">𝑙</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.2.6.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.6">𝑎</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.2.7.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.7">𝑦</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.2.8.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.8">𝑒</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.2.9.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.9">𝑟</ci><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝐙</ci></apply><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.3">𝐙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\mathbf{Z}\leftarrow N({sublayer}(\mathbf{Z})+\mathbf{Z}),</annotation></semantics></math></td><td></td><td rowspan="1"><span>(1)</span></td></tr></tbody></table>

sublayer(⋅){sublayer}(\\cdot) 是子层本身实现的映射， N(⋅)N(\\cdot) 表示归一化，e。g。, BN(⋅)BN(\\cdot) \[[160](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib160)\]， LN(⋅)LN(\\cdot) \[[161](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib161)\]。

讨论讨论存在一个重要的未解决问题，即后归一化与预归一化。 原始的Vanilla Transformer 为每个 MHSA 和 FFN 子层使用后规范化。然而，如果我们从数学的角度考虑，前规范化更有意义\[[162](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib162)\]。这与矩阵理论的基本原理相似，即规范化应在投影之前进行e。g，例如，Gram–Schmidt 过程 <sup>2</sup><sup>2</sup>[https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt\_process](https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process) 。这个问题应该通过理论研究和实验验证进一步研究。

#### 3.1.1 输入标记化

分词原始 Transformer 最初是为了机器翻译而提出的作为序列到序列模型，因此将词汇序列作为输入是直截了当的。如前所述，原始的自注意力机制可以独立于模态将任意输入建模为一个全连接图。具体来说，原始 Transformer 及其变体都接受分词序列，其中每个标记都可以被视为图中的一个节点。

特殊/定制标记 在 Transformer 中， 各种特殊/定制标记可以语义上定义为标记序列中的占位符 e.例如., 隐藏标记 。\[[\[4\]\]. 一些常见的特殊标记总结在附录中。特殊标记可以用于单模态和多模态 Transformer。](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib4)

位置嵌入 位置嵌入被添加 将位置信息保留到标记嵌入中 \[[4](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib4)\]。 Vanilla Transformer 使用正弦和余弦函数来生成位置嵌入。迄今为止，已经提出了各种位置嵌入的实现方法。具体的解决方案不属于本次调查的重点。

讨论 输入标记化的主要优势包括以下方面：

(1) 从几何拓扑的角度来看，标记化是一种更通用的方法，通过最小化不同模态引起的约束来实现。一般来说，每种模态在建模上都有内在的约束。例如，句子有适合 RNN 的顺序结构，而照片则被限制在 CNN 工作良好的对齐网格矩阵中。标记化帮助 Transformer 通过不规则稀疏结构固有地处理不同的模态。因此，即使是原始 Transformer 也可以通过简单的连接、加权求和，甚至无需任何多模态定制修改，灵活地编码多模态输入。

(2) 分词是一种更灵活的方法，通过连接/堆叠、加权求和等方式组织输入信息。 原始 Transformer 通过求和位置嵌入来向标记嵌入注入时间信息。例如，当使用 Transformer 来建模自由手绘草图时\[[163](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib163)\]，每个输入标记可以整合各种绘图笔触模式，e。g。例如，笔触坐标、笔触顺序、笔状态（开始/结束）。

(3) 分词与特定任务定制的标记兼容，e。例如，用于掩码语言建模的 标记 [\[4](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib4)\]，用于分类的 [标记 \[](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib5)5\]。

讨论讨论如何理解位置嵌入到 Transformer 中是一个开放性问题。 它可以理解为特征空间的一种隐式坐标基，为 Transformer 提供时间或空间信息。 对于云点\[[164](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib164)\]和草图绘制笔触\[[163](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib163)\]，它们的标记元素已经是一个坐标，这意味着位置嵌入是可选的，不是必需的。此外，位置嵌入可以被视为一种通用附加信息。换句话说，从数学的角度来看，可以添加任何附加信息，例如位置嵌入的细节，e。g。例如，草图绘制笔触\[[163](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib163)\]的笔状态，监控中的摄像机和视角\[[165](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib165)\]。有一篇全面综述\[[166](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib166)\]讨论了 Transformer 中的位置信息。对于句子结构（顺序）和一般图结构（稀疏、任意和不规则），位置嵌入有助于 Transformer 学习或编码底层结构。从自注意力的数学视角来看，i。e。例如，缩放 点积注意力 注意力在缺少位置嵌入信息的情况下对单词（在文本中）或节点（在图中）的位置不变。 因此，在大多数情况下，位置嵌入对于 Transformer 是必要的。

#### 3.1.2 自注意力与多头自注意力

Transformer 的核心组件是原始Transformer 中的自注意力（SA）操作\[[2](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib2)\]，也称为“缩放点积注意力”。 假设 𝐗\=\[𝐱1,𝐱2,⋯\]∈ℝN×dsubscript1subscript2superscript\\mathbf{X}=\[\\mathbf{x}\_{1},\\mathbf{x}\_{2},\\cdots\]\\in\\mathbb{R}^{N\\times d} 是一个由 NN 个元素/标记组成的输入序列，并且可以通过点加法 𝐙←𝐗⊕PositionEmbeddingdirect-sum\\mathbf{Z}\\leftarrow\\mathbf{X}\\oplus PositionEmbedding 或连接 𝐙←concat(𝐗,PositionEmbedding)\\mathbf{Z}\\leftarrow concat(\\mathbf{X},PositionEmbedding) 进行可选的预处理，添加位置编码。

自注意力（SA） 预处理后，嵌入 𝐙\\mathbf{Z} 将通过三个投影矩阵（ 𝐖Q∈ℝd×dqsuperscriptsuperscriptsubscript\\mathbf{W}^{Q}\\in\\mathbb{R}^{d\\times d\_{q}} 、 𝐖K∈ℝd×dksuperscriptsuperscriptsubscript\\mathbf{W}^{K}\\in\\mathbb{R}^{d\\times d\_{k}} 和 𝐖V∈ℝd×dvsuperscriptsuperscriptsubscript\\mathbf{W}^{V}\\in\\mathbb{R}^{d\\times d\_{v}} 、 dq\=dksubscriptsubscriptd\_{q}=d\_{k} ）生成三个嵌入 𝐐\\mathbf{Q} （查询）、 𝐊\\mathbf{K} （键）和 𝐕\\mathbf{V} （值）：

<table id="S3.E2"><tbody><tr><td></td><td><math id="S3.E2.m1.1" alttext="\mathbf{Q}=\mathbf{Z}\mathbf{W}^{Q},\mathbf{K}=\mathbf{Z}\mathbf{W}^{K},\mathbf{V}=\mathbf{Z}\mathbf{W}^{V}." display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1"><mrow id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml">𝐐</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">=</mo><msup id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.cmml">𝐙𝐖</mi><mi id="S3.E2.m1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.cmml">Q</mi></msup></mrow><mo id="S3.E2.m1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.3a.cmml">,</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.2.2.1.1" xref="S3.E2.m1.1.1.1.1.2.2.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.1.1.2" xref="S3.E2.m1.1.1.1.1.2.2.1.1.2.cmml">𝐊</mi><mo id="S3.E2.m1.1.1.1.1.2.2.1.1.1" xref="S3.E2.m1.1.1.1.1.2.2.1.1.1.cmml">=</mo><msup id="S3.E2.m1.1.1.1.1.2.2.1.1.3" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.cmml">𝐙𝐖</mi><mi id="S3.E2.m1.1.1.1.1.2.2.1.1.3.3" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.3.cmml">K</mi></msup></mrow><mo id="S3.E2.m1.1.1.1.1.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.3a.cmml">,</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.cmml">𝐕</mi><mo id="S3.E2.m1.1.1.1.1.2.2.2.2.1" xref="S3.E2.m1.1.1.1.1.2.2.2.2.1.cmml">=</mo><msup id="S3.E2.m1.1.1.1.1.2.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.cmml">𝐙𝐖</mi><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.3.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.cmml">V</mi></msup></mrow></mrow></mrow><mo lspace="0em" id="S3.E2.m1.1.1.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3a.cmml" xref="S3.E2.m1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1"></eq><ci id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">𝐐</ci><apply id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2">𝐙𝐖</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3">𝑄</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.3a.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.1.1.1.1.2.2.1.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1"><eq id="S3.E2.m1.1.1.1.1.2.2.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.1"></eq><ci id="S3.E2.m1.1.1.1.1.2.2.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.2">𝐊</ci><apply id="S3.E2.m1.1.1.1.1.2.2.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2">𝐙𝐖</ci><ci id="S3.E2.m1.1.1.1.1.2.2.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.3">𝐾</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2"><eq id="S3.E2.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.1"></eq><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2">𝐕</ci><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.2.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2">𝐙𝐖</ci><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.3">𝑉</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\mathbf{Q}=\mathbf{Z}\mathbf{W}^{Q},\mathbf{K}=\mathbf{Z}\mathbf{W}^{K},\mathbf{V}=\mathbf{Z}\mathbf{W}^{V}.</annotation></semantics></math></td><td></td><td rowspan="1"><span>(2)</span></td></tr></tbody></table>

自注意力机制的输出被定义为

<table id="S3.E3"><tbody><tr><td></td><td><math id="S3.E3.m1.5" alttext="\mathbf{Z}={SA}(\mathbf{Q},\mathbf{K},\mathbf{V})={Softmax}\left(\frac{\mathbf{Q}\mathbf{K}^{\top}}{\sqrt{d_{q}}}\right)\mathbf{V}." display="block"><semantics id="S3.E3.m1.5a"><mrow id="S3.E3.m1.5.5.1" xref="S3.E3.m1.5.5.1.1.cmml"><mrow id="S3.E3.m1.5.5.1.1" xref="S3.E3.m1.5.5.1.1.cmml"><mi id="S3.E3.m1.5.5.1.1.2" xref="S3.E3.m1.5.5.1.1.2.cmml">𝐙</mi><mo id="S3.E3.m1.5.5.1.1.3" xref="S3.E3.m1.5.5.1.1.3.cmml">=</mo><mrow id="S3.E3.m1.5.5.1.1.4" xref="S3.E3.m1.5.5.1.1.4.cmml"><mi id="S3.E3.m1.5.5.1.1.4.2" xref="S3.E3.m1.5.5.1.1.4.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.4.1" xref="S3.E3.m1.5.5.1.1.4.1.cmml"></mo><mi id="S3.E3.m1.5.5.1.1.4.3" xref="S3.E3.m1.5.5.1.1.4.3.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.4.1a" xref="S3.E3.m1.5.5.1.1.4.1.cmml"></mo><mrow id="S3.E3.m1.5.5.1.1.4.4.2" xref="S3.E3.m1.5.5.1.1.4.4.1.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.4.4.2.1" xref="S3.E3.m1.5.5.1.1.4.4.1.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">𝐐</mi><mo id="S3.E3.m1.5.5.1.1.4.4.2.2" xref="S3.E3.m1.5.5.1.1.4.4.1.cmml">,</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">𝐊</mi><mo id="S3.E3.m1.5.5.1.1.4.4.2.3" xref="S3.E3.m1.5.5.1.1.4.4.1.cmml">,</mo><mi id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml">𝐕</mi><mo stretchy="false" id="S3.E3.m1.5.5.1.1.4.4.2.4" xref="S3.E3.m1.5.5.1.1.4.4.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.5.5.1.1.5" xref="S3.E3.m1.5.5.1.1.5.cmml">=</mo><mrow id="S3.E3.m1.5.5.1.1.6" xref="S3.E3.m1.5.5.1.1.6.cmml"><mi id="S3.E3.m1.5.5.1.1.6.2" xref="S3.E3.m1.5.5.1.1.6.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.6.1" xref="S3.E3.m1.5.5.1.1.6.1.cmml"></mo><mi id="S3.E3.m1.5.5.1.1.6.3" xref="S3.E3.m1.5.5.1.1.6.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.6.1a" xref="S3.E3.m1.5.5.1.1.6.1.cmml"></mo><mi id="S3.E3.m1.5.5.1.1.6.4" xref="S3.E3.m1.5.5.1.1.6.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.6.1b" xref="S3.E3.m1.5.5.1.1.6.1.cmml"></mo><mi id="S3.E3.m1.5.5.1.1.6.5" xref="S3.E3.m1.5.5.1.1.6.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.6.1c" xref="S3.E3.m1.5.5.1.1.6.1.cmml"></mo><mi id="S3.E3.m1.5.5.1.1.6.6" xref="S3.E3.m1.5.5.1.1.6.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.6.1d" xref="S3.E3.m1.5.5.1.1.6.1.cmml"></mo><mi id="S3.E3.m1.5.5.1.1.6.7" xref="S3.E3.m1.5.5.1.1.6.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.6.1e" xref="S3.E3.m1.5.5.1.1.6.1.cmml"></mo><mi id="S3.E3.m1.5.5.1.1.6.8" xref="S3.E3.m1.5.5.1.1.6.8.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.6.1f" xref="S3.E3.m1.5.5.1.1.6.1.cmml"></mo><mrow id="S3.E3.m1.5.5.1.1.6.9.2" xref="S3.E3.m1.4.4.cmml"><mo id="S3.E3.m1.5.5.1.1.6.9.2.1" xref="S3.E3.m1.4.4.cmml">(</mo><mfrac id="S3.E3.m1.4.4" xref="S3.E3.m1.4.4.cmml"><msup id="S3.E3.m1.4.4.2" xref="S3.E3.m1.4.4.2.cmml"><mi id="S3.E3.m1.4.4.2.2" xref="S3.E3.m1.4.4.2.2.cmml">𝐐𝐊</mi><mo id="S3.E3.m1.4.4.2.3" xref="S3.E3.m1.4.4.2.3.cmml">⊤</mo></msup><msqrt id="S3.E3.m1.4.4.3" xref="S3.E3.m1.4.4.3.cmml"><msub id="S3.E3.m1.4.4.3.2" xref="S3.E3.m1.4.4.3.2.cmml"><mi id="S3.E3.m1.4.4.3.2.2" xref="S3.E3.m1.4.4.3.2.2.cmml">d</mi><mi id="S3.E3.m1.4.4.3.2.3" xref="S3.E3.m1.4.4.3.2.3.cmml">q</mi></msub></msqrt></mfrac><mo id="S3.E3.m1.5.5.1.1.6.9.2.2" xref="S3.E3.m1.4.4.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.6.1g" xref="S3.E3.m1.5.5.1.1.6.1.cmml"></mo><mi id="S3.E3.m1.5.5.1.1.6.10" xref="S3.E3.m1.5.5.1.1.6.10.cmml">𝐕</mi></mrow></mrow><mo lspace="0em" id="S3.E3.m1.5.5.1.2" xref="S3.E3.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.5b"><apply id="S3.E3.m1.5.5.1.1.cmml" xref="S3.E3.m1.5.5.1"><and id="S3.E3.m1.5.5.1.1a.cmml" xref="S3.E3.m1.5.5.1"></and><apply id="S3.E3.m1.5.5.1.1b.cmml" xref="S3.E3.m1.5.5.1"><eq id="S3.E3.m1.5.5.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.3"></eq><ci id="S3.E3.m1.5.5.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.2">𝐙</ci><apply id="S3.E3.m1.5.5.1.1.4.cmml" xref="S3.E3.m1.5.5.1.1.4"><times id="S3.E3.m1.5.5.1.1.4.1.cmml" xref="S3.E3.m1.5.5.1.1.4.1"></times><ci id="S3.E3.m1.5.5.1.1.4.2.cmml" xref="S3.E3.m1.5.5.1.1.4.2">𝑆</ci><ci id="S3.E3.m1.5.5.1.1.4.3.cmml" xref="S3.E3.m1.5.5.1.1.4.3">𝐴</ci><vector id="S3.E3.m1.5.5.1.1.4.4.1.cmml" xref="S3.E3.m1.5.5.1.1.4.4.2"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝐐</ci><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝐊</ci><ci id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3">𝐕</ci></vector></apply></apply><apply id="S3.E3.m1.5.5.1.1c.cmml" xref="S3.E3.m1.5.5.1"><eq id="S3.E3.m1.5.5.1.1.5.cmml" xref="S3.E3.m1.5.5.1.1.5"></eq><share href="#S3.E3.m1.5.5.1.1.4.cmml" id="S3.E3.m1.5.5.1.1d.cmml" xref="S3.E3.m1.5.5.1"></share><apply id="S3.E3.m1.5.5.1.1.6.cmml" xref="S3.E3.m1.5.5.1.1.6"><times id="S3.E3.m1.5.5.1.1.6.1.cmml" xref="S3.E3.m1.5.5.1.1.6.1"></times><ci id="S3.E3.m1.5.5.1.1.6.2.cmml" xref="S3.E3.m1.5.5.1.1.6.2">𝑆</ci><ci id="S3.E3.m1.5.5.1.1.6.3.cmml" xref="S3.E3.m1.5.5.1.1.6.3">𝑜</ci><ci id="S3.E3.m1.5.5.1.1.6.4.cmml" xref="S3.E3.m1.5.5.1.1.6.4">𝑓</ci><ci id="S3.E3.m1.5.5.1.1.6.5.cmml" xref="S3.E3.m1.5.5.1.1.6.5">𝑡</ci><ci id="S3.E3.m1.5.5.1.1.6.6.cmml" xref="S3.E3.m1.5.5.1.1.6.6">𝑚</ci><ci id="S3.E3.m1.5.5.1.1.6.7.cmml" xref="S3.E3.m1.5.5.1.1.6.7">𝑎</ci><ci id="S3.E3.m1.5.5.1.1.6.8.cmml" xref="S3.E3.m1.5.5.1.1.6.8">𝑥</ci><apply id="S3.E3.m1.4.4.cmml" xref="S3.E3.m1.5.5.1.1.6.9.2"><divide id="S3.E3.m1.4.4.1.cmml" xref="S3.E3.m1.5.5.1.1.6.9.2"></divide><apply id="S3.E3.m1.4.4.2.cmml" xref="S3.E3.m1.4.4.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.2.1.cmml" xref="S3.E3.m1.4.4.2">superscript</csymbol><ci id="S3.E3.m1.4.4.2.2.cmml" xref="S3.E3.m1.4.4.2.2">𝐐𝐊</ci><csymbol cd="latexml" id="S3.E3.m1.4.4.2.3.cmml" xref="S3.E3.m1.4.4.2.3">top</csymbol></apply><apply id="S3.E3.m1.4.4.3.cmml" xref="S3.E3.m1.4.4.3"><root id="S3.E3.m1.4.4.3a.cmml" xref="S3.E3.m1.4.4.3"></root><apply id="S3.E3.m1.4.4.3.2.cmml" xref="S3.E3.m1.4.4.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.3.2.1.cmml" xref="S3.E3.m1.4.4.3.2">subscript</csymbol><ci id="S3.E3.m1.4.4.3.2.2.cmml" xref="S3.E3.m1.4.4.3.2.2">𝑑</ci><ci id="S3.E3.m1.4.4.3.2.3.cmml" xref="S3.E3.m1.4.4.3.2.3">𝑞</ci></apply></apply></apply><ci id="S3.E3.m1.5.5.1.1.6.10.cmml" xref="S3.E3.m1.5.5.1.1.6.10">𝐕</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.5c">\mathbf{Z}={SA}(\mathbf{Q},\mathbf{K},\mathbf{V})={Softmax}\left(\frac{\mathbf{Q}\mathbf{K}^{\top}}{\sqrt{d_{q}}}\right)\mathbf{V}.</annotation></semantics></math></td><td></td><td rowspan="1"><span>(3)</span></td></tr></tbody></table>

给定一个输入序列，自注意力机制允许每个元素关注所有其他元素，因此自注意力将输入编码为一个全连接图。因此，原始 Transformer 的编码器可以被视为一个全连接的 GNN 编码器，Transformer 家族具有全局感知的非局部能力，类似于非局部网络 \[[167](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib167)\]。

掩码自注意力（MSA） 实际上，修改 自注意力机制是必要的，以帮助 Transformer 的解码器学习上下文依赖，防止位置关注后续位置，以

<table id="S3.E4"><tbody><tr><td></td><td><math id="S3.E4.m1.4" alttext="\mathbf{Z}={MSA}(\mathbf{Q},\mathbf{K},\mathbf{V})={Softmax}\left(\frac{\mathbf{Q}\mathbf{K}^{\top}}{\sqrt{d_{q}}}\odot\mathbf{M}\right)\mathbf{V}," display="block"><semantics id="S3.E4.m1.4a"><mrow id="S3.E4.m1.4.4.1" xref="S3.E4.m1.4.4.1.1.cmml"><mrow id="S3.E4.m1.4.4.1.1" xref="S3.E4.m1.4.4.1.1.cmml"><mi id="S3.E4.m1.4.4.1.1.3" xref="S3.E4.m1.4.4.1.1.3.cmml">𝐙</mi><mo id="S3.E4.m1.4.4.1.1.4" xref="S3.E4.m1.4.4.1.1.4.cmml">=</mo><mrow id="S3.E4.m1.4.4.1.1.5" xref="S3.E4.m1.4.4.1.1.5.cmml"><mi id="S3.E4.m1.4.4.1.1.5.2" xref="S3.E4.m1.4.4.1.1.5.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.5.1" xref="S3.E4.m1.4.4.1.1.5.1.cmml"></mo><mi id="S3.E4.m1.4.4.1.1.5.3" xref="S3.E4.m1.4.4.1.1.5.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.5.1a" xref="S3.E4.m1.4.4.1.1.5.1.cmml"></mo><mi id="S3.E4.m1.4.4.1.1.5.4" xref="S3.E4.m1.4.4.1.1.5.4.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.5.1b" xref="S3.E4.m1.4.4.1.1.5.1.cmml"></mo><mrow id="S3.E4.m1.4.4.1.1.5.5.2" xref="S3.E4.m1.4.4.1.1.5.5.1.cmml"><mo stretchy="false" id="S3.E4.m1.4.4.1.1.5.5.2.1" xref="S3.E4.m1.4.4.1.1.5.5.1.cmml">(</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">𝐐</mi><mo id="S3.E4.m1.4.4.1.1.5.5.2.2" xref="S3.E4.m1.4.4.1.1.5.5.1.cmml">,</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">𝐊</mi><mo id="S3.E4.m1.4.4.1.1.5.5.2.3" xref="S3.E4.m1.4.4.1.1.5.5.1.cmml">,</mo><mi id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml">𝐕</mi><mo stretchy="false" id="S3.E4.m1.4.4.1.1.5.5.2.4" xref="S3.E4.m1.4.4.1.1.5.5.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.4.4.1.1.6" xref="S3.E4.m1.4.4.1.1.6.cmml">=</mo><mrow id="S3.E4.m1.4.4.1.1.1" xref="S3.E4.m1.4.4.1.1.1.cmml"><mi id="S3.E4.m1.4.4.1.1.1.3" xref="S3.E4.m1.4.4.1.1.1.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.2.cmml"></mo><mi id="S3.E4.m1.4.4.1.1.1.4" xref="S3.E4.m1.4.4.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.1.2a" xref="S3.E4.m1.4.4.1.1.1.2.cmml"></mo><mi id="S3.E4.m1.4.4.1.1.1.5" xref="S3.E4.m1.4.4.1.1.1.5.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.1.2b" xref="S3.E4.m1.4.4.1.1.1.2.cmml"></mo><mi id="S3.E4.m1.4.4.1.1.1.6" xref="S3.E4.m1.4.4.1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.1.2c" xref="S3.E4.m1.4.4.1.1.1.2.cmml"></mo><mi id="S3.E4.m1.4.4.1.1.1.7" xref="S3.E4.m1.4.4.1.1.1.7.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.1.2d" xref="S3.E4.m1.4.4.1.1.1.2.cmml"></mo><mi id="S3.E4.m1.4.4.1.1.1.8" xref="S3.E4.m1.4.4.1.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.1.2e" xref="S3.E4.m1.4.4.1.1.1.2.cmml"></mo><mi id="S3.E4.m1.4.4.1.1.1.9" xref="S3.E4.m1.4.4.1.1.1.9.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.1.2f" xref="S3.E4.m1.4.4.1.1.1.2.cmml"></mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.4.4.1.1.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.1.1.cmml"><mfrac id="S3.E4.m1.4.4.1.1.1.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.cmml"><msup id="S3.E4.m1.4.4.1.1.1.1.1.1.2.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E4.m1.4.4.1.1.1.1.1.1.2.2.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.2.2.cmml">𝐐𝐊</mi><mo id="S3.E4.m1.4.4.1.1.1.1.1.1.2.2.3" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.2.3.cmml">⊤</mo></msup><msqrt id="S3.E4.m1.4.4.1.1.1.1.1.1.2.3" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.cmml"><msub id="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2.cmml"><mi id="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2.2.cmml">d</mi><mi id="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2.3" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2.3.cmml">q</mi></msub></msqrt></mfrac><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.4.4.1.1.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.cmml">⊙</mo><mi id="S3.E4.m1.4.4.1.1.1.1.1.1.3" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.cmml">𝐌</mi></mrow><mo id="S3.E4.m1.4.4.1.1.1.1.1.3" xref="S3.E4.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.1.2g" xref="S3.E4.m1.4.4.1.1.1.2.cmml"></mo><mi id="S3.E4.m1.4.4.1.1.1.10" xref="S3.E4.m1.4.4.1.1.1.10.cmml">𝐕</mi></mrow></mrow><mo id="S3.E4.m1.4.4.1.2" xref="S3.E4.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.4b"><apply id="S3.E4.m1.4.4.1.1.cmml" xref="S3.E4.m1.4.4.1"><and id="S3.E4.m1.4.4.1.1a.cmml" xref="S3.E4.m1.4.4.1"></and><apply id="S3.E4.m1.4.4.1.1b.cmml" xref="S3.E4.m1.4.4.1"><eq id="S3.E4.m1.4.4.1.1.4.cmml" xref="S3.E4.m1.4.4.1.1.4"></eq><ci id="S3.E4.m1.4.4.1.1.3.cmml" xref="S3.E4.m1.4.4.1.1.3">𝐙</ci><apply id="S3.E4.m1.4.4.1.1.5.cmml" xref="S3.E4.m1.4.4.1.1.5"><times id="S3.E4.m1.4.4.1.1.5.1.cmml" xref="S3.E4.m1.4.4.1.1.5.1"></times><ci id="S3.E4.m1.4.4.1.1.5.2.cmml" xref="S3.E4.m1.4.4.1.1.5.2">𝑀</ci><ci id="S3.E4.m1.4.4.1.1.5.3.cmml" xref="S3.E4.m1.4.4.1.1.5.3">𝑆</ci><ci id="S3.E4.m1.4.4.1.1.5.4.cmml" xref="S3.E4.m1.4.4.1.1.5.4">𝐴</ci><vector id="S3.E4.m1.4.4.1.1.5.5.1.cmml" xref="S3.E4.m1.4.4.1.1.5.5.2"><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">𝐐</ci><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">𝐊</ci><ci id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3">𝐕</ci></vector></apply></apply><apply id="S3.E4.m1.4.4.1.1c.cmml" xref="S3.E4.m1.4.4.1"><eq id="S3.E4.m1.4.4.1.1.6.cmml" xref="S3.E4.m1.4.4.1.1.6"></eq><share href="#S3.E4.m1.4.4.1.1.5.cmml" id="S3.E4.m1.4.4.1.1d.cmml" xref="S3.E4.m1.4.4.1"></share><apply id="S3.E4.m1.4.4.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1"><times id="S3.E4.m1.4.4.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.2"></times><ci id="S3.E4.m1.4.4.1.1.1.3.cmml" xref="S3.E4.m1.4.4.1.1.1.3">𝑆</ci><ci id="S3.E4.m1.4.4.1.1.1.4.cmml" xref="S3.E4.m1.4.4.1.1.1.4">𝑜</ci><ci id="S3.E4.m1.4.4.1.1.1.5.cmml" xref="S3.E4.m1.4.4.1.1.1.5">𝑓</ci><ci id="S3.E4.m1.4.4.1.1.1.6.cmml" xref="S3.E4.m1.4.4.1.1.1.6">𝑡</ci><ci id="S3.E4.m1.4.4.1.1.1.7.cmml" xref="S3.E4.m1.4.4.1.1.1.7">𝑚</ci><ci id="S3.E4.m1.4.4.1.1.1.8.cmml" xref="S3.E4.m1.4.4.1.1.1.8">𝑎</ci><ci id="S3.E4.m1.4.4.1.1.1.9.cmml" xref="S3.E4.m1.4.4.1.1.1.9">𝑥</ci><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1">direct-product</csymbol><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2"><divide id="S3.E4.m1.4.4.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2"></divide><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.2">superscript</csymbol><ci id="S3.E4.m1.4.4.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.2.2">𝐐𝐊</ci><csymbol cd="latexml" id="S3.E4.m1.4.4.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.2.3">top</csymbol></apply><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.3"><root id="S3.E4.m1.4.4.1.1.1.1.1.1.2.3a.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.3"></root><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2">subscript</csymbol><ci id="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2.2">𝑑</ci><ci id="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.3.2.3">𝑞</ci></apply></apply></apply><ci id="S3.E4.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3">𝐌</ci></apply><ci id="S3.E4.m1.4.4.1.1.1.10.cmml" xref="S3.E4.m1.4.4.1.1.1.10">𝐕</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.4c">\mathbf{Z}={MSA}(\mathbf{Q},\mathbf{K},\mathbf{V})={Softmax}\left(\frac{\mathbf{Q}\mathbf{K}^{\top}}{\sqrt{d_{q}}}\odot\mathbf{M}\right)\mathbf{V},</annotation></semantics></math></td><td></td><td rowspan="1"><span>(4)</span></td></tr></tbody></table>

𝐌\\mathbf{M} 是一个掩码矩阵。例如，在 GPT \[[88](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib88)\] 中，一个上三角掩码用于启用前瞻注意力，其中每个标记只能查看过去的标记。掩码可以在 Transformer 的编码器 \[[168](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib168), [163](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib163)\] 和解码器中使用，并且具有灵活的实现，e。g。例如，0-1 硬掩码 \[[163](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib163)\]，软掩码 \[[168](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib168)\]。

在单模态和多模态实践中，都根据领域知识和先验知识设计了特定的掩码。本质上，MSA 用于向 Transformer 模型注入额外知识，例如，e。g。等。\[\[[163](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib163), [169](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib169), [24](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib24), [170](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib170)\]\]。

多头自注意力（MHSA） 实际上，多个自注意力子层可以并行堆叠，它们的连接输出通过一个投影矩阵 𝐖\\mathbf{W} 融合，形成一个名为多头自注意力的结构

<table id="S3.E5"><tbody><tr><td></td><td><math id="S3.E5.m1.5" alttext="\mathbf{Z}={MHSA}(\mathbf{Q},\mathbf{K},\mathbf{V})={concat}(\mathbf{Z}_{1},\cdots,\mathbf{Z}_{H})\textbf{W}," display="block"><semantics id="S3.E5.m1.5a"><mrow id="S3.E5.m1.5.5.1" xref="S3.E5.m1.5.5.1.1.cmml"><mrow id="S3.E5.m1.5.5.1.1" xref="S3.E5.m1.5.5.1.1.cmml"><mi id="S3.E5.m1.5.5.1.1.4" xref="S3.E5.m1.5.5.1.1.4.cmml">𝐙</mi><mo id="S3.E5.m1.5.5.1.1.5" xref="S3.E5.m1.5.5.1.1.5.cmml">=</mo><mrow id="S3.E5.m1.5.5.1.1.6" xref="S3.E5.m1.5.5.1.1.6.cmml"><mi id="S3.E5.m1.5.5.1.1.6.2" xref="S3.E5.m1.5.5.1.1.6.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.6.1" xref="S3.E5.m1.5.5.1.1.6.1.cmml"></mo><mi id="S3.E5.m1.5.5.1.1.6.3" xref="S3.E5.m1.5.5.1.1.6.3.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.6.1a" xref="S3.E5.m1.5.5.1.1.6.1.cmml"></mo><mi id="S3.E5.m1.5.5.1.1.6.4" xref="S3.E5.m1.5.5.1.1.6.4.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.6.1b" xref="S3.E5.m1.5.5.1.1.6.1.cmml"></mo><mi id="S3.E5.m1.5.5.1.1.6.5" xref="S3.E5.m1.5.5.1.1.6.5.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.6.1c" xref="S3.E5.m1.5.5.1.1.6.1.cmml"></mo><mrow id="S3.E5.m1.5.5.1.1.6.6.2" xref="S3.E5.m1.5.5.1.1.6.6.1.cmml"><mo stretchy="false" id="S3.E5.m1.5.5.1.1.6.6.2.1" xref="S3.E5.m1.5.5.1.1.6.6.1.cmml">(</mo><mi id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">𝐐</mi><mo id="S3.E5.m1.5.5.1.1.6.6.2.2" xref="S3.E5.m1.5.5.1.1.6.6.1.cmml">,</mo><mi id="S3.E5.m1.2.2" xref="S3.E5.m1.2.2.cmml">𝐊</mi><mo id="S3.E5.m1.5.5.1.1.6.6.2.3" xref="S3.E5.m1.5.5.1.1.6.6.1.cmml">,</mo><mi id="S3.E5.m1.3.3" xref="S3.E5.m1.3.3.cmml">𝐕</mi><mo stretchy="false" id="S3.E5.m1.5.5.1.1.6.6.2.4" xref="S3.E5.m1.5.5.1.1.6.6.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.5.5.1.1.7" xref="S3.E5.m1.5.5.1.1.7.cmml">=</mo><mrow id="S3.E5.m1.5.5.1.1.2" xref="S3.E5.m1.5.5.1.1.2.cmml"><mi id="S3.E5.m1.5.5.1.1.2.4" xref="S3.E5.m1.5.5.1.1.2.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.2.3" xref="S3.E5.m1.5.5.1.1.2.3.cmml"></mo><mi id="S3.E5.m1.5.5.1.1.2.5" xref="S3.E5.m1.5.5.1.1.2.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.2.3a" xref="S3.E5.m1.5.5.1.1.2.3.cmml"></mo><mi id="S3.E5.m1.5.5.1.1.2.6" xref="S3.E5.m1.5.5.1.1.2.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.2.3b" xref="S3.E5.m1.5.5.1.1.2.3.cmml"></mo><mi id="S3.E5.m1.5.5.1.1.2.7" xref="S3.E5.m1.5.5.1.1.2.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.2.3c" xref="S3.E5.m1.5.5.1.1.2.3.cmml"></mo><mi id="S3.E5.m1.5.5.1.1.2.8" xref="S3.E5.m1.5.5.1.1.2.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.2.3d" xref="S3.E5.m1.5.5.1.1.2.3.cmml"></mo><mi id="S3.E5.m1.5.5.1.1.2.9" xref="S3.E5.m1.5.5.1.1.2.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.2.3e" xref="S3.E5.m1.5.5.1.1.2.3.cmml"></mo><mrow id="S3.E5.m1.5.5.1.1.2.2.2" xref="S3.E5.m1.5.5.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E5.m1.5.5.1.1.2.2.2.3" xref="S3.E5.m1.5.5.1.1.2.2.3.cmml">(</mo><msub id="S3.E5.m1.5.5.1.1.1.1.1.1" xref="S3.E5.m1.5.5.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.5.5.1.1.1.1.1.1.2" xref="S3.E5.m1.5.5.1.1.1.1.1.1.2.cmml">𝐙</mi><mn id="S3.E5.m1.5.5.1.1.1.1.1.1.3" xref="S3.E5.m1.5.5.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.E5.m1.5.5.1.1.2.2.2.4" xref="S3.E5.m1.5.5.1.1.2.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.E5.m1.4.4" xref="S3.E5.m1.4.4.cmml">⋯</mi><mo id="S3.E5.m1.5.5.1.1.2.2.2.5" xref="S3.E5.m1.5.5.1.1.2.2.3.cmml">,</mo><msub id="S3.E5.m1.5.5.1.1.2.2.2.2" xref="S3.E5.m1.5.5.1.1.2.2.2.2.cmml"><mi id="S3.E5.m1.5.5.1.1.2.2.2.2.2" xref="S3.E5.m1.5.5.1.1.2.2.2.2.2.cmml">𝐙</mi><mi id="S3.E5.m1.5.5.1.1.2.2.2.2.3" xref="S3.E5.m1.5.5.1.1.2.2.2.2.3.cmml">H</mi></msub><mo stretchy="false" id="S3.E5.m1.5.5.1.1.2.2.2.6" xref="S3.E5.m1.5.5.1.1.2.2.3.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.2.3f" xref="S3.E5.m1.5.5.1.1.2.3.cmml"></mo><mtext id="S3.E5.m1.5.5.1.1.2.10" xref="S3.E5.m1.5.5.1.1.2.10a.cmml">W</mtext></mrow></mrow><mo id="S3.E5.m1.5.5.1.2" xref="S3.E5.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.5b"><apply id="S3.E5.m1.5.5.1.1.cmml" xref="S3.E5.m1.5.5.1"><and id="S3.E5.m1.5.5.1.1a.cmml" xref="S3.E5.m1.5.5.1"></and><apply id="S3.E5.m1.5.5.1.1b.cmml" xref="S3.E5.m1.5.5.1"><eq id="S3.E5.m1.5.5.1.1.5.cmml" xref="S3.E5.m1.5.5.1.1.5"></eq><ci id="S3.E5.m1.5.5.1.1.4.cmml" xref="S3.E5.m1.5.5.1.1.4">𝐙</ci><apply id="S3.E5.m1.5.5.1.1.6.cmml" xref="S3.E5.m1.5.5.1.1.6"><times id="S3.E5.m1.5.5.1.1.6.1.cmml" xref="S3.E5.m1.5.5.1.1.6.1"></times><ci id="S3.E5.m1.5.5.1.1.6.2.cmml" xref="S3.E5.m1.5.5.1.1.6.2">𝑀</ci><ci id="S3.E5.m1.5.5.1.1.6.3.cmml" xref="S3.E5.m1.5.5.1.1.6.3">𝐻</ci><ci id="S3.E5.m1.5.5.1.1.6.4.cmml" xref="S3.E5.m1.5.5.1.1.6.4">𝑆</ci><ci id="S3.E5.m1.5.5.1.1.6.5.cmml" xref="S3.E5.m1.5.5.1.1.6.5">𝐴</ci><vector id="S3.E5.m1.5.5.1.1.6.6.1.cmml" xref="S3.E5.m1.5.5.1.1.6.6.2"><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">𝐐</ci><ci id="S3.E5.m1.2.2.cmml" xref="S3.E5.m1.2.2">𝐊</ci><ci id="S3.E5.m1.3.3.cmml" xref="S3.E5.m1.3.3">𝐕</ci></vector></apply></apply><apply id="S3.E5.m1.5.5.1.1c.cmml" xref="S3.E5.m1.5.5.1"><eq id="S3.E5.m1.5.5.1.1.7.cmml" xref="S3.E5.m1.5.5.1.1.7"></eq><share href="#S3.E5.m1.5.5.1.1.6.cmml" id="S3.E5.m1.5.5.1.1d.cmml" xref="S3.E5.m1.5.5.1"></share><apply id="S3.E5.m1.5.5.1.1.2.cmml" xref="S3.E5.m1.5.5.1.1.2"><times id="S3.E5.m1.5.5.1.1.2.3.cmml" xref="S3.E5.m1.5.5.1.1.2.3"></times><ci id="S3.E5.m1.5.5.1.1.2.4.cmml" xref="S3.E5.m1.5.5.1.1.2.4">𝑐</ci><ci id="S3.E5.m1.5.5.1.1.2.5.cmml" xref="S3.E5.m1.5.5.1.1.2.5">𝑜</ci><ci id="S3.E5.m1.5.5.1.1.2.6.cmml" xref="S3.E5.m1.5.5.1.1.2.6">𝑛</ci><ci id="S3.E5.m1.5.5.1.1.2.7.cmml" xref="S3.E5.m1.5.5.1.1.2.7">𝑐</ci><ci id="S3.E5.m1.5.5.1.1.2.8.cmml" xref="S3.E5.m1.5.5.1.1.2.8">𝑎</ci><ci id="S3.E5.m1.5.5.1.1.2.9.cmml" xref="S3.E5.m1.5.5.1.1.2.9">𝑡</ci><vector id="S3.E5.m1.5.5.1.1.2.2.3.cmml" xref="S3.E5.m1.5.5.1.1.2.2.2"><apply id="S3.E5.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1.2">𝐙</ci><cn type="integer" id="S3.E5.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.1.3">1</cn></apply><ci id="S3.E5.m1.4.4.cmml" xref="S3.E5.m1.4.4">⋯</ci><apply id="S3.E5.m1.5.5.1.1.2.2.2.2.cmml" xref="S3.E5.m1.5.5.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.2.2.2.2.1.cmml" xref="S3.E5.m1.5.5.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E5.m1.5.5.1.1.2.2.2.2.2.cmml" xref="S3.E5.m1.5.5.1.1.2.2.2.2.2">𝐙</ci><ci id="S3.E5.m1.5.5.1.1.2.2.2.2.3.cmml" xref="S3.E5.m1.5.5.1.1.2.2.2.2.3">𝐻</ci></apply></vector><ci id="S3.E5.m1.5.5.1.1.2.10a.cmml" xref="S3.E5.m1.5.5.1.1.2.10"><mtext id="S3.E5.m1.5.5.1.1.2.10.cmml" xref="S3.E5.m1.5.5.1.1.2.10">W</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.5c">\mathbf{Z}={MHSA}(\mathbf{Q},\mathbf{K},\mathbf{V})={concat}(\mathbf{Z}_{1},\cdots,\mathbf{Z}_{H})\textbf{W},</annotation></semantics></math></td><td></td><td rowspan="1"><span>(5)</span></td></tr></tbody></table>

每个头 𝐙h\=SA(𝐐h,𝐊h𝐕h)subscriptsubscriptsubscriptsubscript\\mathbf{Z}\_{h}={SA}(\\mathbf{Q}\_{h},\\mathbf{K}\_{h}\\mathbf{V}\_{h}) 和 h∈\[1,H\]1h\\in\[1,H\] ，其中 W 是一个线性投影矩阵。MHSA（多头自注意力）的想法是一种集成。MHSA 帮助模型共同关注来自多个表示子空间的信息。

#### 3.1.3 前馈网络

多头注意力子层的输出将通过位置编码的前馈网络（FFN），该网络由连续的线性层和非线性激活组成。例如，一个两层 FFN 可以表示为：

<table id="S3.E6"><tbody><tr><td></td><td><math id="S3.E6.m1.2" alttext="FFN(\mathbf{Z})=\sigma(\mathbf{Z}\mathbf{W}_{1}+\mathbf{b}_{1})\mathbf{W}_{2}+\mathbf{b}_{2}," display="block"><semantics id="S3.E6.m1.2a"><mrow id="S3.E6.m1.2.2.1" xref="S3.E6.m1.2.2.1.1.cmml"><mrow id="S3.E6.m1.2.2.1.1" xref="S3.E6.m1.2.2.1.1.cmml"><mrow id="S3.E6.m1.2.2.1.1.3" xref="S3.E6.m1.2.2.1.1.3.cmml"><mi id="S3.E6.m1.2.2.1.1.3.2" xref="S3.E6.m1.2.2.1.1.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.3.1" xref="S3.E6.m1.2.2.1.1.3.1.cmml"></mo><mi id="S3.E6.m1.2.2.1.1.3.3" xref="S3.E6.m1.2.2.1.1.3.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.3.1a" xref="S3.E6.m1.2.2.1.1.3.1.cmml"></mo><mi id="S3.E6.m1.2.2.1.1.3.4" xref="S3.E6.m1.2.2.1.1.3.4.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.3.1b" xref="S3.E6.m1.2.2.1.1.3.1.cmml"></mo><mrow id="S3.E6.m1.2.2.1.1.3.5.2" xref="S3.E6.m1.2.2.1.1.3.cmml"><mo stretchy="false" id="S3.E6.m1.2.2.1.1.3.5.2.1" xref="S3.E6.m1.2.2.1.1.3.cmml">(</mo><mi id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml">𝐙</mi><mo stretchy="false" id="S3.E6.m1.2.2.1.1.3.5.2.2" xref="S3.E6.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.2.2.1.1.2" xref="S3.E6.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E6.m1.2.2.1.1.1" xref="S3.E6.m1.2.2.1.1.1.cmml"><mrow id="S3.E6.m1.2.2.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.cmml"><mi id="S3.E6.m1.2.2.1.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.1.2.cmml"></mo><mrow id="S3.E6.m1.2.2.1.1.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.2.2.1.1.1.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.2.2.1.1.1.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml"><msub id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">𝐙𝐖</mi><mn id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.3" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S3.E6.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml">+</mo><msub id="S3.E6.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.2.cmml">𝐛</mi><mn id="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.3" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.3.cmml">1</mn></msub></mrow><mo stretchy="false" id="S3.E6.m1.2.2.1.1.1.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.1.1.2a" xref="S3.E6.m1.2.2.1.1.1.1.2.cmml"></mo><msub id="S3.E6.m1.2.2.1.1.1.1.4" xref="S3.E6.m1.2.2.1.1.1.1.4.cmml"><mi id="S3.E6.m1.2.2.1.1.1.1.4.2" xref="S3.E6.m1.2.2.1.1.1.1.4.2.cmml">𝐖</mi><mn id="S3.E6.m1.2.2.1.1.1.1.4.3" xref="S3.E6.m1.2.2.1.1.1.1.4.3.cmml">2</mn></msub></mrow><mo id="S3.E6.m1.2.2.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.2.cmml">+</mo><msub id="S3.E6.m1.2.2.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.3.cmml"><mi id="S3.E6.m1.2.2.1.1.1.3.2" xref="S3.E6.m1.2.2.1.1.1.3.2.cmml">𝐛</mi><mn id="S3.E6.m1.2.2.1.1.1.3.3" xref="S3.E6.m1.2.2.1.1.1.3.3.cmml">2</mn></msub></mrow></mrow><mo id="S3.E6.m1.2.2.1.2" xref="S3.E6.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.2b"><apply id="S3.E6.m1.2.2.1.1.cmml" xref="S3.E6.m1.2.2.1"><eq id="S3.E6.m1.2.2.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.2"></eq><apply id="S3.E6.m1.2.2.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.3"><times id="S3.E6.m1.2.2.1.1.3.1.cmml" xref="S3.E6.m1.2.2.1.1.3.1"></times><ci id="S3.E6.m1.2.2.1.1.3.2.cmml" xref="S3.E6.m1.2.2.1.1.3.2">𝐹</ci><ci id="S3.E6.m1.2.2.1.1.3.3.cmml" xref="S3.E6.m1.2.2.1.1.3.3">𝐹</ci><ci id="S3.E6.m1.2.2.1.1.3.4.cmml" xref="S3.E6.m1.2.2.1.1.3.4">𝑁</ci><ci id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1">𝐙</ci></apply><apply id="S3.E6.m1.2.2.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1"><plus id="S3.E6.m1.2.2.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1.2"></plus><apply id="S3.E6.m1.2.2.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1"><times id="S3.E6.m1.2.2.1.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.2"></times><ci id="S3.E6.m1.2.2.1.1.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3">𝜎</ci><apply id="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1"><plus id="S3.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.1"></plus><apply id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.2">𝐙𝐖</ci><cn type="integer" id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.3">1</cn></apply><apply id="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.2">𝐛</ci><cn type="integer" id="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S3.E6.m1.2.2.1.1.1.1.4.cmml" xref="S3.E6.m1.2.2.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.1.1.4.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.4">subscript</csymbol><ci id="S3.E6.m1.2.2.1.1.1.1.4.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.4.2">𝐖</ci><cn type="integer" id="S3.E6.m1.2.2.1.1.1.1.4.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.4.3">2</cn></apply></apply><apply id="S3.E6.m1.2.2.1.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.1.3.1.cmml" xref="S3.E6.m1.2.2.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.2.2.1.1.1.3.2.cmml" xref="S3.E6.m1.2.2.1.1.1.3.2">𝐛</ci><cn type="integer" id="S3.E6.m1.2.2.1.1.1.3.3.cmml" xref="S3.E6.m1.2.2.1.1.1.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.2c">FFN(\mathbf{Z})=\sigma(\mathbf{Z}\mathbf{W}_{1}+\mathbf{b}_{1})\mathbf{W}_{2}+\mathbf{b}_{2},</annotation></semantics></math></td><td></td><td rowspan="1"><span>(6)</span></td></tr></tbody></table>

其中 𝐖1subscript1\\mathbf{W}\_{1} 、 𝐛1subscript1\\mathbf{b}\_{1} 、 𝐖2subscript2\\mathbf{W}\_{2} 和 𝐛2subscript2\\mathbf{b}\_{2} 表示两个线性变换的权重和偏置，而 σ(⋅)\\sigma(\\cdot) 是非线性激活，e。g。， ReLU(⋅)\\text{ReLU}(\\cdot) \[[171](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib171)\]， GELU(⋅)GELU(\\cdot) \[[172](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib172)\]。在一些 Transformer 文献中，FFN 也被称为多层感知器（MLP）。

### 3.2 视觉 Transformer

视觉 Transformer（ViT）<引用 id=0>\[<引用 id=1>5\] 具有针对图像的特定输入管道，其中输入图像必须分割成固定大小的（例如，e.g.， 16×16161616\\times 16 ， 32×32323232\\times 32 ）补丁。在经过线性嵌入层并添加位置嵌入后，所有补丁序列将由标准 Transformer 编码器进行编码。给定图像 𝐗∈ℝH×W×Csuperscript\\mathbf{X}\\in\\mathbb{R}^{H\\times W\\times C} （ HH 高度， WW 宽度， CC 通道），ViT 需要将 𝐗\\mathbf{X} 重塑为一个平铺的 2D 补丁序列： 𝐱p∈ℝ𝐍×(𝐏𝟐⋅𝐂)subscriptsuperscriptsuperscript2\\mathbf{x}\_{p}\\in\\mathbb{R}^{\\mathbf{N\\times(P^{2}\\cdot C)}} ，其中 (P×P)(P\\times P) 是补丁分辨率， N\=HW/P2superscript2N=HW/P^{2} 。为了进行分类，一种标准方法是在嵌入补丁序列之前添加一个额外的可学习嵌入“分类标记”\[CLASS\]：

<table id="S3.E7"><tbody><tr><td></td><td><math id="S3.E7.m1.3" alttext="\textbf{Z}\leftarrow concat(\texttt{[CLASS]},\mathbf{X}\mathbf{W})," display="block"><semantics id="S3.E7.m1.3a"><mrow id="S3.E7.m1.3.3.1" xref="S3.E7.m1.3.3.1.1.cmml"><mrow id="S3.E7.m1.3.3.1.1" xref="S3.E7.m1.3.3.1.1.cmml"><mtext id="S3.E7.m1.3.3.1.1.2" xref="S3.E7.m1.3.3.1.1.2a.cmml">Z</mtext><mo stretchy="false" id="S3.E7.m1.3.3.1.1.1" xref="S3.E7.m1.3.3.1.1.1.cmml">←</mo><mrow id="S3.E7.m1.3.3.1.1.3" xref="S3.E7.m1.3.3.1.1.3.cmml"><mi id="S3.E7.m1.3.3.1.1.3.2" xref="S3.E7.m1.3.3.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.3.3.1.1.3.1" xref="S3.E7.m1.3.3.1.1.3.1.cmml"></mo><mi id="S3.E7.m1.3.3.1.1.3.3" xref="S3.E7.m1.3.3.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.3.3.1.1.3.1a" xref="S3.E7.m1.3.3.1.1.3.1.cmml"></mo><mi id="S3.E7.m1.3.3.1.1.3.4" xref="S3.E7.m1.3.3.1.1.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.3.3.1.1.3.1b" xref="S3.E7.m1.3.3.1.1.3.1.cmml"></mo><mi id="S3.E7.m1.3.3.1.1.3.5" xref="S3.E7.m1.3.3.1.1.3.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.3.3.1.1.3.1c" xref="S3.E7.m1.3.3.1.1.3.1.cmml"></mo><mi id="S3.E7.m1.3.3.1.1.3.6" xref="S3.E7.m1.3.3.1.1.3.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.3.3.1.1.3.1d" xref="S3.E7.m1.3.3.1.1.3.1.cmml"></mo><mi id="S3.E7.m1.3.3.1.1.3.7" xref="S3.E7.m1.3.3.1.1.3.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.3.3.1.1.3.1e" xref="S3.E7.m1.3.3.1.1.3.1.cmml"></mo><mrow id="S3.E7.m1.3.3.1.1.3.8.2" xref="S3.E7.m1.3.3.1.1.3.8.1.cmml"><mo stretchy="false" id="S3.E7.m1.3.3.1.1.3.8.2.1" xref="S3.E7.m1.3.3.1.1.3.8.1.cmml">(</mo><mtext id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1a.cmml">[CLASS]</mtext><mo id="S3.E7.m1.3.3.1.1.3.8.2.2" xref="S3.E7.m1.3.3.1.1.3.8.1.cmml">,</mo><mi id="S3.E7.m1.2.2" xref="S3.E7.m1.2.2.cmml">𝐗𝐖</mi><mo stretchy="false" id="S3.E7.m1.3.3.1.1.3.8.2.3" xref="S3.E7.m1.3.3.1.1.3.8.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E7.m1.3.3.1.2" xref="S3.E7.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.3b"><apply id="S3.E7.m1.3.3.1.1.cmml" xref="S3.E7.m1.3.3.1"><ci id="S3.E7.m1.3.3.1.1.1.cmml" xref="S3.E7.m1.3.3.1.1.1">←</ci><ci id="S3.E7.m1.3.3.1.1.2a.cmml" xref="S3.E7.m1.3.3.1.1.2"><mtext id="S3.E7.m1.3.3.1.1.2.cmml" xref="S3.E7.m1.3.3.1.1.2">Z</mtext></ci><apply id="S3.E7.m1.3.3.1.1.3.cmml" xref="S3.E7.m1.3.3.1.1.3"><times id="S3.E7.m1.3.3.1.1.3.1.cmml" xref="S3.E7.m1.3.3.1.1.3.1"></times><ci id="S3.E7.m1.3.3.1.1.3.2.cmml" xref="S3.E7.m1.3.3.1.1.3.2">𝑐</ci><ci id="S3.E7.m1.3.3.1.1.3.3.cmml" xref="S3.E7.m1.3.3.1.1.3.3">𝑜</ci><ci id="S3.E7.m1.3.3.1.1.3.4.cmml" xref="S3.E7.m1.3.3.1.1.3.4">𝑛</ci><ci id="S3.E7.m1.3.3.1.1.3.5.cmml" xref="S3.E7.m1.3.3.1.1.3.5">𝑐</ci><ci id="S3.E7.m1.3.3.1.1.3.6.cmml" xref="S3.E7.m1.3.3.1.1.3.6">𝑎</ci><ci id="S3.E7.m1.3.3.1.1.3.7.cmml" xref="S3.E7.m1.3.3.1.1.3.7">𝑡</ci><interval closure="open" id="S3.E7.m1.3.3.1.1.3.8.1.cmml" xref="S3.E7.m1.3.3.1.1.3.8.2"><ci id="S3.E7.m1.1.1a.cmml" xref="S3.E7.m1.1.1"><mtext id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.1.1">[CLASS]</mtext></ci><ci id="S3.E7.m1.2.2.cmml" xref="S3.E7.m1.2.2">𝐗𝐖</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.3c">\textbf{Z}\leftarrow concat(\texttt{[CLASS]},\mathbf{X}\mathbf{W}),</annotation></semantics></math></td><td></td><td rowspan="1"><span>(7)</span></td></tr></tbody></table>

其中 𝐖\\mathbf{W} 表示投影。

表 I： 多模态输入的 Token 化与 Token 嵌入比较。 “ICD”：国际疾病分类。

### 3.3 多模态 Transformer

最近，大量 Transformer 在多种多模态任务中得到了广泛研究，并显示出在判别和生成任务中与各种模态兼容的能力。

在本节中，我们将回顾现有多模态 Transformer 模型的关键技术/设计，从多模态输入（第 3.3.1 节）、自注意力变体（第 3.3.2 节）和网络架构（第 3.3.3 节）的角度进行回顾。

#### 3.3.1 多模态输入

Transformer 系列是一种通用架构，可以被表述为一种通用图神经网络。具体来说，自注意力可以通过关注全局（非局部）模式，将每个输入处理为一个全连接图。因此，这种内在特性使得 Transformer 可以在一个模态无关的管道中工作，通过将每个标记的嵌入视为图中的一个节点，与各种模态兼容。

分词和嵌入处理 给定任意模态的输入， 用户只需执行两个主要步骤：(1) 对输入进行分词，(2) 选择一个嵌入空间来表示这些标记，然后将数据输入到 Transformer 中。 在实践中，对输入进行分词以及为分词选择嵌入对于 Transformer 至关重要，但同时也非常灵活，有许多替代方案。 例如，给定一张图像，分词和嵌入的解决方案不是唯一的。 用户可以选择或设计在多个粒度级别上的标记化——粗粒度与细粒度。 e.例如，使用对象检测器获得的 ROI（区域兴趣）和 CNN 特征作为标记和标记嵌入\[cite id=3\]\[[102](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib102)\]，使用补丁和线性投影作为标记和标记嵌入\[cite id=5\]\[[5](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib5)\]，或者使用由对象检测器和图生成器获得的图节点和 GNN 特征作为标记和标记嵌入\[cite id=7\]\[[181](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib181)\]。给定一个标记化计划，后续的嵌入方法可以多种多样。例如，对于视频输入，常见的标记化是将视频上的非重叠窗口（下采样）视为标记，然后可以通过各种 3D CNN 提取它们的嵌入，例如，VideoBERT\[cite id=11\]\[[7](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib7)\]，CBT\[cite id=13\]\[[107](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib107)\]和 UniVL\[cite id=15\]\[[117](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib117)\]使用 S3D\[cite id=17\]\[[186](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib186)\]，ActBERT 使用 ResNet-3D\[cite id=19\]\[[187](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib187)\]。

表 [我](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#S3.T1 "TABLE I ‣ 3.2 Vision Transformer ‣ 3 Transformers ‣ Multimodal Learning with Transformers: A Survey") 总结了针对 Transformers 的多模态输入的一些常见做法，包括 RGB、视频、音频/语音/音乐、文本、图等。

讨论 从几何拓扑的角度来看， 表 I 中列出的每种模态都可以被视为一个图。RGB 图像本质上是一个像素空间中的整洁网格图。视频和音频都是基于剪辑/段落的复杂空间图，涉及时间和语义模式。如果我们考虑绘图线条的关键点，2D 和 3D 绘图草图都是一种稀疏图。\[[163](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib163), [78](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib78)\] 与草图类似，人体姿态也是一种图。 三维点云是一个图，其中每个坐标是一个节点。 其他抽象模态也可以解释为图，例如，源代码 \[44\]，源代码的数据流 \[44\]，表格 \[18\]，SQL 数据库模式 \[25\]，文本问题图 \[24\]，以及电子健康记录（EHRs） \[184\]。

标记嵌入融合 实际上， Transformer 允许每个标记位置包含多个嵌入。 这是一种早期融合嵌入的方法，适用于单模态和多模态 Transformer 模型。（这将在后续章节中进一步讨论。） 最常见的融合方式是多个嵌入的 token-wise 求和，嵌入 e。嵌入 g，一个特定的 token 嵌入 ⊕direct-sum\\oplus 位置嵌入。与灵活的 token 化类似，token 嵌入融合也是灵活的，并且广泛应用于单模态和多模态 Transformer 应用。在\[[81](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib81)\]中，使用 token-wise 加权求和来执行多模态监控 AI 的 RGB 和灰度图像的早期融合。 特别是在多模态 Transformer 应用中，标记嵌入融合起着重要作用，因为各种嵌入可以通过标记级运算符进行融合，例如在 VisualBERT \[[104](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib104)\] 和 Unicoder-VL \[[108](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib108)\] 中，段嵌入按标记级添加以指示每个标记来自哪种模态（视觉或语言），VL-BERT \[[105](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib105)\] 通过“语言标记嵌入 ⊕direct-sum\\oplus 全图像视觉特征嵌入”将全局视觉上下文注入语言领域，InterBERT \[[188](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib188)\] 通过“ROI 嵌入 ⊕direct-sum\\oplus 位置嵌入”为 ROI 添加位置信息，在 ImageBERT \[[115](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib115)\] 中，融合了五种嵌入“图像嵌入 ⊕direct-sum\\oplus 位置嵌入 ⊕direct-sum\\oplus 语言嵌入 ⊕direct-sum\\oplus 段嵌入 ⊕direct-sum\\oplus 序列位置嵌入”。

表 II： 多模态交互/融合的自注意力变体。 α\\alpha 和 β\\beta 表示权重。 “Att.”：注意力；“Concat.”/“Con.”：连接 “Tfs”：Transformer 层。 N(A)subscriptN\_{(\\texttt{A})} 和 N(B)subscriptN\_{(\\texttt{B})} 表示两种模态的标记序列长度。

#### 3.3.2 多模态上下文中的自注意力变体

在多模态 Transformer 中，跨模态交互（例如，融合、对齐）本质上是通过自注意力及其变体来处理的。因此，在本节中，我们将从自注意力设计的角度回顾 Transformer 的主要多模态建模实践，包括（1）早期求和（按令牌加权），（2）早期连接，（3）分层注意力（多流到单流），（4）分层注意力（单流到多流），（5）交叉注意力，以及（6）交叉注意力到连接。参见表 II 和图 2。

为了简洁起见，我们将对双模态情况下的数学公式进行陈述和比较。请注意，所有讨论的自注意力及其变体都足够灵活，可以扩展到多模态情况。具体来说，以下公式对模态、分词和嵌入都是不可知的，因为自注意力将任意模态中任意标记的嵌入建模为图中的一个节点。

给定来自两种任意模态的输入 𝐗Asubscript\\mathbf{X}\_{\\texttt{A}} 和 𝐗Bsubscript\\mathbf{X}\_{\\texttt{B}} 𝐙(A)subscript\\mathbf{Z}\_{(\\texttt{A})} 和 𝐙(B)subscript\\mathbf{Z}\_{(\\texttt{B})} 分别表示它们各自的标记嵌入。令 𝐙\\mathbf{Z} 表示由多模态交互产生的标记嵌入（序列）。 Tf(⋅)Tf(\\cdot) 表示 Transformer 层/块的处理。

![Refer to caption](https://ar5iv.labs.arxiv.org/html/2206.06488/assets/x1.png)

![Refer to caption](https://ar5iv.labs.arxiv.org/html/2206.06488/assets/x2.png)

![Refer to caption](https://ar5iv.labs.arxiv.org/html/2206.06488/assets/x3.png)

![Refer to caption](https://ar5iv.labs.arxiv.org/html/2206.06488/assets/x4.png)

![Refer to caption](https://ar5iv.labs.arxiv.org/html/2206.06488/assets/x5.png)

![Refer to caption](https://ar5iv.labs.arxiv.org/html/2206.06488/assets/x6.png)

图 2：基于 Transformer 的跨模态交互：(a)早期求和，(b)早期连接，(c)分层注意力（多流到单流），(d)分层注意力（单流到多流），(e)交叉注意力，和(f)交叉注意力到连接。“Q”：查询嵌入；“K”：键嵌入；“V”：值嵌入。“TL”：Transformer 层。最佳以彩色查看。

(1) 早期求和 在实践中，早期求和<文献 id=1>\[<引用 id=2>46, <引用 id=3>81\]是一种简单有效的多模态交互，其中可以从多个模态中加权求和每个标记位置的标记嵌入，然后由 Transformer 层进行处理：

<table id="S3.E8"><tbody><tr><td></td><td><math id="S3.E8.m1.6" alttext="\mathbf{Z}\leftarrow Tf(\alpha\mathbf{Z}_{(\texttt{A})}\oplus\beta\mathbf{Z}_{(\texttt{B})})={MHSA}(\mathbf{Q}_{(\texttt{AB})},\mathbf{K}_{(\texttt{AB})},\mathbf{V}_{(\texttt{AB})})," display="block"><semantics id="S3.E8.m1.6a"><mrow id="S3.E8.m1.6.6.1" xref="S3.E8.m1.6.6.1.1.cmml"><mrow id="S3.E8.m1.6.6.1.1" xref="S3.E8.m1.6.6.1.1.cmml"><mi id="S3.E8.m1.6.6.1.1.6" xref="S3.E8.m1.6.6.1.1.6.cmml">𝐙</mi><mo stretchy="false" id="S3.E8.m1.6.6.1.1.7" xref="S3.E8.m1.6.6.1.1.7.cmml">←</mo><mrow id="S3.E8.m1.6.6.1.1.1" xref="S3.E8.m1.6.6.1.1.1.cmml"><mi id="S3.E8.m1.6.6.1.1.1.3" xref="S3.E8.m1.6.6.1.1.1.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.6.6.1.1.1.2" xref="S3.E8.m1.6.6.1.1.1.2.cmml"></mo><mi id="S3.E8.m1.6.6.1.1.1.4" xref="S3.E8.m1.6.6.1.1.1.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.6.6.1.1.1.2a" xref="S3.E8.m1.6.6.1.1.1.2.cmml"></mo><mrow id="S3.E8.m1.6.6.1.1.1.1.1" xref="S3.E8.m1.6.6.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E8.m1.6.6.1.1.1.1.1.2" xref="S3.E8.m1.6.6.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.6.6.1.1.1.1.1.1" xref="S3.E8.m1.6.6.1.1.1.1.1.1.cmml"><mrow id="S3.E8.m1.6.6.1.1.1.1.1.1.2" xref="S3.E8.m1.6.6.1.1.1.1.1.1.2.cmml"><mi id="S3.E8.m1.6.6.1.1.1.1.1.1.2.2" xref="S3.E8.m1.6.6.1.1.1.1.1.1.2.2.cmml">α</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.6.6.1.1.1.1.1.1.2.1" xref="S3.E8.m1.6.6.1.1.1.1.1.1.2.1.cmml"></mo><msub id="S3.E8.m1.6.6.1.1.1.1.1.1.2.3" xref="S3.E8.m1.6.6.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E8.m1.6.6.1.1.1.1.1.1.2.3.2" xref="S3.E8.m1.6.6.1.1.1.1.1.1.2.3.2.cmml">𝐙</mi><mrow id="S3.E8.m1.1.1.1.3" xref="S3.E8.m1.1.1.1.1a.cmml"><mo stretchy="false" id="S3.E8.m1.1.1.1.3.1" xref="S3.E8.m1.1.1.1.1a.cmml">(</mo><mtext id="S3.E8.m1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml">A</mtext><mo stretchy="false" id="S3.E8.m1.1.1.1.3.2" xref="S3.E8.m1.1.1.1.1a.cmml">)</mo></mrow></msub></mrow><mo id="S3.E8.m1.6.6.1.1.1.1.1.1.1" xref="S3.E8.m1.6.6.1.1.1.1.1.1.1.cmml">⊕</mo><mrow id="S3.E8.m1.6.6.1.1.1.1.1.1.3" xref="S3.E8.m1.6.6.1.1.1.1.1.1.3.cmml"><mi id="S3.E8.m1.6.6.1.1.1.1.1.1.3.2" xref="S3.E8.m1.6.6.1.1.1.1.1.1.3.2.cmml">β</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.6.6.1.1.1.1.1.1.3.1" xref="S3.E8.m1.6.6.1.1.1.1.1.1.3.1.cmml"></mo><msub id="S3.E8.m1.6.6.1.1.1.1.1.1.3.3" xref="S3.E8.m1.6.6.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E8.m1.6.6.1.1.1.1.1.1.3.3.2" xref="S3.E8.m1.6.6.1.1.1.1.1.1.3.3.2.cmml">𝐙</mi><mrow id="S3.E8.m1.2.2.1.3" xref="S3.E8.m1.2.2.1.1a.cmml"><mo stretchy="false" id="S3.E8.m1.2.2.1.3.1" xref="S3.E8.m1.2.2.1.1a.cmml">(</mo><mtext id="S3.E8.m1.2.2.1.1" xref="S3.E8.m1.2.2.1.1.cmml">B</mtext><mo stretchy="false" id="S3.E8.m1.2.2.1.3.2" xref="S3.E8.m1.2.2.1.1a.cmml">)</mo></mrow></msub></mrow></mrow><mo stretchy="false" id="S3.E8.m1.6.6.1.1.1.1.1.3" xref="S3.E8.m1.6.6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E8.m1.6.6.1.1.8" xref="S3.E8.m1.6.6.1.1.8.cmml">=</mo><mrow id="S3.E8.m1.6.6.1.1.4" xref="S3.E8.m1.6.6.1.1.4.cmml"><mi id="S3.E8.m1.6.6.1.1.4.5" xref="S3.E8.m1.6.6.1.1.4.5.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.6.6.1.1.4.4" xref="S3.E8.m1.6.6.1.1.4.4.cmml"></mo><mi id="S3.E8.m1.6.6.1.1.4.6" xref="S3.E8.m1.6.6.1.1.4.6.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.6.6.1.1.4.4a" xref="S3.E8.m1.6.6.1.1.4.4.cmml"></mo><mi id="S3.E8.m1.6.6.1.1.4.7" xref="S3.E8.m1.6.6.1.1.4.7.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.6.6.1.1.4.4b" xref="S3.E8.m1.6.6.1.1.4.4.cmml"></mo><mi id="S3.E8.m1.6.6.1.1.4.8" xref="S3.E8.m1.6.6.1.1.4.8.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.6.6.1.1.4.4c" xref="S3.E8.m1.6.6.1.1.4.4.cmml"></mo><mrow id="S3.E8.m1.6.6.1.1.4.3.3" xref="S3.E8.m1.6.6.1.1.4.3.4.cmml"><mo stretchy="false" id="S3.E8.m1.6.6.1.1.4.3.3.4" xref="S3.E8.m1.6.6.1.1.4.3.4.cmml">(</mo><msub id="S3.E8.m1.6.6.1.1.2.1.1.1" xref="S3.E8.m1.6.6.1.1.2.1.1.1.cmml"><mi id="S3.E8.m1.6.6.1.1.2.1.1.1.2" xref="S3.E8.m1.6.6.1.1.2.1.1.1.2.cmml">𝐐</mi><mrow id="S3.E8.m1.3.3.1.3" xref="S3.E8.m1.3.3.1.1a.cmml"><mo stretchy="false" id="S3.E8.m1.3.3.1.3.1" xref="S3.E8.m1.3.3.1.1a.cmml">(</mo><mtext id="S3.E8.m1.3.3.1.1" xref="S3.E8.m1.3.3.1.1.cmml">AB</mtext><mo stretchy="false" id="S3.E8.m1.3.3.1.3.2" xref="S3.E8.m1.3.3.1.1a.cmml">)</mo></mrow></msub><mo id="S3.E8.m1.6.6.1.1.4.3.3.5" xref="S3.E8.m1.6.6.1.1.4.3.4.cmml">,</mo><msub id="S3.E8.m1.6.6.1.1.3.2.2.2" xref="S3.E8.m1.6.6.1.1.3.2.2.2.cmml"><mi id="S3.E8.m1.6.6.1.1.3.2.2.2.2" xref="S3.E8.m1.6.6.1.1.3.2.2.2.2.cmml">𝐊</mi><mrow id="S3.E8.m1.4.4.1.3" xref="S3.E8.m1.4.4.1.1a.cmml"><mo stretchy="false" id="S3.E8.m1.4.4.1.3.1" xref="S3.E8.m1.4.4.1.1a.cmml">(</mo><mtext id="S3.E8.m1.4.4.1.1" xref="S3.E8.m1.4.4.1.1.cmml">AB</mtext><mo stretchy="false" id="S3.E8.m1.4.4.1.3.2" xref="S3.E8.m1.4.4.1.1a.cmml">)</mo></mrow></msub><mo id="S3.E8.m1.6.6.1.1.4.3.3.6" xref="S3.E8.m1.6.6.1.1.4.3.4.cmml">,</mo><msub id="S3.E8.m1.6.6.1.1.4.3.3.3" xref="S3.E8.m1.6.6.1.1.4.3.3.3.cmml"><mi id="S3.E8.m1.6.6.1.1.4.3.3.3.2" xref="S3.E8.m1.6.6.1.1.4.3.3.3.2.cmml">𝐕</mi><mrow id="S3.E8.m1.5.5.1.3" xref="S3.E8.m1.5.5.1.1a.cmml"><mo stretchy="false" id="S3.E8.m1.5.5.1.3.1" xref="S3.E8.m1.5.5.1.1a.cmml">(</mo><mtext id="S3.E8.m1.5.5.1.1" xref="S3.E8.m1.5.5.1.1.cmml">AB</mtext><mo stretchy="false" id="S3.E8.m1.5.5.1.3.2" xref="S3.E8.m1.5.5.1.1a.cmml">)</mo></mrow></msub><mo stretchy="false" id="S3.E8.m1.6.6.1.1.4.3.3.7" xref="S3.E8.m1.6.6.1.1.4.3.4.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E8.m1.6.6.1.2" xref="S3.E8.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.6b"><apply id="S3.E8.m1.6.6.1.1.cmml" xref="S3.E8.m1.6.6.1"><and id="S3.E8.m1.6.6.1.1a.cmml" xref="S3.E8.m1.6.6.1"></and><apply id="S3.E8.m1.6.6.1.1b.cmml" xref="S3.E8.m1.6.6.1"><ci id="S3.E8.m1.6.6.1.1.7.cmml" xref="S3.E8.m1.6.6.1.1.7">←</ci><ci id="S3.E8.m1.6.6.1.1.6.cmml" xref="S3.E8.m1.6.6.1.1.6">𝐙</ci><apply id="S3.E8.m1.6.6.1.1.1.cmml" xref="S3.E8.m1.6.6.1.1.1"><times id="S3.E8.m1.6.6.1.1.1.2.cmml" xref="S3.E8.m1.6.6.1.1.1.2"></times><ci id="S3.E8.m1.6.6.1.1.1.3.cmml" xref="S3.E8.m1.6.6.1.1.1.3">𝑇</ci><ci id="S3.E8.m1.6.6.1.1.1.4.cmml" xref="S3.E8.m1.6.6.1.1.1.4">𝑓</ci><apply id="S3.E8.m1.6.6.1.1.1.1.1.1.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1"><csymbol cd="latexml" id="S3.E8.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1.1.1">direct-sum</csymbol><apply id="S3.E8.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1.1.2"><times id="S3.E8.m1.6.6.1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1.1.2.1"></times><ci id="S3.E8.m1.6.6.1.1.1.1.1.1.2.2.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1.1.2.2">𝛼</ci><apply id="S3.E8.m1.6.6.1.1.1.1.1.1.2.3.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E8.m1.6.6.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E8.m1.6.6.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1.1.2.3.2">𝐙</ci><ci id="S3.E8.m1.1.1.1.1a.cmml" xref="S3.E8.m1.1.1.1.3"><mtext mathsize="70%" id="S3.E8.m1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1">A</mtext></ci></apply></apply><apply id="S3.E8.m1.6.6.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1.1.3"><times id="S3.E8.m1.6.6.1.1.1.1.1.1.3.1.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1.1.3.1"></times><ci id="S3.E8.m1.6.6.1.1.1.1.1.1.3.2.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1.1.3.2">𝛽</ci><apply id="S3.E8.m1.6.6.1.1.1.1.1.1.3.3.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E8.m1.6.6.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E8.m1.6.6.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E8.m1.6.6.1.1.1.1.1.1.3.3.2">𝐙</ci><ci id="S3.E8.m1.2.2.1.1a.cmml" xref="S3.E8.m1.2.2.1.3"><mtext mathsize="70%" id="S3.E8.m1.2.2.1.1.cmml" xref="S3.E8.m1.2.2.1.1">B</mtext></ci></apply></apply></apply></apply></apply><apply id="S3.E8.m1.6.6.1.1c.cmml" xref="S3.E8.m1.6.6.1"><eq id="S3.E8.m1.6.6.1.1.8.cmml" xref="S3.E8.m1.6.6.1.1.8"></eq><share href="#S3.E8.m1.6.6.1.1.1.cmml" id="S3.E8.m1.6.6.1.1d.cmml" xref="S3.E8.m1.6.6.1"></share><apply id="S3.E8.m1.6.6.1.1.4.cmml" xref="S3.E8.m1.6.6.1.1.4"><times id="S3.E8.m1.6.6.1.1.4.4.cmml" xref="S3.E8.m1.6.6.1.1.4.4"></times><ci id="S3.E8.m1.6.6.1.1.4.5.cmml" xref="S3.E8.m1.6.6.1.1.4.5">𝑀</ci><ci id="S3.E8.m1.6.6.1.1.4.6.cmml" xref="S3.E8.m1.6.6.1.1.4.6">𝐻</ci><ci id="S3.E8.m1.6.6.1.1.4.7.cmml" xref="S3.E8.m1.6.6.1.1.4.7">𝑆</ci><ci id="S3.E8.m1.6.6.1.1.4.8.cmml" xref="S3.E8.m1.6.6.1.1.4.8">𝐴</ci><vector id="S3.E8.m1.6.6.1.1.4.3.4.cmml" xref="S3.E8.m1.6.6.1.1.4.3.3"><apply id="S3.E8.m1.6.6.1.1.2.1.1.1.cmml" xref="S3.E8.m1.6.6.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.6.6.1.1.2.1.1.1.1.cmml" xref="S3.E8.m1.6.6.1.1.2.1.1.1">subscript</csymbol><ci id="S3.E8.m1.6.6.1.1.2.1.1.1.2.cmml" xref="S3.E8.m1.6.6.1.1.2.1.1.1.2">𝐐</ci><ci id="S3.E8.m1.3.3.1.1a.cmml" xref="S3.E8.m1.3.3.1.3"><mtext mathsize="70%" id="S3.E8.m1.3.3.1.1.cmml" xref="S3.E8.m1.3.3.1.1">AB</mtext></ci></apply><apply id="S3.E8.m1.6.6.1.1.3.2.2.2.cmml" xref="S3.E8.m1.6.6.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.E8.m1.6.6.1.1.3.2.2.2.1.cmml" xref="S3.E8.m1.6.6.1.1.3.2.2.2">subscript</csymbol><ci id="S3.E8.m1.6.6.1.1.3.2.2.2.2.cmml" xref="S3.E8.m1.6.6.1.1.3.2.2.2.2">𝐊</ci><ci id="S3.E8.m1.4.4.1.1a.cmml" xref="S3.E8.m1.4.4.1.3"><mtext mathsize="70%" id="S3.E8.m1.4.4.1.1.cmml" xref="S3.E8.m1.4.4.1.1">AB</mtext></ci></apply><apply id="S3.E8.m1.6.6.1.1.4.3.3.3.cmml" xref="S3.E8.m1.6.6.1.1.4.3.3.3"><csymbol cd="ambiguous" id="S3.E8.m1.6.6.1.1.4.3.3.3.1.cmml" xref="S3.E8.m1.6.6.1.1.4.3.3.3">subscript</csymbol><ci id="S3.E8.m1.6.6.1.1.4.3.3.3.2.cmml" xref="S3.E8.m1.6.6.1.1.4.3.3.3.2">𝐕</ci><ci id="S3.E8.m1.5.5.1.1a.cmml" xref="S3.E8.m1.5.5.1.3"><mtext mathsize="70%" id="S3.E8.m1.5.5.1.1.cmml" xref="S3.E8.m1.5.5.1.1">AB</mtext></ci></apply></vector></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.6c">\mathbf{Z}\leftarrow Tf(\alpha\mathbf{Z}_{(\texttt{A})}\oplus\beta\mathbf{Z}_{(\texttt{B})})={MHSA}(\mathbf{Q}_{(\texttt{AB})},\mathbf{K}_{(\texttt{AB})},\mathbf{V}_{(\texttt{AB})}),</annotation></semantics></math></td><td></td><td rowspan="1"><span>(8)</span></td></tr></tbody></table>

其中 ⊕direct-sum\\oplus 是逐元素求和， α\\alpha 和 β\\beta 是权重。具体来说， 𝐐(AB)\=(α𝐙(A)⊕β𝐙(B))𝐖(AB)Qsubscriptdirect-sumsubscriptsubscriptsubscriptsuperscript\\mathbf{Q}\_{(\\texttt{AB})}=(\\alpha\\mathbf{Z}\_{(\\texttt{A})}\\oplus\\beta\\mathbf{Z}\_{(\\texttt{B})})\\mathbf{W}^{Q}\_{(\\texttt{AB})} 、 𝐊(AB)\=(α𝐙(A)⊕β𝐙(B))𝐖(AB)Ksubscriptdirect-sumsubscriptsubscriptsubscriptsuperscript\\mathbf{K}\_{(\\texttt{AB})}=(\\alpha\\mathbf{Z}\_{(\\texttt{A})}\\oplus\\beta\\mathbf{Z}\_{(\\texttt{B})})\\mathbf{W}^{K}\_{(\\texttt{AB})} 和 𝐕(AB)\=(α𝐙(A)⊕β𝐙(B))𝐖(AB)Vsubscriptdirect-sumsubscriptsubscriptsubscriptsuperscript\\mathbf{V}\_{(\\texttt{AB})}=(\\alpha\\mathbf{Z}\_{(\\texttt{A})}\\oplus\\beta\\mathbf{Z}\_{(\\texttt{B})})\\mathbf{W}^{V}\_{(\\texttt{AB})} 。其主要优点是不增加计算复杂度。然而，其主要缺点是由于手动设置的权重。如第 3.1.1 节和第 3.3.1 节所述，求和位置嵌入本质上是一种早期求和的情况。

(2) 早期级联 另一个简单直接的解决方案是早期连接 \[[7](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib7), [44](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib44), [178](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib178), [180](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib180)\]，即将来自多个模态的标记嵌入序列连接起来，然后输入到 Transformer 层作为

<table id="S3.E9"><tbody><tr><td></td><td><math id="S3.E9.m1.3" alttext="\mathbf{Z}\leftarrow Tf(\mathcal{C}(\mathbf{Z}_{(\texttt{A})},\mathbf{Z}_{(\texttt{B})}))." display="block"><semantics id="S3.E9.m1.3a"><mrow id="S3.E9.m1.3.3.1" xref="S3.E9.m1.3.3.1.1.cmml"><mrow id="S3.E9.m1.3.3.1.1" xref="S3.E9.m1.3.3.1.1.cmml"><mi id="S3.E9.m1.3.3.1.1.3" xref="S3.E9.m1.3.3.1.1.3.cmml">𝐙</mi><mo stretchy="false" id="S3.E9.m1.3.3.1.1.2" xref="S3.E9.m1.3.3.1.1.2.cmml">←</mo><mrow id="S3.E9.m1.3.3.1.1.1" xref="S3.E9.m1.3.3.1.1.1.cmml"><mi id="S3.E9.m1.3.3.1.1.1.3" xref="S3.E9.m1.3.3.1.1.1.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.3.3.1.1.1.2" xref="S3.E9.m1.3.3.1.1.1.2.cmml"></mo><mi id="S3.E9.m1.3.3.1.1.1.4" xref="S3.E9.m1.3.3.1.1.1.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.3.3.1.1.1.2a" xref="S3.E9.m1.3.3.1.1.1.2.cmml"></mo><mrow id="S3.E9.m1.3.3.1.1.1.1.1" xref="S3.E9.m1.3.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E9.m1.3.3.1.1.1.1.1.2" xref="S3.E9.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E9.m1.3.3.1.1.1.1.1.1" xref="S3.E9.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S3.E9.m1.3.3.1.1.1.1.1.1.4" xref="S3.E9.m1.3.3.1.1.1.1.1.1.4.cmml">𝒞</mi><mo lspace="0em" rspace="0em" id="S3.E9.m1.3.3.1.1.1.1.1.1.3" xref="S3.E9.m1.3.3.1.1.1.1.1.1.3.cmml"></mo><mrow id="S3.E9.m1.3.3.1.1.1.1.1.1.2.2" xref="S3.E9.m1.3.3.1.1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.E9.m1.3.3.1.1.1.1.1.1.2.2.3" xref="S3.E9.m1.3.3.1.1.1.1.1.1.2.3.cmml">(</mo><msub id="S3.E9.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E9.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E9.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.E9.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">𝐙</mi><mrow id="S3.E9.m1.1.1.1.3" xref="S3.E9.m1.1.1.1.1a.cmml"><mo stretchy="false" id="S3.E9.m1.1.1.1.3.1" xref="S3.E9.m1.1.1.1.1a.cmml">(</mo><mtext id="S3.E9.m1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.cmml">A</mtext><mo stretchy="false" id="S3.E9.m1.1.1.1.3.2" xref="S3.E9.m1.1.1.1.1a.cmml">)</mo></mrow></msub><mo id="S3.E9.m1.3.3.1.1.1.1.1.1.2.2.4" xref="S3.E9.m1.3.3.1.1.1.1.1.1.2.3.cmml">,</mo><msub id="S3.E9.m1.3.3.1.1.1.1.1.1.2.2.2" xref="S3.E9.m1.3.3.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E9.m1.3.3.1.1.1.1.1.1.2.2.2.2" xref="S3.E9.m1.3.3.1.1.1.1.1.1.2.2.2.2.cmml">𝐙</mi><mrow id="S3.E9.m1.2.2.1.3" xref="S3.E9.m1.2.2.1.1a.cmml"><mo stretchy="false" id="S3.E9.m1.2.2.1.3.1" xref="S3.E9.m1.2.2.1.1a.cmml">(</mo><mtext id="S3.E9.m1.2.2.1.1" xref="S3.E9.m1.2.2.1.1.cmml">B</mtext><mo stretchy="false" id="S3.E9.m1.2.2.1.3.2" xref="S3.E9.m1.2.2.1.1a.cmml">)</mo></mrow></msub><mo stretchy="false" id="S3.E9.m1.3.3.1.1.1.1.1.1.2.2.5" xref="S3.E9.m1.3.3.1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E9.m1.3.3.1.1.1.1.1.3" xref="S3.E9.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E9.m1.3.3.1.2" xref="S3.E9.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E9.m1.3b"><apply id="S3.E9.m1.3.3.1.1.cmml" xref="S3.E9.m1.3.3.1"><ci id="S3.E9.m1.3.3.1.1.2.cmml" xref="S3.E9.m1.3.3.1.1.2">←</ci><ci id="S3.E9.m1.3.3.1.1.3.cmml" xref="S3.E9.m1.3.3.1.1.3">𝐙</ci><apply id="S3.E9.m1.3.3.1.1.1.cmml" xref="S3.E9.m1.3.3.1.1.1"><times id="S3.E9.m1.3.3.1.1.1.2.cmml" xref="S3.E9.m1.3.3.1.1.1.2"></times><ci id="S3.E9.m1.3.3.1.1.1.3.cmml" xref="S3.E9.m1.3.3.1.1.1.3">𝑇</ci><ci id="S3.E9.m1.3.3.1.1.1.4.cmml" xref="S3.E9.m1.3.3.1.1.1.4">𝑓</ci><apply id="S3.E9.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1"><times id="S3.E9.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.1.3"></times><ci id="S3.E9.m1.3.3.1.1.1.1.1.1.4.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.1.4">𝒞</ci><interval closure="open" id="S3.E9.m1.3.3.1.1.1.1.1.1.2.3.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.1.2.2"><apply id="S3.E9.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E9.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.1.1.1.1.2">𝐙</ci><ci id="S3.E9.m1.1.1.1.1a.cmml" xref="S3.E9.m1.1.1.1.3"><mtext mathsize="70%" id="S3.E9.m1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1">A</mtext></ci></apply><apply id="S3.E9.m1.3.3.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E9.m1.3.3.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E9.m1.3.3.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E9.m1.3.3.1.1.1.1.1.1.2.2.2.2">𝐙</ci><ci id="S3.E9.m1.2.2.1.1a.cmml" xref="S3.E9.m1.2.2.1.3"><mtext mathsize="70%" id="S3.E9.m1.2.2.1.1.cmml" xref="S3.E9.m1.2.2.1.1">B</mtext></ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E9.m1.3c">\mathbf{Z}\leftarrow Tf(\mathcal{C}(\mathbf{Z}_{(\texttt{A})},\mathbf{Z}_{(\texttt{B})})).</annotation></semantics></math></td><td></td><td rowspan="1"><span>(9)</span></td></tr></tbody></table>

因此，所有多模态标记位置可以作为一个整体序列进行关注，这样可以通过条件其他模态的上下文来很好地编码每个模态的位置。VideoBERT 是第一个多模态 Transformer 工作之一，其中视频和文本通过早期拼接融合，可以很好地编码全局多模态上下文\[[188](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib188)\]。然而，拼接后的较长序列会增加计算复杂度。早期拼接也被称为“全注意力”或“Co-Transformer”\[[137](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib137)\]。

(3) 层次化注意力（多流到单流）Transformer 层可以按层次组合以关注跨模态交互。一种常见做法是将多模态输入编码为独立的 Transformer 流，然后通过另一个 Transformer 将它们的输出连接和融合\[[146](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib146)\]：

<table id="S3.E10"><tbody><tr><td></td><td><math id="S3.E10.m1.3" alttext="\mathbf{Z}\leftarrow Tf_{3}(\mathcal{C}(Tf_{1}(\mathbf{Z}_{(\texttt{A})}),Tf_{2}(\mathbf{Z}_{(\texttt{B})})))." display="block"><semantics id="S3.E10.m1.3a"><mrow id="S3.E10.m1.3.3.1" xref="S3.E10.m1.3.3.1.1.cmml"><mrow id="S3.E10.m1.3.3.1.1" xref="S3.E10.m1.3.3.1.1.cmml"><mi id="S3.E10.m1.3.3.1.1.3" xref="S3.E10.m1.3.3.1.1.3.cmml">𝐙</mi><mo stretchy="false" id="S3.E10.m1.3.3.1.1.2" xref="S3.E10.m1.3.3.1.1.2.cmml">←</mo><mrow id="S3.E10.m1.3.3.1.1.1" xref="S3.E10.m1.3.3.1.1.1.cmml"><mi id="S3.E10.m1.3.3.1.1.1.3" xref="S3.E10.m1.3.3.1.1.1.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E10.m1.3.3.1.1.1.2" xref="S3.E10.m1.3.3.1.1.1.2.cmml"></mo><msub id="S3.E10.m1.3.3.1.1.1.4" xref="S3.E10.m1.3.3.1.1.1.4.cmml"><mi id="S3.E10.m1.3.3.1.1.1.4.2" xref="S3.E10.m1.3.3.1.1.1.4.2.cmml">f</mi><mn id="S3.E10.m1.3.3.1.1.1.4.3" xref="S3.E10.m1.3.3.1.1.1.4.3.cmml">3</mn></msub><mo lspace="0em" rspace="0em" id="S3.E10.m1.3.3.1.1.1.2a" xref="S3.E10.m1.3.3.1.1.1.2.cmml"></mo><mrow id="S3.E10.m1.3.3.1.1.1.1.1" xref="S3.E10.m1.3.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E10.m1.3.3.1.1.1.1.1.2" xref="S3.E10.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E10.m1.3.3.1.1.1.1.1.1" xref="S3.E10.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S3.E10.m1.3.3.1.1.1.1.1.1.4" xref="S3.E10.m1.3.3.1.1.1.1.1.1.4.cmml">𝒞</mi><mo lspace="0em" rspace="0em" id="S3.E10.m1.3.3.1.1.1.1.1.1.3" xref="S3.E10.m1.3.3.1.1.1.1.1.1.3.cmml"></mo><mrow id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.3" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.3.cmml">(</mo><mrow id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml"></mo><msub id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4.cmml"><mi id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4.2" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.cmml">f</mi><mn id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4.3" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.2a" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml"></mo><mrow id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">𝐙</mi><mrow id="S3.E10.m1.1.1.1.3" xref="S3.E10.m1.1.1.1.1a.cmml"><mo stretchy="false" id="S3.E10.m1.1.1.1.3.1" xref="S3.E10.m1.1.1.1.1a.cmml">(</mo><mtext id="S3.E10.m1.1.1.1.1" xref="S3.E10.m1.1.1.1.1.cmml">A</mtext><mo stretchy="false" id="S3.E10.m1.1.1.1.3.2" xref="S3.E10.m1.1.1.1.1a.cmml">)</mo></mrow></msub><mo stretchy="false" id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.4" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.3.cmml">,</mo><mrow id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.3" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.2" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.2.cmml"></mo><msub id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4.cmml"><mi id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4.2" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4.2.cmml">f</mi><mn id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4.3" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.2a" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.2.cmml"></mo><mrow id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1.2" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1.1.cmml">(</mo><msub id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1.1" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1.1.cmml"><mi id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1.1.2" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1.1.2.cmml">𝐙</mi><mrow id="S3.E10.m1.2.2.1.3" xref="S3.E10.m1.2.2.1.1a.cmml"><mo stretchy="false" id="S3.E10.m1.2.2.1.3.1" xref="S3.E10.m1.2.2.1.1a.cmml">(</mo><mtext id="S3.E10.m1.2.2.1.1" xref="S3.E10.m1.2.2.1.1.cmml">B</mtext><mo stretchy="false" id="S3.E10.m1.2.2.1.3.2" xref="S3.E10.m1.2.2.1.1a.cmml">)</mo></mrow></msub><mo stretchy="false" id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1.3" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.5" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E10.m1.3.3.1.1.1.1.1.3" xref="S3.E10.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E10.m1.3.3.1.2" xref="S3.E10.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E10.m1.3b"><apply id="S3.E10.m1.3.3.1.1.cmml" xref="S3.E10.m1.3.3.1"><ci id="S3.E10.m1.3.3.1.1.2.cmml" xref="S3.E10.m1.3.3.1.1.2">←</ci><ci id="S3.E10.m1.3.3.1.1.3.cmml" xref="S3.E10.m1.3.3.1.1.3">𝐙</ci><apply id="S3.E10.m1.3.3.1.1.1.cmml" xref="S3.E10.m1.3.3.1.1.1"><times id="S3.E10.m1.3.3.1.1.1.2.cmml" xref="S3.E10.m1.3.3.1.1.1.2"></times><ci id="S3.E10.m1.3.3.1.1.1.3.cmml" xref="S3.E10.m1.3.3.1.1.1.3">𝑇</ci><apply id="S3.E10.m1.3.3.1.1.1.4.cmml" xref="S3.E10.m1.3.3.1.1.1.4"><csymbol cd="ambiguous" id="S3.E10.m1.3.3.1.1.1.4.1.cmml" xref="S3.E10.m1.3.3.1.1.1.4">subscript</csymbol><ci id="S3.E10.m1.3.3.1.1.1.4.2.cmml" xref="S3.E10.m1.3.3.1.1.1.4.2">𝑓</ci><cn type="integer" id="S3.E10.m1.3.3.1.1.1.4.3.cmml" xref="S3.E10.m1.3.3.1.1.1.4.3">3</cn></apply><apply id="S3.E10.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1"><times id="S3.E10.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.3"></times><ci id="S3.E10.m1.3.3.1.1.1.1.1.1.4.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.4">𝒞</ci><interval closure="open" id="S3.E10.m1.3.3.1.1.1.1.1.1.2.3.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2"><apply id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1"><times id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.3">𝑇</ci><apply id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4.2">𝑓</ci><cn type="integer" id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.4.3">1</cn></apply><apply id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2">𝐙</ci><ci id="S3.E10.m1.1.1.1.1a.cmml" xref="S3.E10.m1.1.1.1.3"><mtext mathsize="70%" id="S3.E10.m1.1.1.1.1.cmml" xref="S3.E10.m1.1.1.1.1">A</mtext></ci></apply></apply><apply id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2"><times id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.2"></times><ci id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.3">𝑇</ci><apply id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4.1.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4">subscript</csymbol><ci id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4.2.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4.2">𝑓</ci><cn type="integer" id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4.3.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.4.3">2</cn></apply><apply id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1.1.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1.1.1.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1">subscript</csymbol><ci id="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1.1.2.cmml" xref="S3.E10.m1.3.3.1.1.1.1.1.1.2.2.2.1.1.1.2">𝐙</ci><ci id="S3.E10.m1.2.2.1.1a.cmml" xref="S3.E10.m1.2.2.1.3"><mtext mathsize="70%" id="S3.E10.m1.2.2.1.1.cmml" xref="S3.E10.m1.2.2.1.1">B</mtext></ci></apply></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E10.m1.3c">\mathbf{Z}\leftarrow Tf_{3}(\mathcal{C}(Tf_{1}(\mathbf{Z}_{(\texttt{A})}),Tf_{2}(\mathbf{Z}_{(\texttt{B})}))).</annotation></semantics></math></td><td></td><td rowspan="1"><span>(10)</span></td></tr></tbody></table>

这种分层注意力是后期交互/融合的实现，可以被视为早期拼接的特殊情况。

(4) 层次化注意力（单流到多流）InterBERT \[[188](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib188)\] 是另一种层次化注意力的良好实践，其中连接的多模态输入由一个共享的单流 Transformer 编码，随后是两个独立的 Transformer 流。这种流程可以表示为

<table id="S3.E11"><tbody><tr><td></td><td><math id="S3.E11.m1.13" alttext="\left\{\begin{aligned} {\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0}\mathcal{C}(}\mathbf{Z}_{(\texttt{A})},\mathbf{Z}_{(\texttt{B})}{\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0})}&amp;\leftarrow Tf_{1}(\mathcal{C}(\mathbf{Z}_{(\texttt{A})},\mathbf{Z}_{(\texttt{B})})),\\
\mathbf{Z}_{(\texttt{A})}&amp;\leftarrow Tf_{2}(\mathbf{Z}_{(\texttt{A})}),\\
\mathbf{Z}_{(\texttt{B})}&amp;\leftarrow Tf_{3}(\mathbf{Z}_{(\texttt{B})}).\end{aligned}\right." display="block"><semantics id="S3.E11.m1.13a"><mrow id="S3.E11.m1.13b"><mo id="S3.E11.m1.13.14">{</mo><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt" id="S3.E11.m1.13.13"><mtr id="S3.E11.m1.13.13a"><mtd columnalign="right" id="S3.E11.m1.13.13b"><mrow id="S3.E11.m1.4.4.4.4.4"><mi mathcolor="#000000" id="S3.E11.m1.4.4.4.4.4.6">𝒞</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.4.4.4.4.4.5"></mo><mrow id="S3.E11.m1.4.4.4.4.4.4.2"><mo mathcolor="#000000" stretchy="false" id="S3.E11.m1.4.4.4.4.4.4.2.3">(</mo><msub id="S3.E11.m1.3.3.3.3.3.3.1.1"><mi id="S3.E11.m1.3.3.3.3.3.3.1.1.2">𝐙</mi><mrow id="S3.E11.m1.1.1.1.1.1.1.1.3"><mo stretchy="false" id="S3.E11.m1.1.1.1.1.1.1.1.3.1">(</mo><mtext id="S3.E11.m1.1.1.1.1.1.1.1.1">A</mtext><mo stretchy="false" id="S3.E11.m1.1.1.1.1.1.1.1.3.2">)</mo></mrow></msub><mo id="S3.E11.m1.4.4.4.4.4.4.2.4">,</mo><msub id="S3.E11.m1.4.4.4.4.4.4.2.2"><mi id="S3.E11.m1.4.4.4.4.4.4.2.2.2">𝐙</mi><mrow id="S3.E11.m1.2.2.2.2.2.2.1.3"><mo stretchy="false" id="S3.E11.m1.2.2.2.2.2.2.1.3.1">(</mo><mtext id="S3.E11.m1.2.2.2.2.2.2.1.1">B</mtext><mo stretchy="false" id="S3.E11.m1.2.2.2.2.2.2.1.3.2">)</mo></mrow></msub><mo mathcolor="#000000" stretchy="false" id="S3.E11.m1.4.4.4.4.4.4.2.5">)</mo></mrow></mrow></mtd><mtd columnalign="left" id="S3.E11.m1.13.13c"><mrow id="S3.E11.m1.7.7.7.7.3.3"><mrow id="S3.E11.m1.7.7.7.7.3.3.1"><mi id="S3.E11.m1.7.7.7.7.3.3.1.3"></mi><mo stretchy="false" id="S3.E11.m1.7.7.7.7.3.3.1.2">←</mo><mrow id="S3.E11.m1.7.7.7.7.3.3.1.1"><mi id="S3.E11.m1.7.7.7.7.3.3.1.1.3">T</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.7.7.7.7.3.3.1.1.2"></mo><msub id="S3.E11.m1.7.7.7.7.3.3.1.1.4"><mi id="S3.E11.m1.7.7.7.7.3.3.1.1.4.2">f</mi><mn id="S3.E11.m1.7.7.7.7.3.3.1.1.4.3">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.E11.m1.7.7.7.7.3.3.1.1.2a"></mo><mrow id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1"><mo stretchy="false" id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1.2">(</mo><mrow id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1.1"><mi id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1.1.4">𝒞</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1.1.3"></mo><mrow id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1.1.2.2"><mo stretchy="false" id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1.1.2.2.3">(</mo><msub id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1.1.1.1.1"><mi id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1.1.1.1.1.2">𝐙</mi><mrow id="S3.E11.m1.5.5.5.5.1.1.1.3"><mo stretchy="false" id="S3.E11.m1.5.5.5.5.1.1.1.3.1">(</mo><mtext id="S3.E11.m1.5.5.5.5.1.1.1.1">A</mtext><mo stretchy="false" id="S3.E11.m1.5.5.5.5.1.1.1.3.2">)</mo></mrow></msub><mo id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1.1.2.2.4">,</mo><msub id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1.1.2.2.2"><mi id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1.1.2.2.2.2">𝐙</mi><mrow id="S3.E11.m1.6.6.6.6.2.2.1.3"><mo stretchy="false" id="S3.E11.m1.6.6.6.6.2.2.1.3.1">(</mo><mtext id="S3.E11.m1.6.6.6.6.2.2.1.1">B</mtext><mo stretchy="false" id="S3.E11.m1.6.6.6.6.2.2.1.3.2">)</mo></mrow></msub><mo stretchy="false" id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1.1.2.2.5">)</mo></mrow></mrow><mo stretchy="false" id="S3.E11.m1.7.7.7.7.3.3.1.1.1.1.3">)</mo></mrow></mrow></mrow><mo id="S3.E11.m1.7.7.7.7.3.3.2">,</mo></mrow></mtd></mtr><mtr id="S3.E11.m1.13.13d"><mtd columnalign="right" id="S3.E11.m1.13.13e"><msub id="S3.E11.m1.8.8.8.1.1"><mi id="S3.E11.m1.8.8.8.1.1.3">𝐙</mi><mrow id="S3.E11.m1.8.8.8.1.1.1.1.3"><mo stretchy="false" id="S3.E11.m1.8.8.8.1.1.1.1.3.1">(</mo><mtext id="S3.E11.m1.8.8.8.1.1.1.1.1">A</mtext><mo stretchy="false" id="S3.E11.m1.8.8.8.1.1.1.1.3.2">)</mo></mrow></msub></mtd><mtd columnalign="left" id="S3.E11.m1.13.13f"><mrow id="S3.E11.m1.10.10.10.3.2.2"><mrow id="S3.E11.m1.10.10.10.3.2.2.1"><mi id="S3.E11.m1.10.10.10.3.2.2.1.3"></mi><mo stretchy="false" id="S3.E11.m1.10.10.10.3.2.2.1.2">←</mo><mrow id="S3.E11.m1.10.10.10.3.2.2.1.1"><mi id="S3.E11.m1.10.10.10.3.2.2.1.1.3">T</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.10.10.10.3.2.2.1.1.2"></mo><msub id="S3.E11.m1.10.10.10.3.2.2.1.1.4"><mi id="S3.E11.m1.10.10.10.3.2.2.1.1.4.2">f</mi><mn id="S3.E11.m1.10.10.10.3.2.2.1.1.4.3">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.E11.m1.10.10.10.3.2.2.1.1.2a"></mo><mrow id="S3.E11.m1.10.10.10.3.2.2.1.1.1.1"><mo stretchy="false" id="S3.E11.m1.10.10.10.3.2.2.1.1.1.1.2">(</mo><msub id="S3.E11.m1.10.10.10.3.2.2.1.1.1.1.1"><mi id="S3.E11.m1.10.10.10.3.2.2.1.1.1.1.1.2">𝐙</mi><mrow id="S3.E11.m1.9.9.9.2.1.1.1.3"><mo stretchy="false" id="S3.E11.m1.9.9.9.2.1.1.1.3.1">(</mo><mtext id="S3.E11.m1.9.9.9.2.1.1.1.1">A</mtext><mo stretchy="false" id="S3.E11.m1.9.9.9.2.1.1.1.3.2">)</mo></mrow></msub><mo stretchy="false" id="S3.E11.m1.10.10.10.3.2.2.1.1.1.1.3">)</mo></mrow></mrow></mrow><mo id="S3.E11.m1.10.10.10.3.2.2.2">,</mo></mrow></mtd></mtr><mtr id="S3.E11.m1.13.13g"><mtd columnalign="right" id="S3.E11.m1.13.13h"><msub id="S3.E11.m1.11.11.11.1.1"><mi id="S3.E11.m1.11.11.11.1.1.3">𝐙</mi><mrow id="S3.E11.m1.11.11.11.1.1.1.1.3"><mo stretchy="false" id="S3.E11.m1.11.11.11.1.1.1.1.3.1">(</mo><mtext id="S3.E11.m1.11.11.11.1.1.1.1.1">B</mtext><mo stretchy="false" id="S3.E11.m1.11.11.11.1.1.1.1.3.2">)</mo></mrow></msub></mtd><mtd columnalign="left" id="S3.E11.m1.13.13i"><mrow id="S3.E11.m1.13.13.13.3.2.2"><mrow id="S3.E11.m1.13.13.13.3.2.2.1"><mi id="S3.E11.m1.13.13.13.3.2.2.1.3"></mi><mo stretchy="false" id="S3.E11.m1.13.13.13.3.2.2.1.2">←</mo><mrow id="S3.E11.m1.13.13.13.3.2.2.1.1"><mi id="S3.E11.m1.13.13.13.3.2.2.1.1.3">T</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.13.13.13.3.2.2.1.1.2"></mo><msub id="S3.E11.m1.13.13.13.3.2.2.1.1.4"><mi id="S3.E11.m1.13.13.13.3.2.2.1.1.4.2">f</mi><mn id="S3.E11.m1.13.13.13.3.2.2.1.1.4.3">3</mn></msub><mo lspace="0em" rspace="0em" id="S3.E11.m1.13.13.13.3.2.2.1.1.2a"></mo><mrow id="S3.E11.m1.13.13.13.3.2.2.1.1.1.1"><mo stretchy="false" id="S3.E11.m1.13.13.13.3.2.2.1.1.1.1.2">(</mo><msub id="S3.E11.m1.13.13.13.3.2.2.1.1.1.1.1"><mi id="S3.E11.m1.13.13.13.3.2.2.1.1.1.1.1.2">𝐙</mi><mrow id="S3.E11.m1.12.12.12.2.1.1.1.3"><mo stretchy="false" id="S3.E11.m1.12.12.12.2.1.1.1.3.1">(</mo><mtext id="S3.E11.m1.12.12.12.2.1.1.1.1">B</mtext><mo stretchy="false" id="S3.E11.m1.12.12.12.2.1.1.1.3.2">)</mo></mrow></msub><mo stretchy="false" id="S3.E11.m1.13.13.13.3.2.2.1.1.1.1.3">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E11.m1.13.13.13.3.2.2.2">.</mo></mrow></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex" id="S3.E11.m1.13c">\left\{\begin{aligned} {\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0}\mathcal{C}(}\mathbf{Z}_{(\texttt{A})},\mathbf{Z}_{(\texttt{B})}{\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0})}&amp;\leftarrow Tf_{1}(\mathcal{C}(\mathbf{Z}_{(\texttt{A})},\mathbf{Z}_{(\texttt{B})})),\\ \mathbf{Z}_{(\texttt{A})}&amp;\leftarrow Tf_{2}(\mathbf{Z}_{(\texttt{A})}),\\ \mathbf{Z}_{(\texttt{B})}&amp;\leftarrow Tf_{3}(\mathbf{Z}_{(\texttt{B})}).\end{aligned}\right.</annotation></semantics></math></td><td></td><td rowspan="1"><span>(11)</span></td></tr></tbody></table>

该方法感知跨模态交互，同时保持单模态表示的独立性。

(5) 跨注意力 对于双流 Transformer，如果在跨流方式下交换/调换 𝐐\\mathbf{Q} （查询）嵌入，也可以感知跨模态交互。这种方法被称为交叉注意力或共注意力\[[190](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib190)\]，它最初在 VilBERT\[[102](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib102)\]中被提出：

<table id="S3.E12"><tbody><tr><td></td><td><math id="S3.E12.m1.4" alttext="\left\{\begin{aligned} \mathbf{Z}_{(\texttt{A})}&amp;\leftarrow{MHSA}(\mathbf{Q}_{\texttt{B}},\mathbf{K}_{\texttt{A}},\mathbf{V}_{\texttt{A}}),\\
\mathbf{Z}_{(\texttt{B})}&amp;\leftarrow{MHSA}(\mathbf{Q}_{\texttt{A}},\mathbf{K}_{\texttt{B}},\mathbf{V}_{\texttt{B}}).\end{aligned}\right." display="block"><semantics id="S3.E12.m1.4a"><mrow id="S3.E12.m1.4b"><mo id="S3.E12.m1.4.5">{</mo><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt" id="S3.E12.m1.4.4"><mtr id="S3.E12.m1.4.4a"><mtd columnalign="right" id="S3.E12.m1.4.4b"><msub id="S3.E12.m1.1.1.1.1.1"><mi id="S3.E12.m1.1.1.1.1.1.3">𝐙</mi><mrow id="S3.E12.m1.1.1.1.1.1.1.1.3"><mo stretchy="false" id="S3.E12.m1.1.1.1.1.1.1.1.3.1">(</mo><mtext id="S3.E12.m1.1.1.1.1.1.1.1.1">A</mtext><mo stretchy="false" id="S3.E12.m1.1.1.1.1.1.1.1.3.2">)</mo></mrow></msub></mtd><mtd columnalign="left" id="S3.E12.m1.4.4c"><mrow id="S3.E12.m1.2.2.2.2.1.1"><mrow id="S3.E12.m1.2.2.2.2.1.1.1"><mi id="S3.E12.m1.2.2.2.2.1.1.1.5"></mi><mo stretchy="false" id="S3.E12.m1.2.2.2.2.1.1.1.4">←</mo><mrow id="S3.E12.m1.2.2.2.2.1.1.1.3"><mi id="S3.E12.m1.2.2.2.2.1.1.1.3.5">M</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.2.2.2.2.1.1.1.3.4"></mo><mi id="S3.E12.m1.2.2.2.2.1.1.1.3.6">H</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.2.2.2.2.1.1.1.3.4a"></mo><mi id="S3.E12.m1.2.2.2.2.1.1.1.3.7">S</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.2.2.2.2.1.1.1.3.4b"></mo><mi id="S3.E12.m1.2.2.2.2.1.1.1.3.8">A</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.2.2.2.2.1.1.1.3.4c"></mo><mrow id="S3.E12.m1.2.2.2.2.1.1.1.3.3.3"><mo stretchy="false" id="S3.E12.m1.2.2.2.2.1.1.1.3.3.3.4">(</mo><msub id="S3.E12.m1.2.2.2.2.1.1.1.1.1.1.1"><mi id="S3.E12.m1.2.2.2.2.1.1.1.1.1.1.1.2">𝐐</mi><mtext id="S3.E12.m1.2.2.2.2.1.1.1.1.1.1.1.3">B</mtext></msub><mo id="S3.E12.m1.2.2.2.2.1.1.1.3.3.3.5">,</mo><msub id="S3.E12.m1.2.2.2.2.1.1.1.2.2.2.2"><mi id="S3.E12.m1.2.2.2.2.1.1.1.2.2.2.2.2">𝐊</mi><mtext id="S3.E12.m1.2.2.2.2.1.1.1.2.2.2.2.3">A</mtext></msub><mo id="S3.E12.m1.2.2.2.2.1.1.1.3.3.3.6">,</mo><msub id="S3.E12.m1.2.2.2.2.1.1.1.3.3.3.3"><mi id="S3.E12.m1.2.2.2.2.1.1.1.3.3.3.3.2">𝐕</mi><mtext id="S3.E12.m1.2.2.2.2.1.1.1.3.3.3.3.3">A</mtext></msub><mo stretchy="false" id="S3.E12.m1.2.2.2.2.1.1.1.3.3.3.7">)</mo></mrow></mrow></mrow><mo id="S3.E12.m1.2.2.2.2.1.1.2">,</mo></mrow></mtd></mtr><mtr id="S3.E12.m1.4.4d"><mtd columnalign="right" id="S3.E12.m1.4.4e"><msub id="S3.E12.m1.3.3.3.1.1"><mi id="S3.E12.m1.3.3.3.1.1.3">𝐙</mi><mrow id="S3.E12.m1.3.3.3.1.1.1.1.3"><mo stretchy="false" id="S3.E12.m1.3.3.3.1.1.1.1.3.1">(</mo><mtext id="S3.E12.m1.3.3.3.1.1.1.1.1">B</mtext><mo stretchy="false" id="S3.E12.m1.3.3.3.1.1.1.1.3.2">)</mo></mrow></msub></mtd><mtd columnalign="left" id="S3.E12.m1.4.4f"><mrow id="S3.E12.m1.4.4.4.2.1.1"><mrow id="S3.E12.m1.4.4.4.2.1.1.1"><mi id="S3.E12.m1.4.4.4.2.1.1.1.5"></mi><mo stretchy="false" id="S3.E12.m1.4.4.4.2.1.1.1.4">←</mo><mrow id="S3.E12.m1.4.4.4.2.1.1.1.3"><mi id="S3.E12.m1.4.4.4.2.1.1.1.3.5">M</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.4.4.4.2.1.1.1.3.4"></mo><mi id="S3.E12.m1.4.4.4.2.1.1.1.3.6">H</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.4.4.4.2.1.1.1.3.4a"></mo><mi id="S3.E12.m1.4.4.4.2.1.1.1.3.7">S</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.4.4.4.2.1.1.1.3.4b"></mo><mi id="S3.E12.m1.4.4.4.2.1.1.1.3.8">A</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.4.4.4.2.1.1.1.3.4c"></mo><mrow id="S3.E12.m1.4.4.4.2.1.1.1.3.3.3"><mo stretchy="false" id="S3.E12.m1.4.4.4.2.1.1.1.3.3.3.4">(</mo><msub id="S3.E12.m1.4.4.4.2.1.1.1.1.1.1.1"><mi id="S3.E12.m1.4.4.4.2.1.1.1.1.1.1.1.2">𝐐</mi><mtext id="S3.E12.m1.4.4.4.2.1.1.1.1.1.1.1.3">A</mtext></msub><mo id="S3.E12.m1.4.4.4.2.1.1.1.3.3.3.5">,</mo><msub id="S3.E12.m1.4.4.4.2.1.1.1.2.2.2.2"><mi id="S3.E12.m1.4.4.4.2.1.1.1.2.2.2.2.2">𝐊</mi><mtext id="S3.E12.m1.4.4.4.2.1.1.1.2.2.2.2.3">B</mtext></msub><mo id="S3.E12.m1.4.4.4.2.1.1.1.3.3.3.6">,</mo><msub id="S3.E12.m1.4.4.4.2.1.1.1.3.3.3.3"><mi id="S3.E12.m1.4.4.4.2.1.1.1.3.3.3.3.2">𝐕</mi><mtext id="S3.E12.m1.4.4.4.2.1.1.1.3.3.3.3.3">B</mtext></msub><mo stretchy="false" id="S3.E12.m1.4.4.4.2.1.1.1.3.3.3.7">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E12.m1.4.4.4.2.1.1.2">.</mo></mrow></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex" id="S3.E12.m1.4c">\left\{\begin{aligned} \mathbf{Z}_{(\texttt{A})}&amp;\leftarrow{MHSA}(\mathbf{Q}_{\texttt{B}},\mathbf{K}_{\texttt{A}},\mathbf{V}_{\texttt{A}}),\\ \mathbf{Z}_{(\texttt{B})}&amp;\leftarrow{MHSA}(\mathbf{Q}_{\texttt{A}},\mathbf{K}_{\texttt{B}},\mathbf{V}_{\texttt{B}}).\end{aligned}\right.</annotation></semantics></math></td><td></td><td rowspan="1"><span>(12)</span></td></tr></tbody></table>

跨注意力机制根据其他模态对每个模态进行关注，不会引起更高的计算复杂度；然而，如果为每个模态考虑，这种方法无法全局执行跨模态注意力，从而失去了整个上下文。如参考文献\[[188](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib188)\]中所述，双流跨注意力可以学习跨模态交互，而在每个模态内部没有对自身上下文进行自注意力。

（6）交叉注意力到拼接 两个交叉注意力流可以进一步连接并由另一个 Transformer 处理以建模全局上下文。 这种层次化的跨模态交互也得到广泛研究 <参考文献 id=3>\[\[参考文献 id=4\]189, \[参考文献 id=5\]137\]，并缓解了交叉注意力机制的缺点。

<table id="S3.E13"><tbody><tr><td></td><td><math id="S3.E13.m1.7" alttext="\left\{\begin{aligned} \mathbf{Z}_{(\texttt{A})}&amp;\leftarrow{MHSA}(\mathbf{Q}_{\texttt{B}},\mathbf{K}_{\texttt{A}},\mathbf{V}_{\texttt{A}}),\\
\mathbf{Z}_{(\texttt{B})}&amp;\leftarrow{MHSA}(\mathbf{Q}_{\texttt{A}},\mathbf{K}_{\texttt{B}},\mathbf{V}_{\texttt{B}}),\\
\mathbf{Z}&amp;\leftarrow Tf(\mathcal{C}(\mathbf{Z}_{(\texttt{A})},\mathbf{Z}_{(\texttt{B})})).\end{aligned}\right." display="block"><semantics id="S3.E13.m1.7a"><mrow id="S3.E13.m1.7b"><mo id="S3.E13.m1.7.8">{</mo><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt" id="S3.E13.m1.7.7"><mtr id="S3.E13.m1.7.7a"><mtd columnalign="right" id="S3.E13.m1.7.7b"><msub id="S3.E13.m1.1.1.1.1.1"><mi id="S3.E13.m1.1.1.1.1.1.3">𝐙</mi><mrow id="S3.E13.m1.1.1.1.1.1.1.1.3"><mo stretchy="false" id="S3.E13.m1.1.1.1.1.1.1.1.3.1">(</mo><mtext id="S3.E13.m1.1.1.1.1.1.1.1.1">A</mtext><mo stretchy="false" id="S3.E13.m1.1.1.1.1.1.1.1.3.2">)</mo></mrow></msub></mtd><mtd columnalign="left" id="S3.E13.m1.7.7c"><mrow id="S3.E13.m1.2.2.2.2.1.1"><mrow id="S3.E13.m1.2.2.2.2.1.1.1"><mi id="S3.E13.m1.2.2.2.2.1.1.1.5"></mi><mo stretchy="false" id="S3.E13.m1.2.2.2.2.1.1.1.4">←</mo><mrow id="S3.E13.m1.2.2.2.2.1.1.1.3"><mi id="S3.E13.m1.2.2.2.2.1.1.1.3.5">M</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.2.2.2.2.1.1.1.3.4"></mo><mi id="S3.E13.m1.2.2.2.2.1.1.1.3.6">H</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.2.2.2.2.1.1.1.3.4a"></mo><mi id="S3.E13.m1.2.2.2.2.1.1.1.3.7">S</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.2.2.2.2.1.1.1.3.4b"></mo><mi id="S3.E13.m1.2.2.2.2.1.1.1.3.8">A</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.2.2.2.2.1.1.1.3.4c"></mo><mrow id="S3.E13.m1.2.2.2.2.1.1.1.3.3.3"><mo stretchy="false" id="S3.E13.m1.2.2.2.2.1.1.1.3.3.3.4">(</mo><msub id="S3.E13.m1.2.2.2.2.1.1.1.1.1.1.1"><mi id="S3.E13.m1.2.2.2.2.1.1.1.1.1.1.1.2">𝐐</mi><mtext id="S3.E13.m1.2.2.2.2.1.1.1.1.1.1.1.3">B</mtext></msub><mo id="S3.E13.m1.2.2.2.2.1.1.1.3.3.3.5">,</mo><msub id="S3.E13.m1.2.2.2.2.1.1.1.2.2.2.2"><mi id="S3.E13.m1.2.2.2.2.1.1.1.2.2.2.2.2">𝐊</mi><mtext id="S3.E13.m1.2.2.2.2.1.1.1.2.2.2.2.3">A</mtext></msub><mo id="S3.E13.m1.2.2.2.2.1.1.1.3.3.3.6">,</mo><msub id="S3.E13.m1.2.2.2.2.1.1.1.3.3.3.3"><mi id="S3.E13.m1.2.2.2.2.1.1.1.3.3.3.3.2">𝐕</mi><mtext id="S3.E13.m1.2.2.2.2.1.1.1.3.3.3.3.3">A</mtext></msub><mo stretchy="false" id="S3.E13.m1.2.2.2.2.1.1.1.3.3.3.7">)</mo></mrow></mrow></mrow><mo id="S3.E13.m1.2.2.2.2.1.1.2">,</mo></mrow></mtd></mtr><mtr id="S3.E13.m1.7.7d"><mtd columnalign="right" id="S3.E13.m1.7.7e"><msub id="S3.E13.m1.3.3.3.1.1"><mi id="S3.E13.m1.3.3.3.1.1.3">𝐙</mi><mrow id="S3.E13.m1.3.3.3.1.1.1.1.3"><mo stretchy="false" id="S3.E13.m1.3.3.3.1.1.1.1.3.1">(</mo><mtext id="S3.E13.m1.3.3.3.1.1.1.1.1">B</mtext><mo stretchy="false" id="S3.E13.m1.3.3.3.1.1.1.1.3.2">)</mo></mrow></msub></mtd><mtd columnalign="left" id="S3.E13.m1.7.7f"><mrow id="S3.E13.m1.4.4.4.2.1.1"><mrow id="S3.E13.m1.4.4.4.2.1.1.1"><mi id="S3.E13.m1.4.4.4.2.1.1.1.5"></mi><mo stretchy="false" id="S3.E13.m1.4.4.4.2.1.1.1.4">←</mo><mrow id="S3.E13.m1.4.4.4.2.1.1.1.3"><mi id="S3.E13.m1.4.4.4.2.1.1.1.3.5">M</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.4.4.4.2.1.1.1.3.4"></mo><mi id="S3.E13.m1.4.4.4.2.1.1.1.3.6">H</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.4.4.4.2.1.1.1.3.4a"></mo><mi id="S3.E13.m1.4.4.4.2.1.1.1.3.7">S</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.4.4.4.2.1.1.1.3.4b"></mo><mi id="S3.E13.m1.4.4.4.2.1.1.1.3.8">A</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.4.4.4.2.1.1.1.3.4c"></mo><mrow id="S3.E13.m1.4.4.4.2.1.1.1.3.3.3"><mo stretchy="false" id="S3.E13.m1.4.4.4.2.1.1.1.3.3.3.4">(</mo><msub id="S3.E13.m1.4.4.4.2.1.1.1.1.1.1.1"><mi id="S3.E13.m1.4.4.4.2.1.1.1.1.1.1.1.2">𝐐</mi><mtext id="S3.E13.m1.4.4.4.2.1.1.1.1.1.1.1.3">A</mtext></msub><mo id="S3.E13.m1.4.4.4.2.1.1.1.3.3.3.5">,</mo><msub id="S3.E13.m1.4.4.4.2.1.1.1.2.2.2.2"><mi id="S3.E13.m1.4.4.4.2.1.1.1.2.2.2.2.2">𝐊</mi><mtext id="S3.E13.m1.4.4.4.2.1.1.1.2.2.2.2.3">B</mtext></msub><mo id="S3.E13.m1.4.4.4.2.1.1.1.3.3.3.6">,</mo><msub id="S3.E13.m1.4.4.4.2.1.1.1.3.3.3.3"><mi id="S3.E13.m1.4.4.4.2.1.1.1.3.3.3.3.2">𝐕</mi><mtext id="S3.E13.m1.4.4.4.2.1.1.1.3.3.3.3.3">B</mtext></msub><mo stretchy="false" id="S3.E13.m1.4.4.4.2.1.1.1.3.3.3.7">)</mo></mrow></mrow></mrow><mo id="S3.E13.m1.4.4.4.2.1.1.2">,</mo></mrow></mtd></mtr><mtr id="S3.E13.m1.7.7g"><mtd columnalign="right" id="S3.E13.m1.7.7h"><mi id="S3.E13.m1.7.7.7.4.1">𝐙</mi></mtd><mtd columnalign="left" id="S3.E13.m1.7.7i"><mrow id="S3.E13.m1.7.7.7.3.3.3"><mrow id="S3.E13.m1.7.7.7.3.3.3.1"><mi id="S3.E13.m1.7.7.7.3.3.3.1.3"></mi><mo stretchy="false" id="S3.E13.m1.7.7.7.3.3.3.1.2">←</mo><mrow id="S3.E13.m1.7.7.7.3.3.3.1.1"><mi id="S3.E13.m1.7.7.7.3.3.3.1.1.3">T</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.7.7.7.3.3.3.1.1.2"></mo><mi id="S3.E13.m1.7.7.7.3.3.3.1.1.4">f</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.7.7.7.3.3.3.1.1.2a"></mo><mrow id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1"><mo stretchy="false" id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1.2">(</mo><mrow id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1.1"><mi id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1.1.4">𝒞</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1.1.3"></mo><mrow id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1.1.2.2"><mo stretchy="false" id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1.1.2.2.3">(</mo><msub id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1.1.1.1.1"><mi id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1.1.1.1.1.2">𝐙</mi><mrow id="S3.E13.m1.5.5.5.1.1.1.1.3"><mo stretchy="false" id="S3.E13.m1.5.5.5.1.1.1.1.3.1">(</mo><mtext id="S3.E13.m1.5.5.5.1.1.1.1.1">A</mtext><mo stretchy="false" id="S3.E13.m1.5.5.5.1.1.1.1.3.2">)</mo></mrow></msub><mo id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1.1.2.2.4">,</mo><msub id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1.1.2.2.2"><mi id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1.1.2.2.2.2">𝐙</mi><mrow id="S3.E13.m1.6.6.6.2.2.2.1.3"><mo stretchy="false" id="S3.E13.m1.6.6.6.2.2.2.1.3.1">(</mo><mtext id="S3.E13.m1.6.6.6.2.2.2.1.1">B</mtext><mo stretchy="false" id="S3.E13.m1.6.6.6.2.2.2.1.3.2">)</mo></mrow></msub><mo stretchy="false" id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1.1.2.2.5">)</mo></mrow></mrow><mo stretchy="false" id="S3.E13.m1.7.7.7.3.3.3.1.1.1.1.3">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E13.m1.7.7.7.3.3.3.2">.</mo></mrow></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex" id="S3.E13.m1.7c">\left\{\begin{aligned} \mathbf{Z}_{(\texttt{A})}&amp;\leftarrow{MHSA}(\mathbf{Q}_{\texttt{B}},\mathbf{K}_{\texttt{A}},\mathbf{V}_{\texttt{A}}),\\ \mathbf{Z}_{(\texttt{B})}&amp;\leftarrow{MHSA}(\mathbf{Q}_{\texttt{A}},\mathbf{K}_{\texttt{B}},\mathbf{V}_{\texttt{B}}),\\ \mathbf{Z}&amp;\leftarrow Tf(\mathcal{C}(\mathbf{Z}_{(\texttt{A})},\mathbf{Z}_{(\texttt{B})})).\end{aligned}\right.</annotation></semantics></math></td><td></td><td rowspan="1"><span>(13)</span></td></tr></tbody></table>

讨论 所有上述用于多模态交互的自注意力变体都是通用的，可以灵活应用于策略和多粒度任务中。 具体来说，这些交互可以灵活组合和嵌套。 例如，在分层注意力（单流到多流）中使用了多个交叉注意力流，在双流解耦模型中，方程式①和方程式②的 Tf2subscript2Tf\_{2} 和 Tf3subscript3Tf\_{3} 通过方程式③中定义的交叉注意力实现。此外，它们可以扩展到多个模态（ ≥3absent3\\geq 3 ）。TriBERT 是一种用于视觉、姿态和音频的三模态交叉注意力（共注意力），其中给定一个查询嵌入，其键嵌入和值嵌入是从其他模态的拼接。在文献\[189\]中，将交叉注意力应用于三个模态（i.e. 语言、视频和音频）。

#### 3.3.3 网络架构

本质上，各种多模态 Transformer 之所以有效，是因为它们内部的多模态注意力，即上述的自注意力变体。同时，如图 2 所示，这些注意力决定了嵌入的多模态 Transformer 的外部网络结构。

一般来说，如果我们从网络结构的角度考虑，(1)早期求和和早期连接在单流中工作，(2)交叉注意力在多流中工作，(3)分层注意力和交叉注意力在混合流中工作。因此，多模态 Transformer 可以分为单流（例如，Uniter e., Uniter g., Visualbert \[[106](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib106)\], Vl-bert \[[104](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib104)\], Vl-bert \[[105](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib105)\]，Unified VLP \[[110](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib110)\]），多流（例如，ViLBERT e., ViLBERT g., Lxmert \[[102](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib102)\], Lxmert \[[103](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib103)\], ActBERT \[[114](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib114)\]），混合流（例如，InterBERT e., InterBERT g.), 等等。

从交互的时机角度来看，这些多模态注意力可以分为三类，早期交互：早期求和、早期拼接和层次注意力（单流到多流），晚期交互：层次注意力（多流到单流），或全程交互：交叉注意力，交叉注意力到拼接。

如图 2 所示\[[192](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib192)\]，多模态 Transformer 模型根据组件的计算大小，还有一个基于架构分类的体系。

## 4应用场景

在本节中，我们概述了基于应用场景的多模态 Transformer。我们考虑了两个重要范式：（1）用于多模态预训练的 Transformer（第 4.1 节，包括无任务相关（第 4.1.1 节）和多任务相关（第 4.1.2 节）的多模态预训练），以及（2）用于特定多模态任务的 Transformer（第 4.2 节）。

### 4.1 4.1 Transformer 在多模态预训练中的应用

受 Transformer 在自然语言处理领域预训练巨大成功的启发，Transformer 也被广泛研究用于多模态预训练，因为各种大规模多模态语料库正在涌现。最近的研究表明，如果在大规模多模态语料库上预训练，基于 Transformer 的模型在广泛的下游多模态任务中明显优于其他竞争对手，并且还实现了零样本泛化能力。这些优势使得基于 Transformer 的多模态预训练成为了一个热门话题，它有两个主要方向，即 i.通用预训练用于无监督的下游任务（第 4.1.1 节），目标导向的预训练用于特定的下游任务（第 4.1.2 节）。

我们关注以下关键点：（1）哪些趋势正在出现？（2）在预训练期间，跨模态交互发生在哪里/如何发生？（3）如何整理和理解预训练的前置目标？它们如何驱动 Transformer 学习跨模态交互？

#### 4.1.1 任务无关的多模态预训练

最近，以 Transformer 为导向的预训练研究已经广泛展开，涉及多种模态组合，例如视频-文本\[7, 107, 117\]，图像-文本\[102, 104, 103, 193, 194, 195\]，声学-文本\[180\]。

在现有工作中，以下主要趋势正在出现：

(1) 视觉-语言预训练（VLP）是该领域的一个主要研究问题。VLP 包括“图像 + 语言”和“视频 + 语言”，也称为视觉语言预训练。已经提出了大量优秀的工作，例如e。g。例如，VideoBERT \[[7](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib7)\]，ViLBERT \[[102](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib102)\]，LXMERT \[[103](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib103)\]，VisualBERT \[[104](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib104)\]，VL-BERT \[[105](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib105)\]，UNITER \[[106](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib106)\]，CBT \[[107](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib107)\]，Unicoder-VL \[[108](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib108)\]，B2T2 \[[109](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib109)\]，VLP \[[110](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib110)\]，12-in-1 \[[111](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib111)\]，Oscar \[[112](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib112)\]，Pixel-BERT \[[113](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib113)\]，ActBERT \[[114](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib114)\]，ImageBERT \[[115](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib115)\]，HERO \[[116](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib116)\]，UniVL \[[117](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib117)\]，SemVLP \[[196](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib196)\]。

(2) 语音可以用作文本。得益于最近自动语音识别（ASR）技术的进步，在多模态环境中，语音可以通过现成的语音识别工具转换为文本。例如，VideoBERT \[[7](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib7)\] 和 CBT \[[107](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib107)\] 充分利用语音而不是低级声音作为跨模态监督的来源，通过提取高级语义文本。

(3) 过度依赖高质量的多模态数据。大多数基于 Transformer 的多模态预训练工作以自监督的方式进行，然而，它过度依赖于高质量的多模态样本对/元组。例如，大量的图像-语言预训练 Transformer 模型是在大规模图像-文本对上预训练的，e。g。例如，VisualBERT \[[104](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib104)\]，VL-BERT \[[105](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib105)\]，ViLBERT \[[102](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib102)\]，LXMERT \[[103](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib103)\]，UNITER \[[106](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib106)\]。另一个例子是，教学视频（例如，烹饪） <sup>3</sup><sup>3</sup>Note that instructional videos also have weakly aligned cases \[[197](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib197), [198](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib198)\]. 被广泛用作预训练语料库，e。g。例如，HowToVQA69M \[[140](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib140)\]，HowTo100M \[[141](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib141)\]，因为与其它视频相比，它们的视觉线索/内容与口头语言更有可能相互对应。然而，将跨模态对齐作为跨模态监督在大规模应用中是昂贵的。 因此，如何使用弱对齐甚至未配对/未对齐的多模态数据作为预训练语料库仍然是研究不足的领域。一些最近的研究尝试使用弱对齐的跨模态监督来训练 Transformer 以学习跨模态交互。

(4) 大多数现有的预训练任务在不同模态之间都能很好地迁移。 例如，文本域中的掩码语言建模（MLM）已应用于音频和图像，例如，掩码声学建模 \[[200](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib200), [180](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib180)\]，掩码图像区域预测 \[[190](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib190)\]，而文本域中的句子排序建模（SOM）\[[201](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib201)\]和视频域中的帧排序建模（FOM）\[[116](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib116)\]具有相同的思想。我们将在下文中进一步讨论多模态 Transformer 预训练的前置任务。

(5) 模型结构主要分为三类。本质上，在多模态预训练场景中，Transformer 模型基于第[3.3.2](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#S3.SS3.SSS2 "3.3.2 Self-Attention Variants in Multimodal Context ‣ 3.3 Multimodal Transformers ‣ 3 Transformers ‣ Multimodal Learning with Transformers: A Survey")节中讨论的自注意力变体进行工作。因此，如果从模型结构的视角来看，现有的多模态预训练 Transformer 也主要分为三类，i。e。单流、多流、混合流。

\[6\] 跨模态交互可以在预训练管道的各个组件/级别中执行。 对于基于 Transformer 的多模态预训练，关键在于驱动 Transformer（编码器，带/不带解码器）学习跨模态交互。 在现有的基于 Transformer 的多模态预训练实践中，跨模态交互是灵活的，可以在预训练管道的各个组件/级别中执行。 总体而言，基于 Transformer 的多模态预训练管道有三个关键组件，从下到上，即标记化、Transformer 表示和目标监督。对于不仅限于多模态预训练，还包括特定的多模态任务，跨模态交互可以在三个组件中的任意一个或多个组件内进行。如第 3.3.2 节所述，因为自注意力模型将任意模态中任意标记的嵌入视为图中的一个节点，所以现有的预训练管道通常可以在模态之间独立转移，除非考虑了模态特定的目标。

讨论 视觉语言预训练（VLP）遵循两种通用流程：两阶段（需要对象检测器，例如，Faster R-CNN \[202\]）（例如，LXMERT \[103\]，ViLBert \[102\]，VL-Bert \[105\]，UNITER \[106\]）和端到端（例如，Pixel-Bert \[113\]，SOHO \[203\]，KD-VLP \[204\]，Simvlm \[199\]）。两阶段流程的主要优势是对象感知感知，通过使用监督预训练的视觉检测器，然而这些基于一个强烈的假设，即视觉表示可以固定。

讨论 如何寻找本质上具有良好对齐的多模态监督的更多语料库，例如教学视频，这仍然是一个开放性问题。 然而， 弱对齐的跨模态样本在现实场景中很受欢迎，例如，大量的弱对齐多模态 数据样本在电子商务领域不断涌现，这得益于细粒度分类、复杂组合和模糊对应。标注/对齐的跨模态数据集在收集和标注过程中成本极高；如何利用从网络爬取的弱对齐甚至未对齐的语料库是一个有前景的问题。一些最近取得成功的实践\[[9](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib9)，[205](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib205)，[199](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib199)\]。 弱对齐的图像-文本对 为了进行预训练，并实现图像分类、图像-文本检索和开放式视觉问答的竞争性能和无样本学习能力，例如等。因为这些弱监督实践充分利用了大规模预训练语料库，因此它们为无样本泛化提供了更大的希望。

前置任务 在基于 Transformer 的多模态预训练中 预训练任务/目标也被称作前缀任务/目标。 截至目前，已经研究了各种预训练任务，例如，掩码语言建模（MLM）\[1\]，掩码图像区域预测/分类（也称为掩码对象分类（MOC））\[2, 1\]，掩码区域回归（MRR）\[3\]，视觉-语言匹配（VLM）（例如，图像-文本匹配（ITM）\[4\]，图像文本匹配（ITM），短语-区域对齐（PRA）\[5\]，词-区域对齐（WRA）\[6\]，视频-字幕匹配（VSM）\[7\]），掩码帧建模（MFM）\[8\]，帧顺序建模（FOM）\[9\]，下一句预测（NSP）\[10, 11, 2\]，掩码句子生成（MSG）\[12\]，掩码组建模（MGM）\[13\]，前缀语言建模（PrefixLM）\[14\]，视频条件掩码语言模型\[15\]，文本条件掩码帧模型\[16\]，视觉翻译语言建模（VTLM）\[17\]，以及图像条件掩码语言建模（也称为图像注意掩码语言建模）\[18\]。 这些下游任务无关的预训练是可选的，可以直接训练下游任务目标，这将在第 4.1.2 节中讨论。表 3 提供了基于 Transformer 的多模态预训练的常见和代表性预训练任务。 实际上，预训练任务可以组合，一些代表性案例总结在文献\[[57](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib57)\]的表 3 和文献\[[58](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib58)\]的表 2 中。

表 III：多模态预训练 Transformer 模型的预训练任务比较（用于无监督下游任务）。 “C-M Loss”：跨模态损失；“Con. Loss”：基于其他模态/模态的损失。

前缀任务有多种分类：

(1) 监督。常见的多模态预训练 Transformer 使用良好对齐、弱对齐甚至未对齐的多模态样本对/元组，分别以监督、弱监督和无监督的方式进行工作。同时，如果我们从监督的角度考虑它们的先验任务/目标定义，先验任务可以分为无监督/自监督（例如，掩码语言模型（MLM）\[[7](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib7), [137](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib137)\]）和监督（例如，图像-文本匹配（ITM）\[[188](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib188)\]\[[106](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib106), [104](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib104), [102](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib102), [103](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib103), [209](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib209)\]）等。如今，自监督尝试占多数。

(2) 模态。从数学公式来看，一些预训练任务是在单一模态上定义的，例如：e。g。掩码语言模型 \[[7](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib7)\]，掩码声学模型 \[[200](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib200)\]，掩码区域回归（MRR）\[[115](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib115)\]，而其他预训练任务是在多个模态上定义的，例如：e。g。图像条件下的掩码语言模型（IMLM）\[[208](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib208)\]，图像-文本匹配（ITM）\[[188](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib188)\]，视频-字幕匹配（VSM）\[[116](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib116)\]。因此，从数学角度来看，预训练任务可以分为两类，即：i。e。单模态和多模态。

然而，这种分类并不真正准确。应强调的是，在多模态预训练 Transformer 模型中，即使预训练目标仅包括单模态元素，预训练仍然可以涉及其他模态，本质上依赖于其他模态的线索，通过（a）预正标记级别交互和/或 Transformer 级别交互，（b）与其他涉及其他模态的预训练协同训练。例如，VL-BERT \[[105](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib105)\] 使用两个双重预训练任务，i.e., 遮蔽语言建模和遮蔽 RoI 分类。

(3) 动机。如果考虑它们的动机，预训练任务包括掩码、描述、匹配、排序等。

一些最近的调查专注于视觉语言预训练（VLP），并从领域（图像-文本或视频-文本）、视觉特征提取、语言特征提取、架构（单流或双流）、解码器（带/不带）、预训练任务/目标、预训练数据集和下游任务等角度比较现有的 VLP Transformer 模型，例如参考文献\[57\]的第 3 表和参考文献\[58\]的第 2 表。 与这些观点不同， 在本综述中， 我们将从一些新的角度提出我们的比较。 具体来说： \[6\](1) Transformer 生态系统的核心是自注意力，因此我们将从自注意力或其变体如何以及何时执行跨模态交互的角度比较现有的多模态预训练 Transformer 模型。 (2) 从几何拓扑的角度考虑，自注意力有助于 Transformer 内在地 在一种模态无关的管道中工作，该管道兼容 通过采用每个模态的嵌入 token 作为图中的一个节点，因此我们强调现有的 VLP 可以应用于除视觉和语言领域之外的其他模态。 \[8\](3) 我们建议将基于 Transformer 的多模态预训练管道视为具有三个关键组件，从下到上，第一，分词，Transformer 表示，目标监督。

讨论 尽管最近取得了进展， 多模态预训练 Transformer 方法仍存在一些明显的瓶颈。 例如，正如在 VLP 领域由\[cite id=2\]\[[208](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib208)\]讨论的那样，尽管 BERT 风格的跨模态预训练模型在各种下游视觉-语言任务上产生了优异的结果，但它们无法直接应用于生成任务。 如前所述\[[208](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib208)\]，VideoBERT\[[7](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib7)\]和 CBT\[[107](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib107)\]都需要为视频字幕训练一个单独的视频到文本解码器。这在使用于判别性和生成性任务的预训练模型之间存在显著差距，主要原因是为判别性任务定向的预训练模型不涉及 Transformer 的解码器。因此，如何设计更统一的管道，使其能够适用于判别性和生成性下游任务，也是一个待解决的问题。再次以实例来说，如<sup>[<a data-immersive-translate-walked="4cf38516-8cde-48cb-a710-6364f35313a2" title="" href="https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib137">137</a>]</sup>所述，常见的多模态预训练模型在细粒度/实例级任务上通常表现不佳。

讨论如\[[208](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib208)\]中所述，作为预训练任务的掩码语言和区域建模的主要优势是，从这些监督中学习的 Transformer 编码器可以基于双向上下文编码视觉和语言模式，并且它自然适合语义理解任务，例如 VQA、图像-文本检索。

讨论 如何提升多模态预训练 Transformer 的性能是一个开放性问题。 一些实践表明 多任务训练（通过添加辅助损失）和对抗训练改进了多模态预训练 Transformer，以进一步提高性能。同时，过于复杂的预训练目标可能会增加在不同损失项之间平衡的挑战，从而复杂化训练优化。此外，预文本的难度也值得讨论。总的来说，如果旨在学习更明确的对象概念，将使用更复杂的预文本损失。然而，对于预文本来说，是否更复杂更好仍然是一个问题。

#### 4.1.2 任务特定多模态预训练

在多模态 Transformer 的实践中，上述下游任务无关的预训练是可选的，不是必需的，针对下游任务的特定预训练也得到了广泛研究\[^211\[^150\[^208\[^190\]\]\]。主要原因包括：(1) 受现有技术的限制，设计一套适用于所有各种下游应用的高度通用网络架构、预训练任务和语料库极为困难。(2) 不同下游应用之间存在不可忽视的差距，例如任务逻辑、数据形式，这使得从预训练转移到下游应用变得困难。

因此，大量下游任务仍然需要定制化的预训练来提高性能。Guhur 等人提出针对视觉和语言导航的领域预训练，因为一般的视觉语言预训练（VLP）侧重于学习视觉语言相关性，并未设计用于满足具身视觉语言导航（VLN）所需的顺序决策。Murahari 等人提出一种面向视觉对话的方法，以利用通用视觉语言数据集上的预训练。XGPT 针对图像描述生成定制，以克服基于 BERT 的跨模态预训练模型无法直接应用于生成任务的限制。ERNIE-ViLG 设计用于使用 Transformer 进行双向图像-文本生成。

特殊模态具有其独特的领域知识，可用于设计特定的预训练文本。 GraphCodeBERT \[[44](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib44)\] 使用两个结构感知预训练任务（例如，预测变量被识别的位置，变量之间的数据流边预测）用于编程源代码。为了从 360∘superscript360360^{\\circ} 视频中的空间线索中学习，Morgado 等人 等 \[[145](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib145)\] 提出对 360∘superscript360360^{\\circ} 视频和空间音频进行对比性视听空间对齐。Med-BERT \[[184](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib184)\] 是一个在两百万患者结构化电子健康记录数据集上预训练的上下文嵌入模型。Kaleido-BERT \[[212](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib212)\] 是一个为时尚领域量身定制的视觉语言感知 Transformer 模型。

### 4.2 4.2 针对特定多模态任务的 Transformer

近期的研究表明，Transformer 模型可以在经典和新型判别应用中编码各种多模态输入，例如 RGB 和光流\[46\]、RGB 和深度\[213\]、RGB 和点云\[214\]、RGB 和激光雷达\[215, 216\]、文本描述和点云\[31\]、声学和文本\[180\]、音频和视觉观察用于音频-视觉导航\[76\]、语音查询和 SQL 数据库模式\[25\]、文本问题/查询和 SQL 数据库模式\[24\]、音频和标签\[217\]、视频的多模态表示\[218, 219\]、文本查询和视频\[220\]、音频和视频用于音频视觉语音增强（AVSE）\[179\]、音频和视频用于音频-视觉视频解析\[173\]。 音频和视频用于视听语音识别 \[[134](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib134)\]，视频和文本用于引用视频对象分割（RVOS） \[[221](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib221)\]，源代码、注释和数据流 \[[44](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib44)\]，图像和文本用于检索 \[[222](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib222)\]。

同时，Transformer 也为各种多模态生成任务做出了贡献，包括单模态到单模态（例如，原始音频到 3D 网格序列\[39\]，RGB 到 3D 场景\[40\]，单张图像到 3D 人体纹理估计\[223\]，RGB 到场景图\[224, 19, 225, 226\]，图到图\[33\]，知识图谱到文本\[227\]，视频到场景图\[228\]，视频到字幕\[229, 230, 231, 232\]，图像到字幕\[233, 234, 235, 236, 237\]，文本到语音\[238\]，文本到图像\[205, 239\]，文本到形状\[240\]，RGB 到 3D 人体姿态和网格\[41\]，音乐到舞蹈\[241\]）。 多模态到单模态（例如，图像和文本到场景图\[cite id=43\]\[[242](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib242)\]，视频对话（文本、音频和视觉到文本）\[cite id=45\]\[[243](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib243)\]，单声道音频和深度到立体声音频\[cite id=47\]\[[14](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib14)\]，音乐作品和种子 3D 运动到长距离未来 3D 运动\[cite id=49\]\[[146](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib146)\]，X 光图像和问题到答案\[cite id=51\]\[[244](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib244)\]，视频、文本和音频到文本\[cite id=53\]\[[245](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib245)\]），以及多模态到多模态（例如\[cite id=57\]\[[246](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib246)\]）。

## 5 挑战与设计

补充了第 4 节中讨论的应用场景分类法，我们从技术挑战的角度进一步调查了先前的工作。我们讨论了基于 Transformer 的多模态学习中的七个挑战，包括融合、对齐、迁移性、效率、鲁棒性、通用性和可解释性。这进一步扩展了在文献\[1\]中引入的分类法，以应对近年来基于 Transformer 的多模态学习（MML）工作的更高多样性和更广泛的范围。

### 5.1 融合

通常，多模态学习 Transformer 将信息在三个层次上融合多个模态：输入（输入。早期融合）、中间表示（中间。融合）和预测（预测。晚期融合）。常见的基于早期融合的多模态学习 Transformer 模型有 \[[7](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib7)，[104](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib104)，[108](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib108)\] 也被称为单流架构 允许采用 BERT 的优点 由于架构修改最小。 这些单流模型的主要区别在于 是使用特定问题的模态与变体掩码技术。 使用注意力操作，一种显著的融合方案 基于瓶颈标记的概念引入。它适用于早期和中期融合，只需简单地选择要融合的层。我们注意到，基于简单预测的后期融合在 MML Transformer 中较少采用。考虑到学习更强的多模态上下文表示的动机和计算能力的巨大进步，这是有道理的。为了增强和解释 MML 的融合，探究模态之间的交互和测量融合程度\[[249](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib249)\]。 将是一个有趣的探索方向。

### 5.2 对齐

跨模态对齐是许多实际多模态应用的关键。基于 Transformer 的跨模态对齐已在各种任务中得到研究，例如，在多说话人视频中的说话人定位\[[250](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib250)\]，语音翻译\[[180](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib180)\]，文本到语音对齐\[[251](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib251)\]，文本到视频检索\[[252](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib252)\], \[[253](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib253)\], \[[254](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib254)\]，以及自然语言的视觉基础\[[255](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib255)\], \[[256](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib256)\], \[[257](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib257)\], \[[258](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib258)\], \[[259](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib259)\]。 最近，基于 Transformer 的对齐 \[[9](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib9)，[119](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib119)，[260](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib260)，[261](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib261)，[262](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib262)\] 导致大量利用网络数据（例如，图像-文本对）进行视觉和语言任务的研究热潮。

一种代表性做法是将两种模态映射到共同的表示空间，通过对比学习对成对样本进行学习。基于这一想法的模型通常规模巨大，从数百万或数十亿的训练数据中优化成本高昂。因此，后续工作大多利用预训练模型来解决各种下游任务\[[263](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#), [120](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#), [264](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#), [265](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#), [266](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#)\]。这些对齐模型具有零样本迁移的能力，尤其是通过提示工程\[[267](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#)\]进行图像分类。这种新颖的视角令人震惊，因为图像分类传统上被视为单模态学习问题，尽管进行了广泛的研究，零样本分类仍然是一个未解决的挑战\[[268](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#)\]。 这已被用于研究更具挑战性和更细粒度的任务（例如，对象检测 \[[269](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib269)\]，视觉问答 \[[263](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib263)，[106](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib106)，[112](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib112)，[103](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib103)\]，以及实例检索 \[[263](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib263)，[222](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib222)\]），通过施加区域（如对象等语义部分）级别的对齐。然而，细粒度对齐将因显式区域检测而带来更多的计算成本，如何在保持区域级学习能力的同时消除这一点成为一个挑战。最近提出的一些想法包括随机采样 \[[113](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib113)\]，学习概念词典 \[[203](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib203)\]，均匀掩码 \[[270](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib270)\]，补丁投影 \[[192](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib192)\]，区域检测器的联合学习 \[[271](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib271)\]，以及掩码预测前的表示对齐 \[[263](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib263)\]。

### 5.3 迁移性

可迁移性是 Transformer 基于的多模态学习的一个主要挑战，涉及如何在不同数据集和应用之间迁移模型的问题。

数据增强和对抗性扰动策略有助于多模态 Transformer 提高泛化能力。VILLA <引用 id=0>\[[210](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib210)\]是一种两阶段策略（任务无关的对抗性预训练，随后是任务特定的对抗性微调），它提高了 VLP Transformer。

在实践中，训练数据和实际数据之间的分布差距是明显的。例如，监督数据样本（标注良好、对齐良好）在实际应用中成本高昂，因此如何将预训练的、在良好对齐的跨模态对/元组上预训练的监督多模态 Transformer 迁移到弱对齐的测试平台上具有挑战性 \[[137](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib137)\]。CLIP \[[9](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib9)\] 是一个启发性的解决方案，通过学习一个共享的多模态嵌入空间来跨模态迁移知识，使模型能够实现零样本迁移到下游任务。CLIP 向社区展示的主要灵感是，预训练的多模态（图像和文本）知识可以通过使用提示模板“一张{标签}的图片。”来弥合训练和测试数据集之间的分布差距。

过拟合是迁移学习的主要障碍。由于强大的建模能力，多模态 Transformer 在训练过程中可能会过度拟合数据集偏差。一些最近的研究探讨了如何将训练在无噪声数据集上的 Oracle 模型迁移到真实数据集。例如，Kervadec 等人探讨了在 VQA 中可迁移的推理模式，并证明了 LXMERT/类似 BERT 的推理模式可以从理想数据集部分迁移到真实数据集。

跨任务差距是转移学习的主要障碍之一，由于推理和输入输出工作流程的不同，例如，如何使用多模态数据集微调语言预训练模型是困难的。在实际应用中，由于模态缺失的问题，多模态预训练的 Transformer 有时需要在推理阶段处理单模态数据。一种解决方案是使用知识蒸馏，例如，从多模态到 Transformer 中的单模态注意力进行蒸馏，从多个单模态 Transformer 教师到共享的 Transformer 编码器，在判别性和生成性多模态任务之间存在巨大的差距。正如在文献\[208\]中讨论的那样，BERT-like 的仅编码器多模态 Transformer（例如，VideoBERT\[7\]、CBT\[107\]）需要分别训练解码器以进行生成任务。 这可能会产生预训练和微调之间的差异，这对泛化性有害。最近，越来越多的尝试进一步研究这个问题，例如，GilBERT \[1\] 是用于判别任务的生成式视觉语言模型，例如，图像-文本检索。

跨语言差距也应考虑在基于 Transformer 的多模态学习的迁移性中，例如，从英语到非英语多模态环境的通用跨语言泛化\[<参考文献 id=2>\[[206](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib206), [277](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib277)\]\]。

### 5.4 效率

多模态 Transformer 存在两个主要效率问题：(1) 由于模型参数容量大，它们对数据需求量大，因此依赖于大规模训练数据集。(2) 它们受到时间复杂度和内存复杂度的限制，这些复杂度随着输入序列长度的平方增长，是由自注意力引起的。在多模态环境中，由于联合高维表示，计算爆炸会变得更加严重。这两个瓶颈相互依赖，应综合考虑。

为了提高多模态 Transformer 的训练和/或推理效率，近期的研究尝试找到各种解决方案，以使用更少的训练数据和/或参数。主要思想可以概括如下。

(1) 知识蒸馏。从训练好的大型 Transformer 中提取知识，用于较小的 Transformer \[[93](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib93)\]。Miech 等人 等。 \[[278](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib278)\] 从较慢的模型（基于早期连接的 Transformer， 𝒪((N(A)+N(B))2)superscriptsubscriptsubscript2\\mathcal{O}((N\_{(\\texttt{A})}+N\_{(\\texttt{B})})^{2}) ）蒸馏到较快的模型（独立双分支 Transformer， 𝒪(N(A)2)superscriptsubscript2\\mathcal{O}(N\_{(\\texttt{A})}^{2}) ）。

(2) 简化和压缩模型。移除组件以简化管道。以 VLP Transformer 模型为例，两阶段管道成本较高，因为它们需要对象检测器。一种简化方法是采用无卷积的方式处理视觉输入，e。g。例如，E2E-VLP \[[271](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib271)\]，ViLT \[[192](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib192)\]。DropToken \[[174](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib174)\]通过在训练过程中随机丢弃输入序列中的一部分视频和音频标记来降低训练复杂度。DropToken 可以被视为 dropout 或对抗训练的一种实现。权重共享也是简化多模态 Transformer 模型的一种常见做法。Wen 等人。\[[279](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib279)\]提出了一种在视觉和文本编码器之上的权重共享 Transformer，以对齐文本和图像。Lee 等人。\[[280](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib280)\]提出了一种基于低秩近似的创新参数共享方案。

(3) 非对称网络结构。为不同模态合理分配不同的模型容量和计算规模，以节省参数。参见文献\[[192](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib192)\]中的图 2。

(4) 提高训练样本的利用率。刘等人通过充分利用不同粒度下的少量样本来训练简化的 LXMERT。李等人通过充分挖掘（a）每种模态内的自监督信号，（b）跨模态的多视角监督以及（c）来自其他相似对的最近邻监督的潜在自监督信号，使用更少的数据来训练 CLIP。\[[282](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib282)\]

(5) 压缩和剪枝模型。搜索多模态 Transformer 的最佳子结构/子网络，例如使用 VLP Transformer 模型进行彩票票据游戏 \[[283](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib283)\]，在训练过程中自适应冻结一些层 \[[284](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib284)\]。

(6) 优化自注意力复杂度。Transformer 的耗时和内存消耗与输入序列长度呈二次方增长 \[[285](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib285)\]。一个潜在的解决方案是优化 𝒪(N2)superscript2\\mathcal{O}(N^{2}) 复杂度，e。g。例如，Child 等人 \[[286](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib286)\]提出了注意力矩阵的稀疏分解，将二次方复杂度降低到 𝒪(nn)\\mathcal{O}(n\\sqrt{n}) ，Transformer-LS \[[287](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib287)\]是一种既适用于语言又适用于视觉长序列的高效 Transformer，具有线性的计算和内存复杂度。

(7) 优化基于自注意力机制的多模态交互/融合的复杂性。Nagrani 等人提出通过注意力瓶颈进行融合（FSN，融合瓶颈）以改进基于早期连接的多模态交互。FSN 通过少量瓶颈潜在变量传递信息，因此要求模型从每个模态中提取最必要的信息以进行跨模态共享。这种策略将融合瓶颈作为桥梁，不仅提高了融合性能，还降低了计算成本。

(8) 优化其他策略。使用最优策略执行基于 Transformer 的常见多模态交互。由于自注意力机制的二次复杂度，使用基于早期连接的多模态交互同步融合来自多个模态/视图的输入是昂贵的。Yan 等人提出了一种高效解决方案，该方案按序列长度升序顺序逐对融合相邻视图之间的信息。这本质上是一种贪婪策略。

### 5.5 5.5 鲁棒性

大规模语料库预训练的多模态 Transformer 在多种多模态应用中取得了最先进的成果，但其鲁棒性仍不明确且研究不足。这至少涉及两个关键挑战，即。如何从理论上分析鲁棒性，如何提高鲁棒性。

尽管最近的研究尝试研究和评估 Transformer 组件/子层如何有助于鲁棒性，但主要瓶颈是社区缺乏分析 Transformer 家族的理论工具。最近，分析鲁棒性的常见做法主要基于实验评估<sup>[<a data-immersive-translate-walked="4cf38516-8cde-48cb-a710-6364f35313a2" title="" href="https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib291">291</a>]</sup>，例如，跨数据集评估、基于扰动的评估。因此，一些多模态数据集<sup>[<a data-immersive-translate-walked="4cf38516-8cde-48cb-a710-6364f35313a2" title="" href="https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib292">292</a>, <a data-immersive-translate-walked="4cf38516-8cde-48cb-a710-6364f35313a2" title="" href="https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib130">130</a>]</sup>被提出用于评估鲁棒性。

近期尝试主要采用两种简单直接的方法来提高多模态 Transformer 模型的鲁棒性：(1) 基于增强和对抗学习策略 \[[293](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib293), [294](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib294)\]，(2) 精细损失函数 \[[295](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib295)\]。例如：VILLA \[[210](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib210)\] 是一个通用的对抗训练框架，可以应用于各种多模态 Transformer。Akula 等人 等 \[[292](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib292)\] 通过实验证明，ViLBERT 无法利用语言结构，并提出两种方法来提高 ViLBERT 的鲁棒性，一种基于对比学习，另一种基于多任务学习。

### 5.6 通用性

由于多模态学习任务和模态的多样性高度，通用性是多模态 Transformer 模型的一个重要问题。大量最近的研究尝试\[<参考文献 id=0>\[<引用 id=1>296, <引用 id=2>117, <引用 id=3>297, <引用 id=4>298\]\]研究如何尽可能统一地使用管道来处理各种模态和多模态任务。理想情况下，统一的多元模态 Transformer 可以与各种数据（例如，对齐和非对齐，单模态和多模态）和任务（例如，监督和无监督，单模态和多模态，判别性和生成性）兼容，并且同时具有少量样本甚至零样本泛化能力。因此，当前针对多模态 Transformer 通用性目标的解决方案是初步探索。

当前以统一为导向的尝试主要包括：

(1) 统一单模态和多模态输入/任务的管道。如第 [5.3 节所述，在实际场景中，由于模态缺失的问题，多模态 Transformer 需要处理单模态数据。将多模态知识提炼成适应单模态数据和任务的紧凑模型是一种成功的实践 \[](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#S5.SS3 "5.3 Transferability ‣ 5 Challenges and Designs ‣ Multimodal Learning with Transformers: A Survey")[275](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib275), [276](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib276)\]。

(2) 统一多模态理解和生成管道。一般来说，对于多模态 Transformer 管道，理解和判别任务只需要 Transformer 编码器，而生成/生成性任务则需要 Transformer 编码器和解码器。现有的尝试使用多任务学习来结合理解和生成工作流程，其中两种工作流程通过多任务损失函数联合训练。从模型结构的角度来看，典型的解决方案包括：(a) 编码器 + 解码器，e。g。例如，E2E-VLP \[[271](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib271)\]。 (b) 分离的编码器 + 交叉编码器 + 解码器，e。g。例如，UniVL \[[117](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib117)\]，CBT \[[107](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib107)\]。 (c) 单一统一/组合的编码器-解码器，e。g。例如，VLP \[[110](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib110)\]。 (d) 双流解耦设计 \[[191](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib191)\]。

(3) 统一和转换任务本身，e。g。例如，CLIP \[[9](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib9)\] 将零样本识别转换为检索，从而降低了修改模型的成本。

然而，上述实践存在一些明显的挑战和瓶颈，至少包括：

(1) 由于模态和任务差距，通用模型应考虑通用性与成本之间的权衡。统一不同模态和任务的管道通常会导致更大的或更复杂的模型配置，而对于特定的模态或任务，某些组件是冗余的。

(2) 多任务损失函数增加了训练的复杂性。如何恰当地有效地协同训练多个目标是一个挑战，因为不同的目标通常应该采用不同的策略进行优化。

### 5.7 可解释性

为什么以及如何 Transformer 在多模态学习中表现出色已经被研究。这些尝试主要使用探查任务和消融研究。曹等人设计了一套探查任务在 UNITER 和 LXMERT 上，以评估在预训练中学习了哪些模式。亨德里克斯等人通过细粒度的图像-句子对探查图像-语言 Transformer，发现动词理解比主语或宾语理解更难。 陈等人通过消融研究检验了预训练任务的优化组合，以比较不同的预文本如何对 Transformers 做出贡献。 尽管这些尝试， 截至目前，多模态 Transformer 的可解释性仍研究不足。

## 6 讨论与展望

设计通用的多模态学习模型，使其能够同时出色地完成所有具有不同特性的单模态和多模态下游任务，是一个非平凡挑战。例如，在跨模态检索等任务中，由于每个模态的表示可以预先计算并重复使用，因此双流架构通常比单流架构更受青睐。然而，如何设计任务无关的多模态学习架构仍然是一个开放性的挑战，除此之外，还有其他设计选择，如预训练和目标损失函数。此外，当前最先进的技术与这一最终目标之间仍存在明显差距。总的来说，现有的多模态 Transformer 模型\[[199](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib199), [263](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib263), [9](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib9)\] 仅对特定的多模态学习任务表现优越 它们被设计成专门用于特定子集的任务 <参考文献 id=10>\[\[参考文献 id=11\]137, \[参考文献 id=12\]212, \[参考文献 id=13\]265, \[参考文献 id=14\]142, \[参考文献 id=15\]266, \[参考文献 id=16\]261, \[参考文献 id=17\]260, \[参考文献 id=18\]249\] 鼓舞人心的是，最近有几项关于通用模态学习的研究被引入，这些研究涉及模态无关的网络设计 <参考文献 id=19>\[\[参考文献 id=20\]3\] 以及更通用的架构设计 <参考文献 id=21>\[\[参考文献 id=22\]307, \[参考文献 id=23\]308, \[参考文献 id=24\]309\]。 希望这能激发进一步的调查。 为了这个目的，与其全面探索庞大的模型设计空间，深入理解和解释多模态学习（MML）模型的行为可能对更优算法设计更有洞察力，尽管不同模态之间的交互和协同本质上复杂，甚至可能在任务上不一致 \[[249](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib249)\]

对于更细粒度的多模态学习，人们普遍认为发现跨模态的潜在语义对齐至关重要。一个直观的策略是利用为多模态学习预提取的语义部分（例如，对象）e。g，。然而，这不仅复杂且容易出错，而且计算成本高昂<sup>[<a href="https://ar5iv.labs.arxiv.org/html/ref_2" id="2">310</a>, <a href="https://ar5iv.labs.arxiv.org/html/ref_4" id="3">106</a>, <a href="https://ar5iv.labs.arxiv.org/html/ref_5" id="4">112</a>, <a href="https://ar5iv.labs.arxiv.org/html/ref_6" id="5">103</a>, <a href="https://ar5iv.labs.arxiv.org/html/ref_7" id="6">104</a>, <a href="https://ar5iv.labs.arxiv.org/html/ref_8" id="7">105</a>, <a href="https://ar5iv.labs.arxiv.org/html/ref_9" id="8">204</a>]</sup>。最近提出的几种补救措施包括随机采样<sup>[<a href="https://ar5iv.labs.arxiv.org/html/ref_11" id="10">113</a>]</sup>、学习概念词典<sup>[<a href="https://ar5iv.labs.arxiv.org/html/ref_13" id="12">203</a>]</sup>、联合学习区域检测器<sup>[<a href="https://ar5iv.labs.arxiv.org/html/ref_15" id="14">271</a>]</sup>以及在掩码预测之前进行表示对齐<sup>[<a href="https://ar5iv.labs.arxiv.org/html/ref_17" id="16">263</a>]</sup>。鉴于多模态学习训练数据的规模，探索这个方向需要巨大的计算成本，并且预计拥有丰富资源的工业研究团队更有可能承担得起。 理想情况下，一个有利的多模态学习方法应该让不同模态之间的细粒度语义对齐自行出现，这值得未来进行仔细研究。

随着学习规模的指数级增长，训练数据不可避免地变得嘈杂和异构。\[[9](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib9), [263](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib263), [199](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib199)\]最近的研究表明，妥善处理噪声问题是有益的。\[[309](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib309), [263](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib263)\] 另一个相关方面是训练策略 例如。特别是，在超过常见单阶段策略的 \[[115](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib115)\] 阶段中，由于输入更长，Transformers 的二次复杂度在多模态数据中变得更加突出。尽管对高效变体的研究广泛 \[[49](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib49)\]，但即使是经验上，对多模态学习（MML）的效率研究仍然被低估，并呼吁进行更多研究。

识别 Transformer 在多模态机器学习中的优势是一个重大的开放性问题。 以下主要观点可以从文献中总结出来： (1) Transformer 可以编码隐式知识 \[[32](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib32)\]。 (2) 多头机制带来了多个建模子空间，可以进一步增强模型的表达能力。 理想情况下，训练后多个头是好的且不同的。 这是一种本质上很好的集成学习实践。 (3) Transformer 本质上有一种全局聚合的特性，能够感知非局部模式。 感谢大型模型容量，Transformer 模型通过在大规模语料库上的有效预训练，更好地处理具有挑战性的领域差距和转变（例如，语言和视觉）。 (5) Transformer 可以表示输入为图，这些图与更多模态本质上是兼容的，例如，例如表格和 SQL。 (6) 对于建模序列和序列模式（例如时间序列），与基于 RNN 的模型相比，Transformers 在训练和/或推理方面具有更好的训练和推理效率，这得益于其在训练和/或推理中的并行计算。Transformers 在处理点序列时本质上是对称不变的，例如，非常适合点云学习 \[[164](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#bib.bib164)\]。 (7) 分词使 Transformer 能够灵活地组织多模态输入，如第 [3.1.1](https://ar5iv.labs.arxiv.org/html/2206.06488?_immersive_translate_auto_translate=1#S3.SS1.SSS1 "3.1.1 Input Tokenization ‣ 3.1 Vanilla Transformer ‣ 3 Transformers ‣ Multimodal Learning with Transformers: A Survey") 节所述。

## 7 结论

本调查重点介绍了基于 Transformer 的多模态机器学习。我们通过介绍 Transformer 在多模态环境中的设计和训练，回顾了该领域的现状。我们总结了该新兴且激动人心的领域的关键挑战和解决方案。此外，我们讨论了开放问题和潜在的研究方向。我们希望这份调查能为新研究人员和实践者提供一个有帮助且详细的概述，为相关专家（例如，多模态机器学习研究人员、Transformer 网络设计者）提供一个便捷的参考，并鼓励未来的进步。
