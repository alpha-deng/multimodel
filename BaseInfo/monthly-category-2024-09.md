# 2024-09 月度论文分类汇总

共有36篇相关领域论文, 另有26篇其他

## 计算语言学(cs.CL:Computation and Language)

该领域共有 3 篇论文

### Recent Trends of Multimodal Affective Computing: A Survey from NLP Perspective 
[[arxiv](https://arxiv.org/abs/2409.07388)] [[cool](https://papers.cool/arxiv/2409.07388)] [[pdf](https://arxiv.org/pdf/2409.07388)]
> **Authors**: Guimin Hu,Yi Xin,Weimin Lyu,Haojian Huang,Chang Sun,Zhihong Zhu,Lin Gui,Ruichu Cai,Erik Cambria,Hasti Seifi
> **First submission**: 2024-09-11
> **First announcement**: 2024-09-12
> **comment**: No comments
- **标题**: 多模式情感计算的最新趋势：从NLP角度进行的调查
- **领域**: 计算语言学
- **摘要**: 多模式情感计算（MAC）由于其在分析人类的行为和意图方面的广泛应用而引起了人们的关注，尤其是在文本主导的多模式情感计算领域。这项调查通过四个热门任务从NLP的角度出发了多模式情感计算的最新趋势：多模式情感分析，对话中的多模式情感识别，多模式的基于方面的情感分析和多模式多模式的情感识别。这项调查的目的是探索当前多模式情感研究的景观，确定发展趋势，并突出各种任务之间的相似性和差异，从NLP的角度提供有关多模式情感计算的最新进展的全面报告。该调查涵盖了任务的形式化，提供了相关工作的概述，描述了基准数据集，并详细介绍了每个任务的评估指标。此外，它简要讨论了涉及面部表情，声学信号，生理信号和情感原因的多模式情感计算的研究。此外，我们讨论了多模式情感计算中的技术方法，挑战和未来方向。为了支持进一步的研究，我们发布了一个存储库，该存储库在多模式情感计算中编译了相关的作品，为社区提供了详细的资源和参考。

### Language-Agnostic Analysis of Speech Depression Detection 
[[arxiv](https://arxiv.org/abs/2409.14769)] [[cool](https://papers.cool/arxiv/2409.14769)] [[pdf](https://arxiv.org/pdf/2409.14769)]
> **Authors**: Sona Binu,Jismi Jose,Fathima Shimna K V,Alino Luke Hans,Reni K. Cherian,Starlet Ben Alex,Priyanka Srivastava,Chiranjeevi Yarra
> **First submission**: 2024-09-23
> **First announcement**: 2024-09-24
> **comment**: No comments
- **标题**: 语言抑郁症检测的语言敏捷分析
- **领域**: 计算语言学
- **摘要**: 与健康同行相比，患有重度抑郁症（MDD）的人在语音中表现出色调变化的症状。但是，这些音调的变化不仅限于MDD状态，而且限于具有独特音调模式的语言。这项工作分析了两种语言的自动抑郁症检测，即英语和马拉雅拉姆语，它们具有独特的韵律和音素特征。我们提出了一种方法，该方法利用了收集的语音数据以及来自参与者的自我报告的标签，以英语和马拉雅拉姆语中的艾维语料库阅读句子。 Ivie语料库由五组句子组成：简单的句子，wh- questions，没有形成标记的问题，反转问题和协调，它们自然可以提示说话者以不同的音调模式说话。卷积神经网络（CNN）用于检测言语的抑郁症。 CNN模型经过训练，以识别与语音抑郁相关的声学特征，重点是两种语言。该模型的性能是在收集的数据集上评估的，该数据集包含来自抑郁症和不抑郁的扬声器的录音，分析了其在两种语言中检测抑郁症的有效性。我们的发现和收集的数据可能有助于发展基于语言语言的抑郁症检测系统，从而增强对不同人群的可及性。

### Spelling Correction through Rewriting of Non-Autoregressive ASR Lattices 
[[arxiv](https://arxiv.org/abs/2409.16469)] [[cool](https://papers.cool/arxiv/2409.16469)] [[pdf](https://arxiv.org/pdf/2409.16469)]
> **Authors**: Leonid Velikovich,Christopher Li,Diamantino Caseiro,Shankar Kumar,Pat Rondon,Kandarp Joshi,Xavier Velez
> **First submission**: 2024-09-24
> **First announcement**: 2024-09-25
> **comment**: 8 pages, 7 figures
- **标题**: 通过重写非自动回旋ASR晶格的拼写校正
- **领域**: 计算语言学,声音,音频和语音处理
- **摘要**: 对于端到端的自动语音识别（ASR）模型，识别个人或稀有短语可能很难。提高准确性的一种有希望的方法是通过对ASR晶格的拼写校正（或重写），在这种校正（或重写）中，可能被误认为的短语被声学上相似和上下文相关的替代方法代替。但是，由于非自动性，独立于上下文独立的光束搜索而产生的嘈杂的假设，对经过连接的时间分类（CTC）训练的ASR模型的重写具有挑战性。我们提出了一种有限状态传感器（FST）技术，用于改写由基于变压器的CTC模型生成的文字晶格。我们的算法直接从词汇配件转换为音素，避免了明确的单词表示并利用CTC晶格的丰富性。我们的方法不需要对ASR模型的重新训练或修改。在具有上下文相关实体的测试集上，我们实现了句子错误率（SER）的相对相对降低的15.2％。

## 密码学和安全(cs.CR:Cryptography and Security)

该领域共有 1 篇论文

### SafeEar: Content Privacy-Preserving Audio Deepfake Detection 
[[arxiv](https://arxiv.org/abs/2409.09272)] [[cool](https://papers.cool/arxiv/2409.09272)] [[pdf](https://arxiv.org/pdf/2409.09272)]
> **Authors**: Xinfeng Li,Kai Li,Yifan Zheng,Chen Yan,Xiaoyu Ji,Wenyuan Xu
> **First submission**: 2024-09-13
> **First announcement**: 2024-09-16
> **comment**: Accepted by ACM CCS 2024. Please cite this paper as "Xinfeng Li, Kai Li, Yifan Zheng, Chen Yan, Xiaoyu Ji, Wenyuan Xu. SafeEar: Content Privacy-Preserving Audio DeepfakeDetection. In Proceedings of ACM Conference on Computer and Communications Security (CCS), 2024."
- **标题**: 安全性：内容隐私的音频深击检测
- **领域**: 密码学和安全,人工智能,多媒体,声音,音频和语音处理
- **摘要**: 文本到语音（TTS）和语音转换（VC）模型在产生逼真和自然的音频方面表现出色。但是，它们的阴暗面，音频效果对社会和个人构成了重大威胁。现有的对策在很大程度上集中于根据完整的原始音频录音来确定语音的真实性，但是通常包含私人内容。这种疏忽可能会从许多应用程序中避免进行深层检测，尤其是在涉及敏感信息（例如商业秘密）的情况下。在本文中，我们提出了Safeear，这是一个新颖的框架，旨在检测DeepFake Audios而不依赖于内部的语音内容。我们的关键思想是将神经音频编解码器设计为一种新型的解耦模型，该模型将语义和声学信息与音频样本很好地分开，而仅使用声学信息（例如韵律和音色）进行深层检测。这样，不会将语义内容暴露于检测器。为了克服没有语义线索的不同深层音频的挑战，我们使用现实世界中的编解码器增强来增强我们的深层检测器。在四个基准数据集上进行的广泛实验表明，安全性在检测各种深层捕获技术的有效性低于2.02％。同时，它屏蔽了五语言语音内容，无法通过机器和人类听觉分析来解密，这是通过单词错误率（WERS）的证明，均超过93.93％和我们的用户研究。此外，我们为抗深层捕获和抗内核恢复评估而构建的基准有助于为未来的音频隐私保护和深层检测领域的研究提供基础。

## 计算机视觉和模式识别(cs.CV:Computer Vision and Pattern Recognition)

该领域共有 5 篇论文

### Advance and Refinement: The Evolution of UAV Detection and Classification Technologies 
[[arxiv](https://arxiv.org/abs/2409.05985)] [[cool](https://papers.cool/arxiv/2409.05985)] [[pdf](https://arxiv.org/pdf/2409.05985)]
> **Authors**: Vladislav Semenyuk,Ildar Kurmashev,Alberto Lupidi,Dmitriy Alyoshin,Liliya Kurmasheva,Alessandro Cantelli-Forti
> **First submission**: 2024-09-09
> **First announcement**: 2024-09-10
> **comment**: 19 pages, 5 figures
- **标题**: 进步和改进：无人机检测和分类技术的演变
- **领域**: 计算机视觉和模式识别,信号处理
- **摘要**: 这篇综述对2020年至今的无人机检测和分类系统的进步进行了详细的分析。它涵盖了各种检测方法，例如雷达，射频，光学传感器和声传感器，并通过复杂的传感器融合技术强调它们的整合。彻底研究了驱动无人机检测和分类的基本技术，重点是它们的准确性和范围。此外，本文讨论了人工智能和机器学习方面的最新创新，这说明了它们对提高这些系统的准确性和效率的影响。综述结束了无人机检测中进一步的技术发展，这有望提高性能和可靠性。

### Object Modeling from Underwater Forward-Scan Sonar Imagery with Sea-Surface Multipath 
[[arxiv](https://arxiv.org/abs/2409.06815)] [[cool](https://papers.cool/arxiv/2409.06815)] [[pdf](https://arxiv.org/pdf/2409.06815)]
> **Authors**: Yuhan Liu,Shahriar Negaharipour
> **First submission**: 2024-09-10
> **First announcement**: 2024-09-11
> **comment**: Copyright 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
- **标题**: 来自水下前向扫描声纳图像的对象建模与海面多路径
- **领域**: 计算机视觉和模式识别
- **摘要**: 我们提出了一种从已知姿势的2-D前向声纳图像的3D水下对象建模的优化技术。对于在海面近端成像的物体中，一个关键贡献是由于空气水界面而解决多路径伪像。在这里，直接目标反向散射形成的对象图像几乎总是被幽灵（有时由镜像组件（由多径传播生成）损坏）。假设存在平面空气水接口，我们在每个视图中建模，本地化并丢弃损坏的对象区域，从而避免恢复的3-D形状的变形。此外，采用了从镜像组件边界的互补视觉提示（在合适的声纳姿势下不同）来提高3-D建模精度。通过在3-D表面网格模型中取代三角形斑点的顶点，以最小化数据和3-D对象模型的合成视图之间的差异来实现优化作为迭代形状调整。为此，我们首先确定在数据和合成视图中对象区域对准对象区域的2-D运动场，然后计算三角形贴片中心的3-D运动，最后是模型顶点。使用应用于相同数据的早期空间雕刻方法的解决方案初始化3-D模型。在各种实验中使用了相同的参数，其中有2个真实数据集，混合的实时数据集以及由实际实验的一般发现引导的计算机生成的数据，以探索非平台空气水接口的影响。结果证实了在大约六个迭代中生成精制的3-D模型。

### On Vision Transformers for Classification Tasks in Side-Scan Sonar Imagery 
[[arxiv](https://arxiv.org/abs/2409.12026)] [[cool](https://papers.cool/arxiv/2409.12026)] [[pdf](https://arxiv.org/pdf/2409.12026)]
> **Authors**: BW Sheffield,Jeffrey Ellen,Ben Whitmore
> **First submission**: 2024-09-18
> **First announcement**: 2024-09-19
> **comment**: No comments
- **标题**: 在视觉变压器上用于侧扫声纳图像中的分类任务
- **领域**: 计算机视觉和模式识别,机器学习
- **摘要**: 侧扫声纳（SSS）图像由于复杂而多样的水下环境而在海底对人造物体的分类中提出了独特的挑战。从历史上看，专家已经手动解释了SSS图像，并依靠具有手工制作功能的传统机器学习技术。尽管该域中的卷积神经网络（CNN）显着高级自动分类，但在处理不同的海底纹理（例如岩石或波纹砂底）时，它们通常会缺少，在这种情况下，假阳性可能会增加。最近，视觉变形金刚（VIT）通过利用自我注意力的机制来捕获图像贴片中的全局信息来解决这些局限性，从而在处理空间层次结构方面具有更大的灵活性。本文严格将VIT模型的性能与常用的CNN体​​系结构（例如Resnet和Convnext）进行了比较，以在SSS图像中进行二进制分类任务。该数据集涵盖了各种地理海底类型，并且在人造物体的存在和不存在之间保持平衡。基于VIT的模型以F1得分，精度，召回和准确度指标表现出卓越的分类性能，尽管以更大的计算资源为代价。 CNN及其感应偏见表现出更好的计算效率，使其适合在水下车辆等资源受限环境中部署。未来的研究方向包括探索VIT的自我监督学习和多模式融合，以进一步提高具有挑战性的水下环境中的性能。

### Autonomous Visual Fish Pen Inspections for Estimating the State of Biofouling Buildup Using ROV -- Extended Abstract 
[[arxiv](https://arxiv.org/abs/2409.12813)] [[cool](https://papers.cool/arxiv/2409.12813)] [[pdf](https://arxiv.org/pdf/2409.12813)]
> **Authors**: Matej Fabijanić,Nadir Kapetanović,Nikola Mišković
> **First submission**: 2024-09-19
> **First announcement**: 2024-09-20
> **comment**: IEEE ICRA Workshop on Field Robotics 2024
- **标题**: 自主视觉鱼笔检查使用ROV估算生物污染堆积状态 - 扩展抽象
- **领域**: 计算机视觉和模式识别
- **摘要**: 鱼笼检查的过程是任何养鱼场的必要维护任务，无论是小规模还是工业，都是有可能完全自动化的任务。取代训练有素的潜水员使用自动船舶进行定期检查，将降低人力成本，并消除与进行水下检查的人类有关的风险。达到这样的自主权意味着可以开发能够估算生物污染堆积状态的图像处理算法。这项工作的目的是提出一个完整的解决方案，以使上述检查过程自动化；从为ROV开发自主控制算法，到自动分割鱼笼的图像，并准确估算生物污染的状态。第一部分是通过使用声学SBL定位系统修改市售ROV并开发闭环控制系统来实现的。第二部分是通过实现提出的生物污染估计框架来实现的，该估计框架依靠AI执行图像分割，并使用已建立的计算机视觉方法处理图像，以获取ROV与鱼笼的距离进行粗略估计。这还涉及开发标签工具，以创建一个图像数据集，以使神经网络执行要训练的语义分割。实验结果表明，使用与声音应答器拟合的ROV进行自主任务，并证明了生物污染估计框架的能力以及令人满意的距离估计功能。总之，实现的生物污染估计精度展示了在水产养殖行业使用的明显潜力。

### ReviveDiff: A Universal Diffusion Model for Restoring Images in Adverse Weather Conditions 
[[arxiv](https://arxiv.org/abs/2409.18932)] [[cool](https://papers.cool/arxiv/2409.18932)] [[pdf](https://arxiv.org/pdf/2409.18932)]
> **Authors**: Wenfeng Huang,Guoan Xu,Wenjing Jia,Stuart Perry,Guangwei Gao
> **First submission**: 2024-09-27
> **First announcement**: 2024-09-30
> **comment**: No comments
- **标题**: REVIVEDIFF：在不利天气条件下恢复图像的通用扩散模型
- **领域**: 计算机视觉和模式识别
- **摘要**: 在充满挑战的环境中捕获的图像（例如夜间，有雾，多雨的天气和水下）通常会严重退化，从而大大损失了视觉质量。这些退化的图像的有效恢复对于随后的视觉任务至关重要。尽管许多现有的方法已成功地纳入了各个任务的特定先验，但这些量身定制的解决方案将其适用性限制在其他降解中。在这项工作中，我们提出了一种称为“ Revivediff”的通用网络体系结构，该架构可以解决广泛的降级，并通过提高和恢复其质量来使图像重新栩栩如生。我们的方法的灵感来自于观察到，与移动或电子问题引起的降低不同，不利条件下的质量降解主要源于自然介质（例如雾，水和低亮度），通常保留物体的原始结构。为了恢复此类图像的质量，我们利用了扩散模型中的最新进步，并开发了RevivedIVER，以恢复一些关键因素，从宏观和微观水平恢复图像质量，例如清晰度，失真，噪音，动态范围和色彩准确性。我们对七个基准数据集进行了严格评估，其中涵盖了五种降解条件：多雨，水下，浅水，烟雾和夜间朦胧。我们的实验结果表明，RevivedIved在定量和视觉上都超过了最先进的方法。

## 机器学习(cs.LG:Machine Learning)

该领域共有 1 篇论文

### Pareto Data Framework: Steps Towards Resource-Efficient Decision Making Using Minimum Viable Data (MVD) 
[[arxiv](https://arxiv.org/abs/2409.12112)] [[cool](https://papers.cool/arxiv/2409.12112)] [[pdf](https://arxiv.org/pdf/2409.12112)]
> **Authors**: Tashfain Ahmed,Josh Siegel
> **First submission**: 2024-09-18
> **First announcement**: 2024-09-19
> **comment**: No comments
- **标题**: 帕累托数据框架：使用最低可行数据（MVD）制定资源有效决策的步骤
- **领域**: 机器学习,人工智能,声音,音频和语音处理
- **摘要**: 本文介绍了Pareto数据框架，一种识别和选择在受约束平台上启用机器学习应用程序（例如嵌入式系统，移动设备和物联网（IoT）设备）上所需的最小可行数据（MVD）的方法。我们证明，降低战略数据可以保持高性能，同时大大降低带宽，能源，计算和存储成本。该框架确定了最小可行的数据（MVD），以优化跨资源约束环境的效率，而无需牺牲性能。它解决了在物联网应用中的常见效率低下实践，例如传感器和过度精确的过度配置以及信号过采样，提出了可扩展的解决方案，以选择最佳传感器选择，信号提取和传输以及数据表示。一种实验方法证明了在减小，量化和截断后有效的声学数据表征，以模拟降低的前后传感器以及网络和存储约束。结果表明，性能可以保持高达95 \％，而样本率降低了75 \％，位深度降低，夹子长度降低了50 \％，这转化为大量成本和资源降低。这些发现对受约束系统的设计和开发具有影响。本文还讨论了该框架的更广泛的含义，包括在物联网应用程序和农业，运输和制造业等领域使先进的AI技术民主化的潜力，以改善访问权限并增加数据驱动的见解的好处。

## 声音(cs.SD:Sound)

该领域共有 20 篇论文

### Multi-label Zero-Shot Audio Classification with Temporal Attention 
[[arxiv](https://arxiv.org/abs/2409.00408)] [[cool](https://papers.cool/arxiv/2409.00408)] [[pdf](https://arxiv.org/pdf/2409.00408)]
> **Authors**: Duygu Dogan,Huang Xie,Toni Heittola,Tuomas Virtanen
> **First submission**: 2024-08-31
> **First announcement**: 2024-09-02
> **comment**: Accepted to International Workshop onAcousticSignalEnhancement (IWAENC) 2024
- **标题**: 多标签零拍音音频分类和时间关注
- **领域**: 声音,机器学习,音频和语音处理
- **摘要**: 零击学习模型能够通过使用辅助信息从可见类中转移知识来对新类进行分类。虽然大多数现有的零照片学习方法都集中在单标签分类任务上，但本研究介绍了一种执行多标签零击音频分类的方法。为了解决对多标签声音进行分类的挑战，同时推广到看不见的类别，我们会适应暂时的关注。时间注意机制根据其声学和语义兼容性将重要的权重分配给不同的音频段，从而使模型能够通过关注与每个类最相关的段来捕获音频样本中不同声音类别的不同优势。与采用时间汇总的声学特征而无需加权的方法，这会导致更准确的多标签零弹药分类，这些方法同样处理所有音频段。我们使用均匀聚合的声学特征，零规则基线以及在监督场景中提出的方法对零射击模型的一部分评估了我们的方法。我们的结果表明，时间关注在多标签方案中增强了零拍音频分类性能。

### Temporal Order Preserved Optimal Transport-based Cross-modal Knowledge Transfer Learning for ASR 
[[arxiv](https://arxiv.org/abs/2409.02239)] [[cool](https://papers.cool/arxiv/2409.02239)] [[pdf](https://arxiv.org/pdf/2409.02239)]
> **Authors**: Xugang Lu,Peng Shen,Yu Tsao,Hisashi Kawai
> **First submission**: 2024-09-03
> **First announcement**: 2024-09-04
> **comment**: Accepted to IEEE SLT 2024
- **标题**: 时间顺序保留了ASR的最佳基于运输的跨模式知识转移学习
- **领域**: 声音,人工智能,计算语言学,音频和语音处理
- **摘要**: 已显示，将语言知识从审计的语言模型（PLM）转移到声学模型已被证明可以大大提高自动语音识别的性能（ASR）。但是，由于跨模式中的异质特征分布，设计了一个有效的模型，用于语言和声学序列之间的特征一致性和知识传递仍然是一项艰巨的任务。有效衡量概率分布差异的最佳运输（OT）具有在声学和语言模态之间对齐和传递知识的巨大潜力。尽管如此，原始OT仍将声学和语言特征序列视为对齐中的两个无序集，并在OT耦合估计过程中忽略了时间顺序信息。因此，需要一个耗时的预训练阶段才能学习声学和语言表示之间的良好对齐方式。在本文中，我们提出了一个时间顺序保留了基于OT（TOT）的跨模式对齐和知识转移（CAKT）（TOT-CAKT）的时间顺序。在TOT-CAKT中，声学序列的本地相邻框架平滑地映射到语言序列的相邻区域，从而保留其时间秩序关系，以特征对齐和匹配。通过Tot-Cakt模型框架，我们使用预算的中国PLM进行语言知识转移进行了普通话ASR实验。我们的结果表明，与使用语言知识转移的几种最先进的模型相比，提出的TOT-CAKT显着提高了ASR性能，并在ASR的顺序特征比对中解决了原始基于OT的方法的弱点。

### MTDA-HSED: Mutual-Assistance Tuning and Dual-Branch Aggregating for Heterogeneous Sound Event Detection 
[[arxiv](https://arxiv.org/abs/2409.06196)] [[cool](https://papers.cool/arxiv/2409.06196)] [[pdf](https://arxiv.org/pdf/2409.06196)]
> **Authors**: Zehao Wang,Haobo Yue,Zhicheng Zhang,Da Mu,Jin Tang,Jianqin Yin
> **First submission**: 2024-09-09
> **First announcement**: 2024-09-10
> **comment**: Submit to Icassp2025
- **标题**: mtda-hsed：相互辅助调整和双分支聚合，用于异质声音事件检测
- **领域**: 声音,机器学习,音频和语音处理
- **摘要**: 声音事件检测（SED）在理解和感知声学场景中起着至关重要的作用。以前的方法表现出了令人印象深刻的功能。但是，它们缺乏从异质数据集中学习复杂场景的学习特征。在本文中，我们介绍了一种新颖的双分支架构，称为Mutual-sassistance调整和双分支聚合，用于异质声音事件检测（MTDA-HSED）。 MTDA-HSED架构采用相互辅助音频适配器（M3A）来有效解决多幕科问题，并使用双分支中型融合（DBMF）模块来解决多晶格问题。具体而言，M3A被集成到BEATS块中，作为适配器，以通过在多scenario数据集中进行微调来提高BEATS的性能。 DBMF模块连接Beats和CNN分支，这有助于从Beats和CNN分支中深入融合信息。实验结果表明，所提出的方法超过了Desus和Maestro Real数据集的\ textbf {$ 5 \％$}的MPAUC基线。代码可在https://github.com/visitor-w/mtda上找到。

### Salmon: A Suite for Acoustic Language Model Evaluation 
[[arxiv](https://arxiv.org/abs/2409.07437)] [[cool](https://papers.cool/arxiv/2409.07437)] [[pdf](https://arxiv.org/pdf/2409.07437)]
> **Authors**: Gallil Maimon,Amit Roth,Yossi Adi
> **First submission**: 2024-09-11
> **First announcement**: 2024-09-12
> **comment**: ICASSP 2025, project page - https://pages.cs.huji.ac.il/adiyoss-lab/salmon/
- **标题**: 鲑鱼：声学语言模型评估套件
- **领域**: 声音,计算语言学,音频和语音处理
- **摘要**: 语音语言模型最近显示出作为通用语音处理系统的巨大潜力。这样的模型能够对音频信号中存在的丰富声学信息进行建模，除了口语内容，例如情感，背景噪声等。尽管如此，评估基准测试了对广泛的声学方面的评估基准，但仍缺乏。为了帮助弥合这一差距，我们介绍了鲑鱼，这是一个新颖的评估套件，其中包括背景噪音，情感，扬声器身份和房间冲动响应。提出的基准测试既评估了检查元素的一致性及其与口语文本匹配的程度。我们遵循一种基于建模的方法，测量模型是否给出的样本比不正确的分数更高。这种方法使得基准快速计算大型型号。我们在鲑鱼上评估了几种语音语言模型，从而突出了每种评估方法的优势和劣势。我们在https://pages.cs.huji.ac.il/adiyoss-lab/salmon/上公开提供代码和数据。

### Self-supervised Learning for Acoustic Few-Shot Classification 
[[arxiv](https://arxiv.org/abs/2409.09647)] [[cool](https://papers.cool/arxiv/2409.09647)] [[pdf](https://arxiv.org/pdf/2409.09647)]
> **Authors**: Jingyong Liang,Bernd Meyer,Issac Ning Lee,Thanh-Toan Do
> **First submission**: 2024-09-15
> **First announcement**: 2024-09-16
> **comment**: No comments
- **标题**: 自我监督的学习，用于声学的几个分类
- **领域**: 声音,人工智能,音频和语音处理
- **摘要**: 标记的数据是有限的，自我监督的学习是减少标签要求的最重要方法之一。尽管它在图像域中进行了广泛的探索，但到目前为止，它在声学域中还没有受到相同的关注。但是，减少标签是许多声学应用的关键要求。特别是在生物声学中，很少有足够的标签可供全面监督学习。这导致广泛使用了在无关的生物声学任务数据上已预先训练的声学识别仪。我们认为，对实际任务数据的培训，并将自我监督的预训练与少量分类相结合是一种卓越的方法，即使只有几个标签可用，它也能够提供高精度。为此，我们介绍并评估了一种新的体系结构，将基于CNN的预处理与基于状态空间模型（SSM）的特征提取相结合。这种组合是由于单独基于CNN的网络难以有效捕获时间信息的事实，这对于对声学信号进行分类至关重要。另一方面，SSM，特别是S4和MAMBA，已被证明具有出色的能力，可以捕获序列数据中的长期依赖性。我们使用对比度学习对实际任务数据进行对比进行培训，然后使用非常少量的标记数据进行微调。我们评估了该提出的体系结构的性能（$ n $ shot，$ n $ class）在标准基准和实际数据上的分类。我们的评估表明，它在几个射击分类问题上的表现优于最先进的体系结构。

### Joint Semantic Knowledge Distillation and Masked Acoustic Modeling for Full-band Speech Restoration with Improved Intelligibility 
[[arxiv](https://arxiv.org/abs/2409.09357)] [[cool](https://papers.cool/arxiv/2409.09357)] [[pdf](https://arxiv.org/pdf/2409.09357)]
> **Authors**: Xiaoyu Liu,Xu Li,Joan Serrà,Santiago Pascual
> **First submission**: 2024-09-14
> **First announcement**: 2024-09-16
> **comment**: Demo link https://masksr.github.io/MaskSR2/
- **标题**: 联合语义知识蒸馏和掩盖声学建模，用于全面语音恢复，并提高清晰度
- **领域**: 声音,人工智能,音频和语音处理,信号处理
- **摘要**: 考虑到各种各样的扭曲，语音恢复旨在以高质量和清晰的方式恢复全乐队的语音。 MaskSR是该任务最近提出的生成模型。与其他类型的模型一样，MaskSr达到了高质量，但是，正如我们所显示的，可以大大提高清晰度。我们通过使用预先训练的自我监督的教师模型来增强MaskSR的语音编码器组成部分的语音编码器组成部分。然后，蒙版语言模型的条件是基于学习的语义特征，以预测编码目标语音的低级光谱细节的声学令牌。我们表明，使用相同的MaskSR模型容量和推理​​时间，提出的模型MaskSr2大大降低了单词错误率，这是一种典型的清晰度指标。 MaskSr2还可以在其他模型中达到竞争性的单词错误率，同时提供卓越的质量。一项消融研究显示了各种语义表示的有效性。

### Energy Consumption Trends in Sound Event Detection Systems 
[[arxiv](https://arxiv.org/abs/2409.08763)] [[cool](https://papers.cool/arxiv/2409.08763)] [[pdf](https://arxiv.org/pdf/2409.08763)]
> **Authors**: Constance Douwes,Romain Serizel
> **First submission**: 2024-09-13
> **First announcement**: 2024-09-16
> **comment**: No comments
- **标题**: 声音事件检测系统中的能耗趋势
- **领域**: 声音,机器学习,音频和语音处理
- **摘要**: 深度学习系统已变得越来越多地精通能源和计算，引起了人们对环境影响的关注。作为声学场景和事件（DCASE）挑战的检测和分类的组织者，我们认识到解决此问题的重要性。在过去的三年中，我们将能耗指标整合到了声音事件检测（SED）系统的评估中。在本文中，我们分析了该能源标准对挑战结果的影响，并探讨了多年来系统复杂性和能源消耗的演变。我们强调了在训练过程中朝着更节能的方法转变，而不会损害性能，而操作和系统复杂性的数量继续增长。通过这种分析，我们希望在SED社区内促进更环保的做法。

### Acoustic identification of individual animals with hierarchical contrastive learning 
[[arxiv](https://arxiv.org/abs/2409.08673)] [[cool](https://papers.cool/arxiv/2409.08673)] [[pdf](https://arxiv.org/pdf/2409.08673)]
> **Authors**: Ines Nolasco,Ilyass Moummad,Dan Stowell,Emmanouil Benetos
> **First submission**: 2024-09-13
> **First announcement**: 2024-09-16
> **comment**: Under review; Submitted to ICASSP 2025
- **标题**: 具有分层对比学习的单个动物的声学识别
- **领域**: 声音,机器学习,音频和语音处理
- **摘要**: 单个动物的声学识别（AIID）与基于音频的物种分类密切相关，但需要更细微的细节来区分同一物种中的单个动物。在这项工作中，我们将AIID构架为层次多标签分类任务，并提出使用层次结构 - 意识到的损失函数来了解维持物种和分类单元之间层次关系的个人身份的强大表示。我们的结果表明，层次嵌入不仅提高了个体级别的识别精度，而且在较高的分类学水平上提高了识别精度，从而有效地保留了学习表示的层次结构。通过将我们的方法与非层次模型进行比较，我们强调了在嵌入空间中执行这种结构的优势。此外，我们将评估扩展到了新型个体类别的分类，这证明了我们在开放集分类方案中的潜力。

### Audio-Driven Reinforcement Learning for Head-Orientation in Naturalistic Environments 
[[arxiv](https://arxiv.org/abs/2409.10048)] [[cool](https://papers.cool/arxiv/2409.10048)] [[pdf](https://arxiv.org/pdf/2409.10048)]
> **Authors**: Wessel Ledder,Yuzhen Qin,Kiki van der Heijden
> **First submission**: 2024-09-16
> **First announcement**: 2024-09-17
> **comment**: Accepted at ICASSP 2025
- **标题**: 在自然主义环境中，音频驱动的增强型学习
- **领域**: 声音,人工智能,音频和语音处理
- **摘要**: 尽管近年来，在音频信号处理中的深入强化学习（DRL）方法已经取得了长足的进步，但在人类机器人互动的背景下，用于导航，凝视控制和头部定向控制等任务的音频驱动的DRL很少受到关注。在这里，我们提出了一个由音频驱动的DRL框架，在该框架中，我们利用深度Q学习来开发一种自主代理，该自主量基于立体声语音记录在声学环境中向说话者朝向讲话者。我们的结果表明，当对态环境中的语音细分培训时，代理商学会了在接近完美的水平上执行任务（即，没有回响）。自然主义声学环境中混响的存在影响了代理的性能，尽管该药物仍然大大优于基线，随机作用的剂。最后，我们量化了自然主义声学环境中提出的DRL方法的概括程度。我们的实验表明，在中等或高级混响环境中受过培训的代理商所学到的政策，但是在厌氧或低混响环境中受过培训的代理商学到的政策并未将其推广到中等或高混响环境。综上所述，这项研究证明了音频驱动的DRL对于诸如头部定向控制等任务的潜力，并突出了对训练策略的需求，从而使真实世界音频驱动的DRL应用程序可以在环境之间进行强有力的概括。

### Machine listening in a neonatal intensive care unit 
[[arxiv](https://arxiv.org/abs/2409.11439)] [[cool](https://papers.cool/arxiv/2409.11439)] [[pdf](https://arxiv.org/pdf/2409.11439)]
> **Authors**: Modan Tailleur,Vincent Lostanlen,Jean-Philippe Rivière,Pierre Aumond
> **First submission**: 2024-09-16
> **First announcement**: 2024-09-18
> **comment**: ef:Workshop onDetectionandClassificationofAcousticScenes and Events (DCASE), Oct 2024, Tokyo, Japan
- **标题**: 在新生儿重症监护病房中聆听的机器
- **领域**: 声音,人工智能,机器学习,音频和语音处理
- **摘要**: 充氧器，警报器和脚步是医院中一些最常见的音源。检测它们对环境心理学具有科学价值，但面临着自己的挑战：即隐私保护和有限的标记数据。在本文中，我们通过边缘计算和云计算的结合解决了这两个挑战。为了保存隐私，我们设计了一个声学传感器，该传感器可以即时计算第三次旋转频谱图，而不是记录音频波形。对于样品有效的机器学习，我们通过光谱转码和标签空间适应来重新利用了预验证的音频神经网络（PANN）。在新生儿重症监护病房（NICU）中进行的一项小规模研究证实，检测到的事件的时间序列与另一种测量方式一致：即父母和医疗保健专业人员的电子徽章。因此，本文证明了在医院病房聆听的多音机器的可行性，同时保证通过设计隐私。

### Learning Spatially-Aware Language and Audio Embeddings 
[[arxiv](https://arxiv.org/abs/2409.11369)] [[cool](https://papers.cool/arxiv/2409.11369)] [[pdf](https://arxiv.org/pdf/2409.11369)]
> **Authors**: Bhavika Devnani,Skyler Seto,Zakaria Aldeneh,Alessandro Toso,Elena Menyaylenko,Barry-John Theobald,Jonathan Sheaffer,Miguel Sarabia
> **First submission**: 2024-09-17
> **First announcement**: 2024-09-18
> **comment**: 26 pages, 7 figures, accepted at NeurIPS 2024
- **标题**: 学习空间意识的语言和音频嵌入
- **领域**: 声音,机器学习,音频和语音处理
- **摘要**: 人类可以描绘出一个不精确的自然语言描述的声音场景。例如，很容易想象出一个声音环境，例如“狮子咆哮声从我身后！”这样的短语。要使机器具有相同程度的理解力，机器必须知道狮子是什么（语义属性），“背后”的概念是（空间属性）以及这些语言信息如何与声音的语义和空间属性保持一致（声音的语义和空间属性（当它来自后面的流频声））。最先进的音频基础模型学会在音频场景和自然文本描述之间进行映射，在非空间音频和文本对中进行培训，因此缺乏空间意识。相比之下，声音事件的定位和检测模型仅限于识别固定数量类别的声音，并且它们将源定位到绝对位置（例如0.2m），而不是使用自然语言（例如“我旁边”）所描述的位置。为了解决这些差距，我们为使用多模式对比度学习训练的具有空间意识的原告和文本嵌入模型。 ELSA支持非空间音频，空间音频和开放词汇文本字幕，描述了声音的空间和语义组件。要训​​练ELSA：（a）我们在空间上增加了总计4,738个小时的三个开源音频数据集的音频和标题，并且（b）我们设计了一个编码器，以捕获非空间音频的语义，以及使用构造构成的象征性学习的语义和空间属性。 Elsa与最先进的语义检索和3D来源本地化都具有竞争力。特别是，Elsa在基线上方的平均音频到文本和文本对文字 +2.8％，在3D源在基线上的本地化中的均值均值 -  11.6°均值 -  11.6°。

### The Sounds of Home: A Speech-Removed Residential Audio Dataset for Sound Event Detection 
[[arxiv](https://arxiv.org/abs/2409.11262)] [[cool](https://papers.cool/arxiv/2409.11262)] [[pdf](https://arxiv.org/pdf/2409.11262)]
> **Authors**: Gabriel Bibbó,Thomas Deacon,Arshdeep Singh,Mark D. Plumbley
> **First submission**: 2024-09-17
> **First announcement**: 2024-09-18
> **comment**: No comments
- **标题**: 家庭声音：言语式的住宅音频数据集用于声音事件检测
- **领域**: 声音,人工智能,音频和语音处理
- **摘要**: 本文介绍了一个住宅音频数据集，以支持旨在促进老年人健康的智能家居应用程序的声音事件检测研究。该数据集是通过在7天的55-80岁的8名参与者的家庭中部署音频记录系统来构建的。通过详细的平面图和建筑材料信息记录了声学特征，以便复制AI模型部署的记录环境。开发了一种新型的自动化语音删除管道，使用预训练的音频神经网络来检测和删除包含口语的段，同时保留包含其他声音事件的段。由此产生的数据集由符合隐私的录音组成，这些录音准确地捕获了住宅空间内日常生活的声音和活动。本文详细介绍了数据集创建方法，使用级联模型体系结构的语音删除管道以及对声带分布的分析以验证语音删除过程。该数据集可实现专门针对家庭应用程序量身定制的声音事件检测模型的开发和基准测试。

### A Lightweight and Real-Time Binaural Speech Enhancement Model with Spatial Cues Preservation 
[[arxiv](https://arxiv.org/abs/2409.12444)] [[cool](https://papers.cool/arxiv/2409.12444)] [[pdf](https://arxiv.org/pdf/2409.12444)]
> **Authors**: Jingyuan Wang,Jie Zhang,Shihao Chen,Miao Sun
> **First submission**: 2024-09-18
> **First announcement**: 2024-09-19
> **comment**: No comments
- **标题**: 带有空间提示保存的轻巧和实时双耳语音增强模型
- **领域**: 声音,人工智能,音频和语音处理
- **摘要**: 双耳语音增强（BSE）旨在共同提高通过听力设备收到的嘈杂信号的语音质量和清晰度，并保留自然聆听目标的空间提示。现有的方法通常会遭受降低（NR）能力和空间提示保存（SCP）精度（SCP）准确性和在复杂声学场景中的高计算需求之间的折衷。在这项工作中，我们提出了一个基于学习的轻质双耳复合卷积网络（LBCCN），该网络通过过滤低频带并保留其余部分，在NR中擅长NR。此外，我们的方法明确结合了频道间相对声传递函数的估计，以确保空间提示的保真度和语音清晰度。结果表明，所提出的LBCCN可以在固定扬声器条件下实现与最新方法的可比NR性能，但计算成本和一定程度的SCP能力。可再现的代码和音频示例可在https://github.com/jywanng/lbccn上找到。

### The Unreliability of Acoustic Systems in Alzheimer's Speech Datasets with Heterogeneous Recording Conditions 
[[arxiv](https://arxiv.org/abs/2409.12170)] [[cool](https://papers.cool/arxiv/2409.12170)] [[pdf](https://arxiv.org/pdf/2409.12170)]
> **Authors**: Lara Gauder,Pablo Riera,Andrea Slachevsky,Gonzalo Forno,Adolfo M. Garcia,Luciana Ferrer
> **First submission**: 2024-09-11
> **First announcement**: 2024-09-19
> **comment**: 5 pages, 1 figure, 1 table
- **标题**: 声学系统在阿尔茨海默氏症的语音数据集中的不可靠性具有异质记录条件
- **领域**: 声音,人工智能,机器学习,音频和语音处理
- **摘要**: 自动语音分析是一种繁荣的方法，可以检测阿尔茨海默氏病（AD）的早期标记。然而，大多数AD数据集的记录条件是异质的，患者和对照通常在不同的声学环境中进行评估。虽然这不是基于语音转录或手动对齐的特征进行分析的问题，但它确实对声学特征的有效性产生了严重的怀疑，这些特征受到收购条件的强烈影响。我们在Adresso数据集中检查了此问题，该问题是从广泛使用的Pitt语料库中得出的。我们表明，基于两个声学特征MFCC和WAV2VEC 2.0嵌入的系统可以在仅使用音频信号的非语音部分时将AD患者与具有高度性能的对照区分开。我们在单独的西班牙语者数据集中复制了这一发现。因此，在这些数据集中，可以通过记录条件来部分预测该类。我们的结果警告说，使用声学系统根据非标准化记录来识别患者。我们建议（a）仅使用转录本或其他从手动注释中得出的其他特征对痴呆症研究的声学异质数据集进行（a），或者（b）被严格控制的声学条件收集的数据集代替。

### Data Efficient Acoustic Scene Classification using Teacher-Informed Confusing Class Instruction 
[[arxiv](https://arxiv.org/abs/2409.11964)] [[cool](https://papers.cool/arxiv/2409.11964)] [[pdf](https://arxiv.org/pdf/2409.11964)]
> **Authors**: Jin Jie Sean Yeo,Ee-Leng Tan,Jisheng Bai,Santi Peksi,Woon-Seng Gan
> **First submission**: 2024-09-18
> **First announcement**: 2024-09-19
> **comment**: 5 pages, 3 figures
- **标题**: 数据有效的声学场景分类使用教师形成的混乱班级指令
- **领域**: 声音,机器学习,音频和语音处理
- **摘要**: 在这份技术报告中，我们描述了SNTL-NTU团队提交的任务1数据有效的低复杂性声学场景分类，对声学场景和事件的检测和分类（DCASE）2024挑战。引入了三个系统来解决不同尺寸的训练分裂。对于小型训练拆分，我们通过减少基本通道的数量来探索提供提供的基线模型的复杂性。我们以混合形式介绍了数据增强，以增加培训样品的多样性。对于较大的训练拆分，我们使用FocusNet向多个修补程序快速频谱变压器（PASST）模型和基线模型的集合提供混乱的类信息，该模型以44.1 kHz的原始采样率进行了训练。我们使用知识蒸馏将集成模型提炼为基线学生模型。在TAU城市声学场景2022移动开发数据集中培训系统的平均测试精度为（62.21、59.82、56.81、53.03、47.97）的最高平均测试精度在三个系统中分别（100、50、50、25、10、5）的最高平均测试精度。

### Investigation of Time-Frequency Feature Combinations with Histogram Layer Time Delay Neural Networks 
[[arxiv](https://arxiv.org/abs/2409.13881)] [[cool](https://papers.cool/arxiv/2409.13881)] [[pdf](https://arxiv.org/pdf/2409.13881)]
> **Authors**: Amirmohammad Mohammadi,Iren'e Masabarakiza,Ethan Barnes,Davelle Carreiro,Alexandra Van Dine,Joshua Peeples
> **First submission**: 2024-09-20
> **First announcement**: 2024-09-23
> **comment**: 5 pages, 14 figures. This work has been submitted to the IEEE for possible publication
- **标题**: 调查与直方图层延迟神经网络的时频特征组合
- **领域**: 声音,机器学习,音频和语音处理
- **摘要**: 尽管深度学习降低了手动特征提取的流行率，但通过功能工程进行数据转换对于改善模型性能仍然至关重要，尤其是对于水下声学信号。音频信号转换为时频表示以及随后处理这些频谱图的方法会显着影响性能。这项工作证明了在直方图层延迟神经网络中使用不同时频特征组合的性能影响。确定了一组最佳功能集，结果表明特定特征组合的表现优于单个数据功能。

### Transfer Learning for Passive Sonar Classification using Pre-trained Audio and ImageNet Models 
[[arxiv](https://arxiv.org/abs/2409.13878)] [[cool](https://papers.cool/arxiv/2409.13878)] [[pdf](https://arxiv.org/pdf/2409.13878)]
> **Authors**: Amirmohammad Mohammadi,Tejashri Kelhe,Davelle Carreiro,Alexandra Van Dine,Joshua Peeples
> **First submission**: 2024-09-20
> **First announcement**: 2024-09-23
> **comment**: 5 pages, 6 figures, This work has been submitted to the IEEE for possible publication
- **标题**: 使用预训练的音频和Imagenet模型进行被动声纳分类的转移学习
- **领域**: 声音,机器学习,音频和语音处理
- **摘要**: 转移学习通常用于利用大型，预训练的模型并进行下游任务进行微调。最普遍的预训练模型最初是使用Imagenet训练的。但是，它们概括的能力可能会因不同的数据方式而异。这项研究比较了在水下声学目标识别（UATR）的背景下，比较了预训练的音频神经网络（PANNS）和Imagenet预训练模型。据观察，在被动声纳分类中，Imagenet预训练的模型略微超过预训练的音频模型。我们还分析了音频采样率对模型预训练和微调的影响。这项研究有助于转移UATR的学习应用，说明了预训练模型在解决UATR域中稀缺，标记数据引起的局限性方面的潜力。

### A sound description: Exploring prompt templates and class descriptions to enhance zero-shot audio classification 
[[arxiv](https://arxiv.org/abs/2409.13676)] [[cool](https://papers.cool/arxiv/2409.13676)] [[pdf](https://arxiv.org/pdf/2409.13676)]
> **Authors**: Michel Olvera,Paraskevas Stamatiadis,Slim Essid
> **First submission**: 2024-09-19
> **First announcement**: 2024-09-23
> **comment**: DCASE 2024 - 9th Workshop onDetectionandClassificationofAcousticScenes and Events, Oct 2024, Tokyo, Japan
- **标题**: 声音描述：探索提示模板和类描述以增强零拍音频分类
- **领域**: 声音,人工智能,音频和语音处理
- **摘要**: 通过对比度学习训练的音频文本模型提供了一种实用的方法，可以通过自然语言提示执行音频分类，例如“这是声音”，其次是类别名称。在这项工作中，我们探索了零击音频分类的替代提示模板，证明了表现较高的选项的存在。首先，我们发现提示的格式会显着影响性能，因此只需提示具有正确格式的班级标签的模型，就可以通过优化的提示模板甚至及时及时结合结合。此外，我们通过以音频为中心的描述来补充类标签。通过利用大型语言模型，我们生成文本描述，这些描述优先考虑声音事件的声学特征，以在类之间进行歧义，而无需广泛的及时工程。我们表明，提示使用类描述会导致最先进的结果在主要的环境声音数据集中导致零击音频分类。值得注意的是，这种方法不需要额外的培训，并且仍保持全部零射。

### ASD-Diffusion: Anomalous Sound Detection with Diffusion Models 
[[arxiv](https://arxiv.org/abs/2409.15957)] [[cool](https://papers.cool/arxiv/2409.15957)] [[pdf](https://arxiv.org/pdf/2409.15957)]
> **Authors**: Fengrun Zhang,Xiang Xie,Kai Guo
> **First submission**: 2024-09-24
> **First announcement**: 2024-09-25
> **comment**: This paper will appear at ICPR 2024
- **标题**: ASD扩散：扩散模型的异常声音检测
- **领域**: 声音,人工智能,音频和语音处理
- **摘要**: 无监督的异常声音检测（ASD）旨在设计一种可推广的方法，该方法可在仅发出正常的声音时可用于检测异常。在本文中，在现实世界工厂提出了基于扩散模型（ASD扩散）的异常声音检测（ASD扩散）。在我们的管道中，声学特征中的异常是从嘈杂的损坏特征重建到其近似正常模式的。其次，提出了一种后处理异常滤波器算法来检测与重建后原始输入显着偏差的异常。此外，引入了denoising扩散模型，以通过更长的采样间隔加速推理速度。所提出的方法在扩散模型作为新方案的应用中具有创新性。 DCASE 2023挑战任务2的开发集的实验结果优于基线7.75％，这表明该方法的有效性。

### SpoofCeleb: Speech Deepfake Detection and SASV In The Wild 
[[arxiv](https://arxiv.org/abs/2409.17285)] [[cool](https://papers.cool/arxiv/2409.17285)] [[pdf](https://arxiv.org/pdf/2409.17285)]
> **Authors**: Jee-weon Jung,Yihan Wu,Xin Wang,Ji-Hoon Kim,Soumi Maiti,Yuta Matsunaga,Hye-jin Shim,Jinchuan Tian,Nicholas Evans,Joon Son Chung,Wangyou Zhang,Seyun Um,Shinnosuke Takamichi,Shinji Watanabe
> **First submission**: 2024-09-18
> **First announcement**: 2024-09-26
> **comment**: 9 pages, 2 figures, 8 tables
- **标题**: Spoofceleb：野外的语音深击检测和SASV
- **领域**: 声音,人工智能,音频和语音处理
- **摘要**: 本文介绍了Spoofceleb，该数据集是为语音深击检测（SDD）和Spoofing-Robust自动扬声器验证（SASV）设计的数据集，利用来自现实世界中的条件以及由文本到语音（TTS）系统产生的源攻击的源数据也对同一真实数据进行了培训。强大的识别系统需要在各种声音环境中记录的语音数据，该环境具有不同的噪声级别。但是，由于对TTS培训的要求，现有数据集通常包括清洁，高质量的录音（真正的数据）；培训TTS模型通常需要工作室质量或录制的读取语音。由于扬声器的多样性不足，现有的SDD数据集在培训SASV模型方面的实用性也有限。我们提出了Spoofceleb，该spoofceleb利用了处理Voxceleb1数据集的全自动管道，将其转换为用于TTS培训的合适形式。随后，我们训练23个当代TTS系统。由此产生的Spoofceleb数据集包含来自1,251个独特扬声器的250万个话语，这些扬声器在自然的现实世界中收集。该数据集包括具有良好控制的实验协议的精心分区培训，验证和评估集。我们为SDD和SASV任务提供基线结果。所有数据，协议和基线都可以在https://jungjee.github.io/spoofceleb上公开获得。

## 音频和语音处理(eess.AS:Audio and Speech Processing)

该领域共有 3 篇论文

### Disentangling Speakers in Multi-Talker Speech Recognition with Speaker-Aware CTC 
[[arxiv](https://arxiv.org/abs/2409.12388)] [[cool](https://papers.cool/arxiv/2409.12388)] [[pdf](https://arxiv.org/pdf/2409.12388)]
> **Authors**: Jiawen Kang,Lingwei Meng,Mingyu Cui,Yuejiao Wang,Xixin Wu,Xunying Liu,Helen Meng
> **First submission**: 2024-09-18
> **First announcement**: 2024-09-19
> **comment**: Accepted by ICASSP2025
- **标题**: 通过使用说话者感知的CTC，在多对话的语音识别中解开演讲者
- **领域**: 音频和语音处理,人工智能,声音
- **摘要**: 多对话者的语音识别（MTASR）在解散和抄写重叠的语音方面面临着独特的挑战。为了应对这些挑战，本文研究了与MTASR的序列化输出培训（SOT）合并时，连接派时间分类（CTC）在说话者分离中的作用。我们的可视化表明，CTC指导编码器在声学嵌入的不同时间区域中代表不同的扬声器。利用这种见解，我们提出了一个基于贝叶斯风险CTC框架的新颖的说话者感知的CTC（SACTC）培训目标。 SACTC是针对多恋者场景的量身定制的CTC变体，它通过限制编码器在特定时间范围内代表不同的扬声器代币来明确对扬声器的模型进行建模。与SOT集成时，SOT-SACTC模型在各种语音重叠程度上始终优于标准SOT-CTC。具体而言，我们观察到相对单词错误率降低了10％，而在低重叠语音中，相对单词错误率为15％。这项工作代表了对MTASR任务的基于CTC的增强功能的初步探索，从而在多对话者语音识别中提供了有关说话者分解的新观点。该代码可在https://github.com/kjw11/speaker-aware-ctc上找到。

### A Joint Spectro-Temporal Relational Thinking Based Acoustic Modeling Framework 
[[arxiv](https://arxiv.org/abs/2409.15357)] [[cool](https://papers.cool/arxiv/2409.15357)] [[pdf](https://arxiv.org/pdf/2409.15357)]
> **Authors**: Zheng Nan,Ting Dang,Vidhyasaharan Sethu,Beena Ahmed
> **First submission**: 2024-09-17
> **First announcement**: 2024-09-24
> **comment**: No comments
- **标题**: 基于频谱关系的联合频谱思想建模框架
- **领域**: 音频和语音处理,计算语言学,机器学习,声音
- **摘要**: 关系思维是指人类对感官信号和先验知识之间的关系形成心理印象的固有能力，然后将它们纳入自己的世界模型中。尽管关系思维在人类对言语的理解中起着至关重要的作用，但在任何人工言语识别系统中尚未将其利用。最近，已经有一些尝试来纠正这种疏忽的尝试，但是这些尝试仅限于在时间域中仅运行的粗话级别模型。为了缩小人造系统与人类能力之间的差距，本文提出了一个新型的基于基于声学思维的光谱式式式播音模型框架。具体而言，它首先生成了许多概率图，以建模时间和频域之间的语音段之间的关系。然后将植根于这些图中每个节点的关系信息进行汇总并嵌入到潜在表示中，而下游任务可以利用这些信息。基于此框架构建的模型优于最先进的系统，在TIMIT数据集上，音素识别任务的提高了7.82 \％。深入的分析进一步表明，我们提出的关系思维模型主要提高了模型识别元音的能力，元音最有可能被音素识别器混淆。

### Semi-Supervised Cognitive State Classification from Speech with Multi-View Pseudo-Labeling 
[[arxiv](https://arxiv.org/abs/2409.16937)] [[cool](https://papers.cool/arxiv/2409.16937)] [[pdf](https://arxiv.org/pdf/2409.16937)]
> **Authors**: Yuanchao Li,Zixing Zhang,Jing Han,Peter Bell,Catherine Lai
> **First submission**: 2024-09-25
> **First announcement**: 2024-09-26
> **comment**: No comments
- **标题**: 来自语音的半监督认知状态分类，具有多视图伪标记
- **领域**: 音频和语音处理,人工智能,计算语言学,多媒体,声音
- **摘要**: 缺乏标记的数据是语音分类任务的普遍挑战，尤其是那些需要广泛主观评估的任务，例如认知状态分类。在这项工作中，我们提出了一个半监督的学习（SSL）框架，引入了一种新型的多视图伪标记方法，该方法利用声学和语言特征来选择培训分类模型的最自信的数据。在声学上，使用Frechet音频距离将未标记的数据与标记的数据进行比较，该距离是根据由多个音频编码生成的嵌入来计算得出的。从语言上讲，大型语言模型被提示修改自动语音识别转录，并根据我们建议的特定于任务的知识来预测标签。当两个来源对齐的伪标记时，可以确定高信心数据，而错配被视为低信心数据。然后，将双峰分类器进行训练，以迭代标记低信心数据，直到满足预定义的标准为止。我们将SSL框架评估有关情绪识别和痴呆症检测任务的框架。实验结果表明，与仅使用标记数据的30％的完全监督学习相比，我们的方法实现了竞争性能，并且显着优于两个选定的基线。

## 图像和视频处理(eess.IV:Image and Video Processing)

该领域共有 1 篇论文

### Performance Assessment of Feature Detection Methods for 2-D FS Sonar Imagery 
[[arxiv](https://arxiv.org/abs/2409.07004)] [[cool](https://papers.cool/arxiv/2409.07004)] [[pdf](https://arxiv.org/pdf/2409.07004)]
> **Authors**: Hitesh Kyatham,Shahriar Negahdaripour,Michael Xu,Xiaomin Lin,Miao Yu,Yiannis Aloimonos
> **First submission**: 2024-09-11
> **First announcement**: 2024-09-12
> **comment**: No comments
- **标题**: 2-D FS声纳图像的功能检测方法的性能评估
- **领域**: 图像和视频处理,计算机视觉和模式识别
- **摘要**: 水下机器人感知对于科学海底探索和商业操作至关重要。关键挑战包括在浑浊环境中的不均匀照明和可见度较差。高频前瞻性声纳相机通过在最大数十米范围内提供高分辨率图像，尽管具有高度的斑点噪声以及缺乏颜色和纹理，但通过提供最大数十米范围的高分辨率图像来解决这些问题。特别是，鲁棒功能检测是自动对象识别，本地化，导航和3-D映射的重要第一步。为RGB图像开发的各种本地功能探测器不适合声纳数据。为了评估他们的性能，我们使用来自五个不同声纳设备的真实声纳图像评估了许多特征探测器。诸如检测准确性，假阳性和对目标特性变化的鲁棒性等性能指标被应用用于分析实验结果。这项研究将对声纳数据的特征检测进行更深入的了解，并开发更有效的方法

## 信号处理(eess.SP:Signal Processing)

该领域共有 1 篇论文

### RF Challenge: The Data-Driven Radio Frequency Signal Separation Challenge 
[[arxiv](https://arxiv.org/abs/2409.08839)] [[cool](https://papers.cool/arxiv/2409.08839)] [[pdf](https://arxiv.org/pdf/2409.08839)]
> **Authors**: Alejandro Lancho,Amir Weiss,Gary C. F. Lee,Tejas Jayashankar,Binoy Kurien,Yury Polyanskiy,Gregory W. Wornell
> **First submission**: 2024-09-13
> **First announcement**: 2024-09-16
> **comment**: 14 pages, 12 figures, submitted to the IEEE Open Journal of the Communications Society
- **标题**: RF挑战：数据驱动的射频信号分离挑战
- **领域**: 信号处理,机器学习
- **摘要**: 本文通过利用最新的AI模型的新型，数据驱动的方法解决了射频（RF）信号中干扰拒绝（RF）信号的关键问题。传统上，干涉拒绝算法是针对特定类型的干扰量身定制的。这项工作引入了更可扩展的数据驱动解决方案，并包含以下贡献。首先，我们提出了一个有见地的信号模型，该模型是开发和分析干扰拒绝算法的基础。其次，我们介绍了RF挑战，这是一个公开可用的数据集，其中包含不同的RF信号以及代码模板，这有助于对RF信号问题的数据驱动分析。第三，我们提出了新型基于AI的拒绝算法，特别是UNET和WaveNet等体系结构，并评估它们在八种不同的信号混合物类型中的性能。这些模型表明，超过传统方法的性能，例如匹配的滤波和最小均方根误差估计，最多可以在比特误差速率上进行两个数量级。第四，我们总结了2024年IEEE国际声学，语音和信号处理国际会议（ICASSP 2024）举办的开放竞赛的结果（ICASSP 2024），强调了该领域持续进步的巨大潜力。我们的发现强调了深度学习算法在减轻干扰方面的希望，为未来的研究奠定了坚实的基础。

## 地球物理学(physics.geo-ph:Geophysics)

该领域共有 1 篇论文

### Self-Updating Vehicle Monitoring Framework Employing Distributed Acoustic Sensing towards Real-World Settings 
[[arxiv](https://arxiv.org/abs/2409.10259)] [[cool](https://papers.cool/arxiv/2409.10259)] [[pdf](https://arxiv.org/pdf/2409.10259)]
> **Authors**: Xi Wang,Xin Liu,Songming Zhu,Zhanwen Li,Lina Gao
> **First submission**: 2024-09-16
> **First announcement**: 2024-09-17
> **comment**: No comments
- **标题**: 自我更新的车辆监控框架，采用分布式声学感应到现实世界的设置
- **领域**: 地球物理学,计算机视觉和模式识别,机器学习,信号处理
- **摘要**: 分布式声传感（DAS）技术的最新出现促进了流量引起的地震数据的有效捕获。交通引起的地震浪潮是城市振动的重要贡献者，并包含至关重要的信息，以促进城市勘探和治理。但是，识别大量嘈杂数据中的车辆运动构成了重大挑战。在这项研究中，我们介绍了一个针对城市环境量身定制的实时半监督车辆监控框架。它仅需要一小部分的手动标签来进行初始培训，并利用未标记的数据以改进模型。此外，该框架可以自主适应新收集的未标记数据。在DAS数据将对象检测作为二维图像以保留空间信息之前，我们利用全面的一维信号预处理来减轻噪声。此外，我们提出了一种新颖的先前损失，该损失结合了车辆痕迹的形状，以跟踪具有不同速度的单个车辆。为了评估我们的模型，我们通过Stanford 2 DAS阵列进行了地震数据进行实验。结果表明，我们的模型表现优于基线模型有效的教师及其受监督的对手YOLO（您只能看一次），既精确又鲁棒。只有35个标记的图像，我们的模型超过了Yolo的地图0.5：0.95标准，幅度为18％，显示出比有效的教师增长7％。我们通过多种更新策略进行了比较实验，以进行自我升级，并确定了一种最佳方法。这种方法超过了单个通行证中所有数据进行的非拟合训练的性能。

## 其他论文

共有 26 篇其他论文

- [Deep Brain Ultrasound Ablation Thermal Dose Modeling with in Vivo Experimental Validation](https://arxiv.org/abs/2409.02395)
  - **标题**: 深脑超声消融热剂量建模与体内实验验证
  - **Filtered Reason**: none of cs.RO,physics.med-ph in whitelist
- [Acoustic Levitation for Environmental Remediation: An Effective Approach for Containment and Forecasting of Oil Spills](https://arxiv.org/abs/2409.01642)
  - **标题**: 环境修复的声音悬浮：一种有效的遏制和预测漏油的方法
  - **Filtered Reason**: none of cs.ET in whitelist
- [Kalman Filtering for Precise Indoor Position and Orientation Estimation Using IMU and Acoustics on Riemannian Manifolds](https://arxiv.org/abs/2409.01002)
  - **标题**: Kalman过滤进行精确的室内位置和使用IMU和声学上的室内估算的估算
  - **Filtered Reason**: none of eess.SP,cs.RO in whitelist
- [Frequency-domain Parallel Computing Using Single On-Chip Nonlinear Acoustic-wave Device](https://arxiv.org/abs/2409.02689)
  - **标题**: 使用单个芯片非线性声波设备的频域并行计算
  - **Filtered Reason**: none of cs.ET,physics.app-ph in whitelist
- [USV-AUV Collaboration Framework for Underwater Tasks under Extreme Sea Conditions](https://arxiv.org/abs/2409.02444)
  - **标题**: 在极端海洋条件下的水下任务的USV-AUV协作框架
  - **Filtered Reason**: none of eess.SY,cs.RO in whitelist
- [Development of Advanced FEM Simulation Technology for Pre-Operative Surgical Planning](https://arxiv.org/abs/2409.03990)
  - **标题**: 开发用于术前手术计划的高级FEM模拟技术
  - **Filtered Reason**: none of cs.RO,physics.med-ph in whitelist
- [SS-BRPE: Self-Supervised Blind Room Parameter Estimation Using Attention Mechanisms](https://arxiv.org/abs/2409.05212)
  - **标题**: SS-BRPE：使用注意机制的自我监督的盲室参数估计
  - **Filtered Reason**: none of eess.AS,cs.SD in whitelist
- [TF-Mamba: A Time-Frequency Network for Sound Source Localization](https://arxiv.org/abs/2409.05034)
  - **标题**: None
  - **Filtered Reason**: none of eess.AS,cs.SD in whitelist
- [PIXHELL Attack: Leaking Sensitive Information from Air-Gap Computers via `Singing Pixels'](https://arxiv.org/abs/2409.04930)
  - **标题**: Pixhell攻击：通过“ Singing Pixels”从气隙计算机中泄漏敏感信息
  - **Filtered Reason**: none of cs.CR in whitelist
- [Soft Acoustic Curvature Sensor: Design and Development](https://arxiv.org/abs/2409.06395)
  - **标题**: 软声曲率传感器：设计和开发
  - **Filtered Reason**: none of eess.AS,cs.RO,cs.SD in whitelist
- [Domain-Invariant Representation Learning of Bird Sounds](https://arxiv.org/abs/2409.08589)
  - **标题**: 域不变的表示鸟的声音学习
  - **Filtered Reason**: none of eess.AS,cs.SD in whitelist
- [Frequency Tracking Features for Data-Efficient Deep Siren Identification](https://arxiv.org/abs/2409.08587)
  - **标题**: 频率跟踪功能，用于数据有效的深警笛识别
  - **Filtered Reason**: none of eess.AS,cs.SD in whitelist
- [Speech as a Biomarker for Disease Detection](https://arxiv.org/abs/2409.10230)
  - **标题**: 语音作为疾病检测的生物标志物
  - **Filtered Reason**: none of eess.AS,cs.SD in whitelist
- [Meijer-G Function with Continued Product and Integer Exponent: Performance of Multi-Aperture UOWC System over EGG Turbulence](https://arxiv.org/abs/2409.11337)
  - **标题**: Meijer-G功能持续产品和整数指数：卵湍流多孔UOWC系统的性能
  - **Filtered Reason**: none of eess.SP,cs.IT in whitelist
- [An Explainable Probabilistic Attribute Embedding Approach for Spoofed Speech Characterization](https://arxiv.org/abs/2409.11027)
  - **标题**: 一种可解释的概率属性嵌入方法，用于欺骗语音表征
  - **Filtered Reason**: none of eess.AS,cs.SD in whitelist
- [A machine learning framework for acoustic reflector mapping](https://arxiv.org/abs/2409.12094)
  - **标题**: 用于声学反射镜映射的机器学习框架
  - **Filtered Reason**: none of cs.RO in whitelist
- [Conformal Prediction for Manifold-based Source Localization with Gaussian Processes](https://arxiv.org/abs/2409.11804)
  - **标题**: 与高斯过程的基于多种源源本地化的共形预测
  - **Filtered Reason**: none of eess.AS,cs.SD in whitelist
- [Point Cloud Structural Similarity-based Underwater Sonar Loop Detection](https://arxiv.org/abs/2409.14020)
  - **标题**: 基于点云结构相似性的水下声纳循环检测
  - **Filtered Reason**: none of cs.RO in whitelist
- [A microscopic investigation of the effect of random envelope fluctuations on phoneme-in-noise perception](https://arxiv.org/abs/2409.13765)
  - **标题**: 对随机包膜波动对音素噪声感知的影响的微观研究
  - **Filtered Reason**: none of eess.AS,cs.SD in whitelist
- [Neural Directional Filtering: Far-Field Directivity Control With a Small Microphone Array](https://arxiv.org/abs/2409.13502)
  - **标题**: 神经定向滤波：带有小麦克风阵列的远场方向性控制
  - **Filtered Reason**: none of eess.AS,cs.SD in whitelist
- [Framework for Robust Localization of UUVs and Mapping of Net Pens](https://arxiv.org/abs/2409.15475)
  - **标题**: 稳健定位的UUV和净笔映射的框架
  - **Filtered Reason**: none of cs.RO in whitelist
- [Topological and geometric characterization of synthetic aperture sonar collections](https://arxiv.org/abs/2409.15447)
  - **标题**: 合成光圈声纳收集的拓扑和几何表征
  - **Filtered Reason**: none of cs.CE in whitelist
- [Efficient learning-based sound propagation for virtual and real-world audio processing applications](https://arxiv.org/abs/2409.15335)
  - **标题**: 用于虚拟和现实世界音频处理应用程序的有效基于学习的声音传播
  - **Filtered Reason**: none of eess.AS,cs.SD in whitelist
- [A Fly on the Wall -- Exploiting Acoustic Side-Channels in Differential Pressure Sensors](https://arxiv.org/abs/2409.18213)
  - **标题**: 墙上的飞行 - 在差压传感器中利用声学侧通道
  - **Filtered Reason**: none of eess.AS,cs.SD in whitelist
- [TADAR: Thermal Array-based Detection and Ranging for Privacy-Preserving Human Sensing](https://arxiv.org/abs/2409.17742)
  - **标题**: TADAR：基于热阵列的检测和范围用于保护隐私的人类感应
  - **Filtered Reason**: none of cs.HC in whitelist
- [Improved Architecture for High-resolution Piano Transcription to Efficiently Capture Acoustic Characteristics of Music Signals](https://arxiv.org/abs/2409.19614)
  - **标题**: 改进的高分辨率钢琴转录的体系结构，有效捕获音乐信号的声学特征
  - **Filtered Reason**: none of eess.AS,cs.SD in whitelist
