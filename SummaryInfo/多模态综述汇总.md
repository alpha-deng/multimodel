

1.  对全部多模态综述性质论文做汇总
	1. [monthly-category-2014-01](monthly-category-2014-01)
		- ### Medical Image Fusion: A survey of the state of the art  [[arxiv](https://arxiv.org/abs/1401.0166)] [[cool](https://papers.cool/arxiv/1401.0166)] [[pdf](https://arxiv.org/pdf/1401.0166)]
			> 	**Authors**: A. P. James,B. V. Dasarathy
			> 	**First submission**: 2013-12-31
			> 	**First announcement**: 2014-01-02
			> 	**comment**: Information Fusion, 2014
			- **标题**: 医学图像融合：对最新状态的调查
			- **领域**: 计算机视觉和模式识别, 人工智能, 医学物理
			- **摘要**: 医疗图像融合是注册和组合来自单个或多个成像方式的多个图像以提高成像质量并降低随机性和冗余的过程，以提高医疗图像的临床适用性以诊断和评估医疗问题。多模式医学图像融合算法和设备在改善基于医学图像的决策临床准确性方面已取得了显着的成就。这篇评论文章提供了方法的事实清单，并总结了医学图像融合领域所面临的广泛科学挑战。我们根据（1）广泛使用的图像融合方法，（2）成像方式和（3）正在研究的器官的成像来表征医学图像融合研究。这篇综述得出的结论是，即使存在一些开放的技术和科学挑战，但事实证明，医学图像的融合对于促进使用医学成像进行医学诊断和分析的临床可靠性很有用，并且是一门科学学科，在未来几年中有可能显着增长。
	2. [monthly-category-2016-01](monthly-category-2016-01)
		- ### Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures [[arxiv](https://arxiv.org/abs/1601.03896)] [[cool](https://papers.cool/arxiv/1601.03896)] [[pdf](https://arxiv.org/pdf/1601.03896)]
			> **Authors**: Raffaella Bernardi,Ruket Cakici,Desmond Elliott,Aykut Erdem,Erkut Erdem,Nazli Ikizler-Cinbis,Frank Keller,Adrian Muscat,Barbara Plank
			> **First submission**: 2016-01-15
			> **First announcement**: 2016-01-18
			> **comment**: Journal of Artificial Intelligence Research 55, 409-442, 2016
			- **标题**: 自动描述从图像中生成：模型，数据集和评估措施的调查
			- **领域**: 计算语言学,计算机视觉和模式识别
			- **摘要**: 自然图像中的自动描述是一个具有挑战性的问题，最近从计算机视觉和自然语言处理社区中引起了很大的兴趣。在这项调查中，我们根据它们如何概念化此问题的方式对现有方法进行了分类，即将描述作为一代问题或视觉或多模式代表空间的检索问题进行分类。我们对现有模型进行了详细的审查，强调了它们的优势和缺点。此外，我们概述了基准图像数据集以及已开发的评估措施来评估机器生成的图像描述的质量。最后，我们推断出自动图像描述生成领域的未来方向。


	2. [monthly-category-2018-01](monthly-category-2018-01)
		- ### Survey on Emotional Body Gesture Recognition [[arxiv](https://arxiv.org/abs/1801.07481)] [[cool](https://papers.cool/arxiv/1801.07481)] [[pdf](https://arxiv.org/pdf/1801.07481)]
			> **Authors**: Fatemeh Noroozi,Ciprian Adrian Corneanu,Dorota Kamińska,Tomasz Sapiński,Sergio Escalera,Gholamreza Anbarjafari
			> **First submission**: 2018-01-23
			> **First announcement**: 2018-01-24
			> **comment**: No comments
			- **标题**: 情感身体手势识别的调查
			- **领域**: 计算机视觉和模式识别
			- **摘要**: 在过去的十年中，自动情绪识别已成为一个热门的研究主题。尽管基于面部表情或语音的作品比比皆是，但认识到身体手势的影响仍然是一个不太探索的话题。我们提出了一项新的综合调查，希望促进该领域的研究。我们首先将情感身体手势作为通常称为“肢体语言”的组成部分，并将一般方面评为性别差异和文化依赖。然后，我们为自动情感身体手势识别定义了一个完整的框架。我们介绍了RGB和3D中的人检测和评论静态和动态的身体姿势估计方法。然后，我们评论了与表示情感表达性手势图像的表示和情感识别有关的最新文献。我们还讨论了将语音或面对面与身体手势相结合的多模式方法，以改善情绪识别。如今，预处理方法学（例如人类的检测和姿势估计）是完全开发用于强大的大规模分析的成熟技术，但我们表明，对于情感识别，标记的数据的数量是稀缺的，但在明确定义的输出空间上尚无共识，并且代表性很小，并且基于天真的差异代表。
	3. [monthly-category-2020-01](monthly-category-2020-01)
		- ### Sensor-based Continuous Authentication of Smartphones' Users Using Behavioral Biometrics: A Contemporary Survey [[arxiv](https://arxiv.org/abs/2001.08578)] [[cool](https://papers.cool/arxiv/2001.08578)] [[pdf](https://arxiv.org/pdf/2001.08578)]
			> **Authors**: Mohammed Abuhamad,Ahmed Abusnaina,DaeHun Nyang,David Mohaisen
			> **First submission**: 2020-01-23
			> **First announcement**: 2020-01-24
			> **comment**: 19 pages
			- **标题**: 基于传感器的智能手机用户的连续身份验证使用行为生物识别技术：当代调查
			- **领域**: 密码学和安全,人机交互,机器学习
			- **摘要**: 移动设备和技术已经变得越来越流行，为台式计算机提供了可比的存储和计算功能，使用户可以存储并与敏感和私人信息进行交互。由于移动设备容易受到未经授权的访问或盗窃的影响，因此对此类个人信息的安全和保护变得越来越重要。用户身份验证是一项至关重要的任务，可以在进入点并连续地通过使用方式授予合法用户的访问权限。通过当今智能手机的嵌入式传感器，通过捕获行为生物识别技术和特质来实现连续和隐式的用户身份验证，使此任务成为可能。在本文中，我们调查了140多种用于连续用户身份验证的基于行为生物识别的方法，包括基于运动的方法（28个研究），基于步态的方法（19个研究），基于键震动力学的方法（20个研究），基于触摸手势的方法（29种研究），基于语音的方法（16个研究）（16个研究）和基于多态的基于多态的方法（34个研究）。该调查概述了使用智能手机嵌入式传感器捕获的行为生物识别技术的当前最新方法，用于连续用户身份验证，包括洞察力和开放挑战的采用，可用性和性能。
	4. [monthly-category-2021-01](monthly-category-2021-01)
		-  ### Transformers in Vision: A Survey [[arxiv](https://arxiv.org/abs/2101.01169)] [[cool](https://papers.cool/arxiv/2101.01169)] [[pdf](https://arxiv.org/pdf/2101.01169)]
			> **Authors**: Salman Khan,Muzammal Naseer,Munawar Hayat,Syed Waqas Zamir,Fahad Shahbaz Khan,Mubarak Shah
			> **First submission**: 2021-01-04
			> **First announcement**: 2021-01-05
			> **comment**: 30 pages (Accepted in ACM Computing Surveys December 2021)
			- **标题**: 视觉中的变压器：调查
			- **领域**: 计算机视觉和模式识别,人工智能,机器学习
			- **摘要**: 自然语言任务上的变压器模型令人惊讶的结果吸引了视觉社区研究其在计算机视觉问题上的应用。在它们的显着益处中，变压器可以在输入序列元素和支持序列的并行处理之间与复发网络（例如长期短期内存（LSTM））进行建模。与卷积网络不同，变压器需要最小的电感偏差来设计其设计，并且自然适合于设定功能。此外，变形金刚的直接设计允许使用类似的处理块处理多种方式（例如，图像，视频，文本和语音），并为非常大的容量网络和庞大的数据集展示了出色的可扩展性。这些优势使使用变压器网络的许多视觉任务取得了令人兴奋的进步。该调查旨在为计算机视觉学科中的变压器模型提供全面的概述。我们首先介绍了变压器成功的基本概念，即自我注意力，大规模的预训练和双向编码。然后，我们涵盖了视觉中变形金刚的广泛应用，包括流行的识别任务（例如，图像分类，对象检测，动作识别和细分），生成模型，多模式任务（例如，视觉问题，视觉响应，视觉推理和视觉接地），视频处理（例如，视频识别，视频识别，视频预测），图像效果（E.着色）和3D分析（例如，点云分类和分割）。我们比较了在建筑设计及其实验价值方面的流行技术的各个优势和局限性。最后，我们对开放研究方向和可能的未来工作进行了分析。
		- [Multimodality in VR: A survey](https://arxiv.org/abs/2101.07906)
			- **标题**: VR中的多模式：调查

	5. [monthly-category-2024-09](monthly-category-2024-09)
		- ### Recent Trends of Multimodal Affective Computing: A Survey from NLP Perspective [[arxiv](https://arxiv.org/abs/2409.07388)] [[cool](https://papers.cool/arxiv/2409.07388)] [[pdf](https://arxiv.org/pdf/2409.07388)]
			> **Authors**: Guimin Hu,Yi Xin,Weimin Lyu,Haojian Huang,Chang Sun,Zhihong Zhu,Lin Gui,Ruichu Cai,Erik Cambria,Hasti Seifi
			> **First submission**: 2024-09-11
			> **First announcement**: 2024-09-12
			> **comment**: No comments
			- **标题**: 多模式情感计算的最新趋势：从NLP角度进行的调查
			- **领域**: 计算语言学
			- **摘要**: 多模式情感计算（MAC）由于其在分析人类的行为和意图方面的广泛应用而引起了人们的关注，尤其是在文本主导的多模式情感计算领域。这项调查通过四个热门任务从NLP的角度出发了多模式情感计算的最新趋势：多模式情感分析，对话中的多模式情感识别，多模式的基于方面的情感分析和多模式多模式的情感识别。这项调查的目的是探索当前多模式情感研究的景观，确定发展趋势，并突出各种任务之间的相似性和差异，从NLP的角度提供有关多模式情感计算的最新进展的全面报告。该调查涵盖了任务的形式化，提供了相关工作的概述，描述了基准数据集，并详细介绍了每个任务的评估指标。此外，它简要讨论了涉及面部表情，声学信号，生理信号和情感原因的多模式情感计算的研究。此外，我们讨论了多模式情感计算中的技术方法，挑战和未来方向。为了支持进一步的研究，我们发布了一个存储库，该存储库在多模式情感计算中编译了相关的作品，为社区提供了详细的资源和参考。(https://arxiv.org/pdf/2409.07388)]
	6. [monthly-category-2024-10](monthly-category-2024-10)
		-  ### A Survey: Collaborative Hardware and Software Design in the Era of Large Language Models [[arxiv](https://arxiv.org/abs/2410.07265)] [[cool](https://papers.cool/arxiv/2410.07265)] [[pdf](https://arxiv.org/pdf/2410.07265)]
			> **Authors**: Cong Guo,Feng Cheng,Zhixu Du,James Kiessling,Jonathan Ku,Shiyu Li,Ziru Li,Mingyuan Ma,Tergel Molom-Ochir,Benjamin Morris,Haoxuan Shan,Jingwei Sun,Yitu Wang,Chiyue Wei,Xueying Wu,Yuhao Wu,Hao Frank Yang,Jingyang Zhang,Junyao Zhang,Qilin Zheng,Guanglei Zhou,Hai,Li,Yiran Chen
			> **First submission**: 2024-10-08
			> **First announcement**: 2024-10-10
			> **comment**: Accepted by IEEE Circuits and Systems Magazine
			- **标题**: 调查：大语模型时代的协作硬件和软件设计
			- **领域**: 硬件架构,人工智能,机器学习,软件工程
			- **摘要**: 大型语言模型（LLM）的快速发展显着改变了人工智能领域，表现出了自然语言处理的显着能力，并朝着多模式功能迈进。这些模型越来越多地整合到各种应用中，从而影响了研究和行业。但是，他们的开发和部署面临着重大挑战，包括需要广泛的计算资源，高能消耗和复杂的软件优化。与传统的深度学习系统不同，LLM需要独特的优化策略来培训和推理，重点是系统级效率。本文调查了专门针对大型语言模型的独特特征和约束的专门定制的硬件和软件共同设计方法。这项调查分析了LLMS对硬件和算法研究的挑战和影响，探索算法优化，硬件设计和系统级创新。它旨在在以LLM中心计算系统中的权衡和考虑方面提供全面的理解，从而指导AI中未来的进步。最后，我们总结了该领域的现有努力，并概述了未来的指示，以实现下一代大型语言模型和AI系统的生产级共同设计方法。
		- ### Prompt Compression for Large Language Models: A Survey [[arxiv](https://arxiv.org/abs/2410.12388)] [[cool](https://papers.cool/arxiv/2410.12388)] [[pdf](https://arxiv.org/pdf/2410.12388)]
			> **Authors**: Zongqian Li,Yinhong Liu,Yixuan Su,Nigel Collier
			> **First submission**: 2024-10-16
			> **First announcement**: 2024-10-17
			> **comment**: No comments
			- **标题**: 大型语言模型的及时压缩：调查
			- **领域**: 计算语言学
			- **摘要**: 利用大型语言模型（LLMS）进行复杂的自然语言任务通常需要长期提示来传达详细的要求和信息，从而增加内存使用和推理成本。为了缓解这些挑战，已经提出了多种有效的方法，并迅速压缩具有重大的研究兴趣。该调查概述了及时的压缩技术，分为硬提示方法和软提示方法。首先，比较了这些方法的技术方法，然后对了解其机制的各种方法进行了探索，包括注意优化的观点，参数有效的微调（PEFT），模态积分和新的合成语言。我们还检查了各种及时压缩技术的下游改编。最后，分析了当前及时压缩方法的局限性，并概述了几个未来的方向，例如优化压缩编码器，结合硬和软提示方法以及利用多模式的见解。
		- ### Monolingual and Multilingual Misinformation Detection for Low-Resource Languages: A Comprehensive Survey [[arxiv](https://arxiv.org/abs/2410.18390)] [[cool](https://papers.cool/arxiv/2410.18390)] [[pdf](https://arxiv.org/pdf/2410.18390)]
			> **Authors**: Xinyu Wang, Wenbo Zhang, Sarah Rajtmajer
			> **First submission**: 2024-10-23
			> **First announcement**: 2024-10-24
			> **comment**: No comments
			- **标题**: 低资源语言的单语和多语言错误信息检测：一项全面的调查
			- **领域**: 计算语言学
			- **摘要**: 在当今的全球数字景观中，错误信息超越了语言界限，对适度系统构成了重大挑战。尽管在错误信息检测方面已取得了重大进展，但重点主要保留在单语高资源的环境上，而低资源的语言经常被忽略。这项调查旨在通过对当前关于单语和多语言环境中低资源语言错误信息检测的研究进行全面概述来弥合差距。我们回顾了这些领域中使用的现有数据集，方法和工具，并确定与：数据资源，模型开发，文化和语言环境，现实世界应用以及研究工作相关的关键挑战。我们还研究了新兴方法，例如语言不足的模型和多模式技术，同时强调需要改进数据收集实践，跨学科协作以及对社会负责人 AI 研究的更强大的激励措施。我们的发现强调了能够解决各种语言和文化背景之间的误解的强大，包容性系统的需求。
		- ### A Survey of Multimodal Sarcasm Detection [[arxiv](https://arxiv.org/abs/2410.18882)] [[cool](https://papers.cool/arxiv/2410.18882)] [[pdf](https://arxiv.org/pdf/2410.18882)]
			> **Authors**: Shafkat Farabi,Tharindu Ranasinghe,Diptesh Kanojia,Yu Kong,Marcos Zampieri
			> **First submission**: 2024-10-24
			> **First announcement**: 2024-10-25
			> **comment**: Published in the Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence Survey Track. Pages 8020-8028
			- **标题**: 多模式讽刺检测的调查
			- **领域**: 计算语言学
			- **摘要**: 讽刺是一种修辞手段，用于传达话语的字面意义的相反。讽刺广泛用于社交媒体和其他形式的计算机介导的通信，促使使用计算模型自动识别它。尽管仅在文本上进行了讽刺检测的明显方法，但讽刺检测通常需要以音调，面部表达和上下文图像中存在的其他信息。这导致了多模式的引入，开放了以多种模式（例如音频，图像，文本和视频）来检测讽刺的可能性。在本文中，我们介绍了有关多模式讽刺检测的首次综合调查 - 迄今为止，MSD。我们调查了2018年至2023年之间关于该主题的论文，并讨论用于此任务的模型和数据集。我们还提出了MSD的未来研究方向。

		- ### A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond [[arxiv](https://arxiv.org/abs/2410.02362)] [[cool](https://papers.cool/arxiv/2410.02362)] [[pdf](https://arxiv.org/pdf/2410.02362)]
			> **Authors**: Shubhi Bansal,Sreeharish A,Madhava Prasath J,Manikandan S,Sreekanth Madisetty,Mohammad Zia Ur Rehman,Chandravardhan Singh Raghaw,Gaurav Duggal,Nagendra Kumar
			> **First submission**: 2024-10-03
			> **First announcement**: 2024-10-04
			> **comment**: No comments
			- **标题**: 对医学图像分析的MAMBA体系结构进行的全面调查：分类，细分，修复及其他
			- **领域**: 计算机视觉和模式识别,人工智能
			- **摘要**: 曼巴（Mamba）是国家空间模型的一种特殊情况，它在医学图像分析中替代了基于模板的深度学习方法的替代方案。尽管变形金刚是强大的体系结构，但它们具有缺点，包括二次计算复杂性和无法有效地解决远程依赖关系。这种限制会影响医学成像中大型且复杂的数据集的分析，那里存在许多空间和时间关系。相比之下，Mamba提供的好处使其非常适合医学图像分析。它具有线性时间的复杂性，这是对变压器的重大改进。 Mamba处理没有注意机制的较长序列，可以更快地推断并需要更少的记忆。 Mamba在合并多模式数据，提高诊断准确性和患者预后方面还表现出强烈的表现。本文的组织使读者可以逐步欣赏Mamba在医学成像中的功能。我们首先定义SSM和模型的核心概念，包括S4，S5和S6，然后探索诸如纯Mamba，U-NET变体等MAMBA体系结构以及具有卷积神经网络，变形金刚和图形神经网络的混合模型。我们还涵盖了MAMBA的优化，技术和适应，扫描，数据集，应用程序，实验结果，并以其医学成像的挑战和未来方向结束。这篇评论旨在证明曼巴在克服医学成像中现有障碍的同时，为该领域的创新进步铺平道路。 Github可在此工作中审查的医学领域应用的MAMBA架构综合列表。
		- ### Diffusion Models in 3D Vision: A Survey [[arxiv](https://arxiv.org/abs/2410.04738)] [[cool](https://papers.cool/arxiv/2410.04738)] [[pdf](https://arxiv.org/pdf/2410.04738)]
			> **Authors**: Zhen Wang,Dongyuan Li,Renhe Jiang
			> **First submission**: 2024-10-07
			> **First announcement**: 2024-10-08
			> **comment**: No comments
			- **标题**: 3D视觉中的扩散模型：调查
			- **领域**: 计算机视觉和模式识别
			- **摘要**: 近年来，3D视觉已成为计算机视觉中的关键领域，为诸如自动驾驶，机器人技术，增强现实（AR）和医学成像等广泛应用提供动力。该字段依赖于来自图像和视频等2D数据源的3D场景的准确感知，理解和重建。最初为2D生成任务设计的扩散模型为更灵活的概率方法提供了潜力，可以更好地捕获现实世界中3D数据中存在的可变性和不确定性。但是，传统方法通常会因效率和可扩展性而困难。在本文中，我们回顾了为3D视觉任务提供扩散模型的最新方法，包括但不限于3D对象生成，形状完成，点云重建和场景理解。我们对扩散模型的基本数学原理进行了深入的讨论，概述了它们的前进和反向过程，以及各种架构进步，使这些模型能够与3D数据集一起使用。我们还讨论了将扩散模型应用于3D视觉的关键挑战，例如处理阻塞和不同点密度以及高维数据的计算需求。最后，我们讨论了潜在的解决方案，包括提高计算效率，增强多模式融合以及探索大规模预处理以更好地跨越3D任务的概括。本文为这个迅速发展的领域的未来探索和发展是基础。
		- ### Towards Multi-Modal Animal Pose Estimation: A Survey and In-Depth Analysis [[arxiv](https://arxiv.org/abs/2410.09312)] [[cool](https://papers.cool/arxiv/2410.09312)] [[pdf](https://arxiv.org/pdf/2410.09312)]
			> **Authors**: Qianyi Deng,Oishi Deb,Amir Patel,Christian Rupprecht,Philip Torr,Niki Trigoni,Andrew Markham
			> **First submission**: 2024-10-11
			> **First announcement**: 2024-10-14
			> **comment**: 35 pages, 5 figures, 8 tables. Qianyi Deng and Oishi Deb are Joint Major Contributors to this work
			- **标题**: 迈向多模式动物姿势估计：一项调查和深入分析
			- **领域**: 计算机视觉和模式识别,人工智能,机器学习
			- **摘要**: 动物姿势估计（APE）旨在使用各种传感器和模态输入（例如RGB摄像机，Lidar，Infrared，IMU，声学和语言提示）定位动物体部位，这对于跨NeuRoscience，生物力学和兽医医学的研究至关重要。通过评估自2011年以来的176篇论文，APE方法由其输入传感器和模态类型，输出形式，学习范式，实验设置和应用领域进行分类，并在单一和多模式猿系统中详细介绍了当前趋势，挑战和未来方向的详细分析。该分析还强调了人与动物姿势估计之间的过渡，以及猿类的创新如何相互富集人的姿势估计和更广泛的机器学习范式。此外，还提供了基于不同传感器和方式的2D和3D APE数据集以及评估指标。这里提供了定期更新的项目页面：https：//github.com/chennydeng/mm-pape。

		- ### Efficient Diffusion Models: A Comprehensive Survey from Principles to Practices [[arxiv](https://arxiv.org/abs/2410.11795)] [[cool](https://papers.cool/arxiv/2410.11795)] [[pdf](https://arxiv.org/pdf/2410.11795)]
			> **Authors**: Zhiyuan Ma,Yuzhu Zhang,Guoli Jia,Liangliang Zhao,Yichao Ma,Mingjie Ma,Gaofeng Liu,Kaiyan Zhang,Jianjun Li,Bowen Zhou
			> **First submission**: 2024-10-15
			> **First announcement**: 2024-10-16
			> **comment**: :I.4.9
			- **标题**: 有效的扩散模型：从原则到实践的全面调查
			- **领域**: 计算机视觉和模式识别
			- **摘要**: 作为近年来最受欢迎和最受欢迎的生成模型之一，扩散模型激发了许多研究人员的兴趣，并稳步地显示出在各种生成任务中的优势，例如图像合成，视频产生，分子设计，3D场景渲染和多模态生成，依靠其密集的理论原理和可靠的应用程序实践。这些最近在扩散模型的努力取得了显着的成功，主要来自渐进的设计原理和有效的体系结构，培训，推理和部署方法。但是，没有进行全面和深入的审查来总结这些原则和实践，以帮助快速理解和应用扩散模型。在这项调查中，我们对这些现有努力提供了一种新的面向效率的观点，该观点主要集中在建筑设计，模型培训，快速推理和可靠的部署方面的深刻原则和有效实践，以指导进一步的理论研究，算法迁移和模型以一种读者友善的方式进行新的场景。 \ url {https://github.com/ponyzym/efficited-dms-survey}

		- ### Radar and Camera Fusion for Object Detection and Tracking: A Comprehensive Survey [[arxiv](https://arxiv.org/abs/2410.19872)] [[cool](https://papers.cool/arxiv/2410.19872)] [[pdf](https://arxiv.org/pdf/2410.19872)]
			> **Authors**: Kun Shi,Shibo He,Zhenyu Shi,Anjun Chen,Zehui Xiong,Jiming Chen,Jun Luo
			> **First submission**: 2024-10-24
			> **First announcement**: 2024-10-28
			> **comment**: No comments
			- **标题**: 雷达和相机融合用于对象检测和跟踪：一项全面的调查
			- **领域**: 计算机视觉和模式识别
			- **摘要**: 多模式融合对于在复杂环境中实施可靠的对象检测和跟踪至关重要。利用异质模态信息的协同作用赋予感知系统实现更全面，健壮和准确的性能的能力。作为无线视觉协作的核心关注，雷达相机融合促使了前瞻性研究方向，这是由于其广泛的适用性，互补性和兼容性。尽管如此，仍然缺乏系统的调查，专门针对雷达和相机的深层融合，以进行对象检测和跟踪。为了填补这一空白，我们踏上了一项努力，以整体方式全面回顾雷达相机融合。首先，我们详细介绍了雷达相机融合感知的基本原理，方法和应用。接下来，我们深入研究有关传感器校准，模态表示，数据对齐和融合操作的关键技术。此外，我们提供了一个详细的分类法，其中涵盖了与对象检测和跟踪相关的研究主题。在雷达和相机技术的背景下。在本文中，我们讨论了雷达相机融合感知领域的新兴观点，并突出了未来研究的潜在领域。

		- ### A Survey on RGB, 3D, and Multimodal Approaches for Unsupervised Industrial Anomaly Detection [[arxiv](https://arxiv.org/abs/2410.21982)] [[cool](https://papers.cool/arxiv/2410.21982)] [[pdf](https://arxiv.org/pdf/2410.21982)]
			> **Authors**: Yuxuan Lin,Yang Chang,Xuan Tong,Jiawen Yu,Antonio Liotta,Guofan Huang,Wei Song,Deyu Zeng,Zongze Wu,Yan Wang,Wenqiang Zhang
			> **First submission**: 2024-10-29
			> **First announcement**: 2024-10-30
			> **comment**: 28 pages, 18 figures
			- **标题**: 无监督工业异常检测的RGB，3D和多模式方法的调查
			- **领域**: 计算机视觉和模式识别
			- **摘要**: 为了提高工业信息化，无监督的工业异常检测（UIAD）技术有效地克服了异常样本的稀缺性，并显着增强了智能制造的自动化和可靠性。尽管RGB，3D和多模式异常检测表明在工业信息化领域中具有全面和强大的功能，但现有的有关工业异常检测的综述尚未充分分类和讨论3D和多模态环境中的方法。我们专注于3D UIAD和多模式UIAD，提供了三种模态环境中无监督工业异常检测的全面摘要。首先，我们将调查与最近的作品进行比较，引入了常用的数据集，评估指标以及对异常检测问题的定义。其次，我们总结了RGB，3D和多模式UIAD的五个研究范例以及RGB UIAD中的三个新兴工业制造优化方向，并在多模态设置中审查了三个多模式特征融合策略。最后，我们概述了UIAD在三种模态环境中目前面临的主要挑战，并提供了对未来发展方向的见解，旨在为研究人员提供详尽的参考，并为发展工业信息的发展提供新的观点。相应的资源可在https://github.com/sunny5250/awesome-multi-setting-uiad上获得。

		- ### Recent Advances of Multimodal Continual Learning: A Comprehensive Survey [[arxiv](https://arxiv.org/abs/2410.05352)] [[cool](https://papers.cool/arxiv/2410.05352)] [[pdf](https://arxiv.org/pdf/2410.05352)]
			> **Authors**: Dianzhi Yu,Xinni Zhang,Yankai Chen,Aiwei Liu,Yifei Zhang,Philip S. Yu,Irwin King
			> **First submission**: 2024-10-07
			> **First announcement**: 2024-10-08
			> **comment**: No comments
			- **标题**: 多模式持续学习的最新进展：一项综合调查
			- **领域**: 机器学习,人工智能
			- **摘要**: 持续学习（CL）旨在使机器学习模型能够从新数据中不断学习，同时在先前获得的知识的基础上而无需忘记。随着机器学习模型从小型到大型预训练的架构发展，从支持单峰到多模式数据，最近出现了多模式持续学习（MMCL）方法。 MMCL的主要挑战是它超出了单峰CL方法的简单堆叠，因为这种直接的方法通常会产生不令人满意的性能。在这项工作中，我们介绍了有关MMCL的首次全面调查。我们提供基本的背景知识和MMCL设置，以及MMCL方法的结构化分类法。我们将现有的MMCL方法分为四个类别，即基于正则化的，基于架构的，基于重播和基于及时的方法，解释其方法并突出其关键创新。此外，为了促使该领域的进一步研究，我们总结了开放的MMCL数据集和基准，并讨论了一些有希望的未来调查和开发方向。我们还创建了一个GitHub存储库，用于索引相关的MMCL论文和开放资源，请访问https://github.com/lucydyu/awesome-multimodal-continual-learning。

		- ### Knowledge Graph Embeddings: A Comprehensive Survey on Capturing Relation Properties [[arxiv](https://arxiv.org/abs/2410.14733)] [[cool](https://papers.cool/arxiv/2410.14733)] [[pdf](https://arxiv.org/pdf/2410.14733)]
			> **Authors**: Guanglin Niu
			> **First submission**: 2024-10-16
			> **First announcement**: 2024-10-21
			> **comment**: 22 pages, 8 figures, 3 tables, this paper is a modified English version of our article already published in Computer Science journal (in Chinese), released to facilitate communication among international researchers in the relevant fields
			- **标题**: 知识图嵌入：一项有关捕获关系属性的综合调查
			- **领域**: 机器学习,人工智能,计算语言学
			- **摘要**: 知识图嵌入（KGE）技术在将符号知识图（KGS）转换为数值表示中起着关键作用，从而增强了各种深度学习模型的知识增强应用程序。与实体不同，kg中的关系是语义含义的载体，其准确的建模对于KGE模型的性能至关重要。首先，我们解决了关系中固有的复杂映射属性，例如一对一，一对多，多一对一对一的映射。我们提供了基于关系映射的模型，利用特定表示空间的模型，基于张量分解的模型和基于神经网络的模型的全面摘要。接下来，着重于捕获对称模式，例如对称，不对称，反转和组成，我们回顾了采用修改的张量分解的模型，这些模型基于修改后的关系映射以及利用旋转操作的模型。随后，考虑到实体之间的隐式层次关系，我们介绍了结合辅助信息，基于双曲线空间的模型以及利用层坐标系的模型。最后，在响应更复杂的场景（例如稀疏和动态kg）时，本文讨论了潜在的未来研究方向。我们探讨了创新的思想，例如将多模式信息整合到KGE中，将关系模型与规则增强，并开发模型以捕获动态KGE设置中的关系特征。

		- ### Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques  [[arxiv](https://arxiv.org/abs/2410.18972)] [[cool](https://papers.cool/arxiv/2410.18972)] [[pdf](https://arxiv.org/pdf/2410.18972)]
			> **Authors**: David Ortiz-Perez,Manuel Benavent-Lledo,Jose Garcia-Rodriguez,David Tomás,M. Flores Vizcaya-Moreno
			> **First submission**: 2024-10-24
			> **First announcement**: 2024-10-25
			> **comment**: No comments
			- **标题**: 对认知下降的深刻见解：通过深度学习技术利用非侵入性方式的调查
			- **领域**: 机器学习,人工智能
			- **摘要**: 认知能力下降是衰老的自然部分，通常导致认知能力降低。但是，在某些情况下，这种下降更明显，通常是由于诸如阿尔茨海默氏病这样的疾病。早期发现异常认知能力下降至关重要，因为它可以促进及时的专业干预。尽管医疗数据可以在此检测中有所帮助，但通常涉及侵入性程序。另一种方法是采用非侵入性技术，例如语音或手写分析，这不一定会影响日常活动。这项调查回顾了使用深度学习技术来自动化认知下降估计任务的最相关方法，包括音频，文本和视觉处理。我们讨论了每种方式和方法的关键特征和优势，包括变压器体系结构和基础模型等最先进的方法。此外，我们提出了整合不同模式以开发多模式模型的作品。我们还强调了最重要的数据集以及使用这些资源的研究的定量结果。从这篇评论中，得出了几个结论。在大多数情况下，文本方式取得了最佳的结果，并且与检测认知能力下降最相关。此外，将各种方法从各个模式结合到多模型模型都一致地增强了几乎所有情况的性能。

		- ### Neural Fields in Robotics: A Survey [[arxiv](https://arxiv.org/abs/2410.20220)] [[cool](https://papers.cool/arxiv/2410.20220)] [[pdf](https://arxiv.org/pdf/2410.20220)]
			> **Authors**: Muhammad Zubair Irshad,Mauro Comi,Yen-Chen Lin,Nick Heppert,Abhinav Valada,Rares Ambrus,Zsolt Kira,Jonathan Tremblay
			> **First submission**: 2024-10-26
			> **First announcement**: 2024-10-28
			> **comment**: 20 pages, 20 figures. Project Page: https://robonerf.github.io
			- **标题**: 机器人技术中的神经领域：一项调查
			- **领域**: 机器人技术,人工智能,计算机视觉和模式识别,机器学习
			- **摘要**: 神经领域已成为计算机视觉和机器人技术中3D场景表示形式的一种变革性方法，从而可以准确推断几何学，3D语义和来自POSED 2D数据的动力学。利用可区分的渲染，神经领域涵盖了连续隐式和显式神经表示，实现了高保真3D重建，多模式传感器数据的整合以及新观点的产生。这项调查探讨了他们在机器人技术中的应用，强调了它们增强感知，计划和控制的潜力。它们的紧凑性，记忆效率和不同性，以及与基础和生成模型无缝集成，使其非常适合实时应用，改善机器人适应性和决策。本文对机器人技术的神经领域进行了详尽的审查，对各个领域的应用进行了分类，并根据200多篇论文评估了其优势和局限性。首先，我们提出四个关键的神经场框架：占用网络，签名距离场，神经辐射场和高斯裂口。其次，我们详细介绍了神经领域在五个主要机器人域中的应用：姿势估计，操纵，导航，物理和自主驾驶，突出关键作品并讨论外卖和开放挑战。最后，我们概述了机器人技术中神经领域的当前局限性，并为未来的研究提出了有希望的方向。项目页面：https：//robonerf.github.io

		- ### Frontiers in Intelligent Colonoscopy [[arxiv](https://arxiv.org/abs/2410.17241)] [[cool](https://papers.cool/arxiv/2410.17241)] [[pdf](https://arxiv.org/pdf/2410.17241)]
			> **Authors**: Ge-Peng Ji,Jingyi Liu,Peng Xu,Nick Barnes,Fahad Shahbaz Khan,Salman Khan,Deng-Ping Fan
			> **First submission**: 2024-10-22
			> **First announcement**: 2024-10-23
			> **comment**: [Work in progress] A comprehensive survey of intelligent colonoscopy in themultimodalera. [Updated Version V2] New training strategy for colonoscopy-specificmultimodallanguage model
			- **标题**: 智能结肠镜检查的前沿
			- **领域**: 图像和视频处理,计算机视觉和模式识别
			- **摘要**: 结肠镜检查目前是结直肠癌最敏感的筛查方法之一。这项研究研究了智能结肠镜检查技术的前沿及其对多模式医学应用的前瞻性影响。有了这个目标，我们首先通过针对结肠镜面的四个任务评估当前以数据为中心和以模型为中心的景观，包括分类，检测，细分和视觉语言理解。这项评估使我们能够确定特定领域的挑战，并揭示了结肠镜检查中的多模式研究仍然开放，以进一步探索。为了拥抱即将到来的多模式时代，我们建立了三个基础举措：大规模的多模式指令调整数据集Coloninst，结肠镜检查设计的多模式语言模型Colongpt和多模式基准。为了促进对这个快速发展的领域的持续监控，我们为最新更新提供了一个公共网站：https：//github.com/ai4colonoscopy/intelliscope。




	8. [monthly-category-2024-11](monthly-category-2024-11)

		- ### Foundations and Recent Trends in Multimodal Mobile Agents: A Survey [[arxiv](https://arxiv.org/abs/2411.02006)] [[cool](https://papers.cool/arxiv/2411.02006)] [[pdf](https://arxiv.org/pdf/2411.02006)]
			> **Authors**: Biao Wu,Yanda Li,Meng Fang,Zirui Song,Zhiwei Zhang,Yunchao Wei,Ling Chen
			> **First submission**: 2024-11-04
			> **First announcement**: 2024-11-05
			> **comment**: 8 pages, 1 figure
			- **标题**: 多模式移动代理的基础和最新趋势：一项调查
			- **领域**: 人工智能
			- **摘要**: 移动代理对于在复杂且动态的移动环境中自动化任务至关重要。随着基础模型的发展，对可以实时和过程多模式数据的代理的需求已经增长。这项调查提供了对移动代理技术的全面综述，重点是最新进步，以增强实时适应性和多模式相互作用。最新的评估基准已经得到了更好的开发，可以捕获移动任务的静态和交互式环境，从而更准确地评估了代理的性能。然后，我们将这些进步分类为两种主要方法：基于及时的方法，这些方法利用大型语言模型（LLMS）进行基于指令的任务执行，以及基于培训的方法，这些方法对特定于移动的应用程序进行了多模式调整多模型。此外，我们探讨了增强代理性能的互补技术。通过讨论关键挑战并概述未来的研究方向，该调查为推进移动代理技术提供了宝贵的见解。可以从https://github.com/aialt/awesome-mobile-agents获得综合资源列​​表

		- ### GUI Agents with Foundation Models: A Comprehensive Survey  [[arxiv](https://arxiv.org/abs/2411.04890)] [[cool](https://papers.cool/arxiv/2411.04890)] [[pdf](https://arxiv.org/pdf/2411.04890)]
			> **Authors**: Shuai Wang,Weiwen Liu,Jingxuan Chen,Yuqi Zhou,Weinan Gan,Xingshan Zeng,Yuhan Che,Shuai Yu,Xinlong Hao,Kun Shao,Bin Wang,Chuhan Wu,Yasheng Wang,Ruiming Tang,Jianye Hao
			> **First submission**: 2024-11-07
			> **First announcement**: 2024-11-08
			> **comment**: No comments
			- **标题**: 具有基础模型的GUI代理：一项全面调查
			- **领域**: 人工智能,人机交互
			- **摘要**: 基础模型，尤其是大型语言模型（LLM）和多模式大语言模型（MLLM）的最新进展，促进了能够执行复杂任务的智能代理的发展。通过利用（M）LLM处理和解释图形用户界面（GUI）的能力，这些代理可以自主执行用户指令，模拟类似人类的交互，例如单击和键入。这项调查合并了基于LLM的GUI代理的最新研究，突出了数据资源，框架和应用程序中的关键创新。我们首先审查代表性数据集和基准，然后概述一个广义的，统一的框架，该框架封装了先前研究的基本组成部分，并得到了详细的分类法的支持。此外，我们探索相关的商业应用。从现有工作中汲取见解，我们确定关键挑战并提出未来的研究方向。我们希望这项调查能够激发（M）基于LLM的GUI代理领域的进一步进步。


		- ### A Comprehensive Survey and Guide to Multimodal Large Language Models in Vision-Language Tasks [[arxiv](https://arxiv.org/abs/2411.06284)] [[cool](https://papers.cool/arxiv/2411.06284)] [[pdf](https://arxiv.org/pdf/2411.06284)]
			> **Authors**: Chia Xin Liang,Pu Tian,Caitlyn Heqi Yin,Yao Yua,Wei An-Hou,Li Ming,Tianyang Wang,Ziqian Bi,Ming Liu
			> **First submission**: 2024-11-09
			> **First announcement**: 2024-11-11
			> **comment**: No comments
			- **标题**: 视觉任务中多模式大语模型的全面调查和指南
			- **领域**: 人工智能
			- **摘要**: 该多模式大语言模型（MLLMS）的调查和应用指南探讨了MLLM的快速发展领域，研究其架构，应用程序，以及对AI和生成模型的影响。从基础概念开始，我们深入研究MLLM如何整合各种数据类型，包括文本，图像，视频和音频，以启用复杂的AI系统，以进行跨模式理解和生成。它涵盖了基本主题，例如培训方法，建筑组件和各个领域的实际应用，从视觉讲故事到增强的可访问性。通过详细的案例研究和技术分析，本文研究了突出的MLLM实现，同时解决了可伸缩性，鲁棒性和跨模式学习方面的关键挑战。最后，以道德考虑，负责任的AI发展和未来的方向进行了讨论，这种权威资源既提供了理论框架和实际见解。它对MLLM的开发和部署的机遇和挑战提供了平衡的观点，对于研究人员，从业人员和对自然语言处理和计算机愿景相交感兴趣的学生来说是非常有价值的。

		- ### Large Language Model-Brained GUI Agents: A Survey [[arxiv](https://arxiv.org/abs/2411.18279)] [[cool](https://papers.cool/arxiv/2411.18279)] [[pdf](https://arxiv.org/pdf/2411.18279)]
			> **Authors**: Chaoyun Zhang,Shilin He,Jiaxu Qian,Bowen Li,Liqun Li,Si Qin,Yu Kang,Minghua Ma,Guyue Liu,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang,Qi Zhang
			> **First submission**: 2024-11-27
			> **First announcement**: 2024-11-28
			> **comment**: The collection of papers reviewed in this survey will be hosted and regularly updated on the GitHub repository: https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey Additionally, a searchable webpage is available at https://aka.ms/gui-agent for easier access and exploration
			- **标题**: 大型语言模型的GUI代理：调查
			- **领域**: 人工智能,计算语言学,人机交互
			- **摘要**: Guis长期以来一直是人类计算机互动的核心，它提供了一种直观且视觉驱动的方式来访问和与数字系统进行交互。 LLM的出现，尤其是多模型模型，已经迎来了GUI自动化的新时代。他们在自然语言理解，代码生成和视觉处理方面表现出了出色的功能。这为新一代LLM脑的GUI代理铺平了道路，能够解释复杂的GUI元素并根据自然语言指示自主执行动作。这些代理代表范式偏移，使用户能够通过简单的对话命令执行复杂的多步任务。它们的应用程序跨越Web导航，移动应用交互和桌面自动化，提供了一种变革性的用户体验，彻底改变了个人与软件互动的方式。这个新兴领域正在迅速发展，在研究和行业中取得了重大进展。为了提供对这一趋势的结构性理解，本文介绍了对LLM脑的GUI代理的全面调查，探讨了其历史发展，核心组成部分和先进的技术。我们解决了研究问题，例如现有的GUI代理框架，用于培训专业GUI代理的数据的收集和利用，针对GUI任务量身定制的大型行动模型的开发以及评估指标和基准评估其有效性所需的评估指标和基准。此外，我们检查了这些代理支持的新兴应用。通过详细的分析，这项调查确定了关键的研究差距，并概述了该领域未来进步的路线图。通过巩固基础知识和最先进的发展，这项工作旨在指导研究人员和从业人员克服挑战并释放LLM脑的GUI代理人的全部潜力。

		- ### Survey of Cultural Awareness in Language Models: Text and Beyond [[arxiv](https://arxiv.org/abs/2411.00860)] [[cool](https://papers.cool/arxiv/2411.00860)] [[pdf](https://arxiv.org/pdf/2411.00860)]
			> **Authors**: Siddhesh Pawar,Junyeong Park,Jiho Jin,Arnav Arora,Junho Myung,Srishti Yadav,Faiz Ghifari Haznitrama,Inhwa Song,Alice Oh,Isabelle Augenstein
			> **First submission**: 2024-10-30
			> **First announcement**: 2024-11-04
			> **comment**: No comments
			- **标题**: 语言模型中文化意识的调查：文本及以后
			- **领域**: 计算语言学,计算机视觉和模式识别
			- **摘要**: 大型语言模型（LLM）在各种应用程序（例如聊天机器人和虚拟助手）中的大规模部署要求LLMS对用户具有文化敏感，以确保包容性。文化在心理学和人类学领域进行了广泛的研究，最近的研究激增了LLM在LLM中更具文化包容性的研究，这超出了多语言性，并以心理学和人类学的发现为基础。在本文中，我们调查了将文化意识纳入基于文本和多模式LLM的工作。我们首先定义LLM中的文化意识，将人类学和心理学的文化定义作为出发点。然后，我们研究用于创建跨文化数据集的方法论，在下游任务中的文化包容策略以及用于基准LLMS文化意识的方法。此外，我们讨论了文化一致性的伦理含义，人类计算机相互作用在推动LLM的文化包容中的作用以及文化一致性在推动社会科学研究中的作用。我们终于根据有关文献差距的发现为未来研究提供指示。

		- ### Understanding World or Predicting Future? A Comprehensive Survey of World Models [[arxiv](https://arxiv.org/abs/2411.14499)] [[cool](https://papers.cool/arxiv/2411.14499)] [[pdf](https://arxiv.org/pdf/2411.14499)]
			> **Authors**: Jingtao Ding,Yunke Zhang,Yu Shang,Yuheng Zhang,Zefang Zong,Jie Feng,Yuan Yuan,Hongyuan Su,Nian Li,Nicholas Sukiennik,Fengli Xu,Yong Li
			> **First submission**: 2024-11-20
			> **First announcement**: 2024-11-22
			> **comment**: No comments
			- **标题**: 了解世界还是预测未来？对世界模型的全面调查
			- **领域**: 计算语言学,人工智能,机器学习
			- **摘要**: 由于多模式大语言模型（例如GPT-4和视频生成模型）（例如Sora）的进步，世界模型的概念引起了极大的关注，这些模型是追求人工通用情报的核心。这项调查对有关世界模型的文献进行了全面的评论。通常，世界模型被视为理解当前世界状态或预测其未来动态的工具。这篇评论提出了对世界模型的系统分类，强调了两个主要功能：（1）构建内部表示以了解世界机制，以及（2）预测未来的状态以模拟和指导决策。最初，我们检查了这两个类别中的当前进展。然后，我们探索世界模型在关键领域的应用，包括自主驾驶，机器人和社交模拟物，重点是每个领域如何利用这些方面。最后，我们概述了关键挑战，并提供了对潜在的未来研究方向的见解。

		- ### Natural Language Understanding and Inference with MLLM in Visual Question Answering: A Survey [[arxiv](https://arxiv.org/abs/2411.17558)] [[cool](https://papers.cool/arxiv/2411.17558)] [[pdf](https://arxiv.org/pdf/2411.17558)]
			> **Authors**: Jiayi Kuang,Jingyou Xie,Haohao Luo,Ronghao Li,Zhe Xu,Xianfeng Cheng,Yinghui Li,Xika Lin,Ying Shen
			> **First submission**: 2024-11-26
			> **First announcement**: 2024-11-27
			> **comment**: No comments
			- **标题**: 自然语言理解和与MLLM在视觉问题回答中的推论：一项调查
			- **领域**: 计算语言学,计算机视觉和模式识别
			- **摘要**: 视觉问题回答（VQA）是一项挑战任务，结合了自然语言处理和计算机视觉技术，并逐渐成为多模式大语模型（MLLM）中的基准测试任务。我们调查的目的是概述VQA的开发以及及时性高的最新模型的详细描述。这项调查提供了对图像和文本的自然语言理解的最新综合，以及基于核心VQA任务的图像问题信息的知识推理模块。此外，我们详细介绍了在VQA中将模态信息与视觉预科模型和多模式大语言模型的最新进展。我们还通过详细说明内部知识的提取和引入外部知识的提取，详尽地回顾了VQA中知识推理的进度。最后，我们介绍VQA的数据集和不同的评估指标，并讨论未来工作的可能指示。

		- ### Blockchain Meets LLMs: A Living Survey on Bidirectional Integration [[arxiv](https://arxiv.org/abs/2411.16809)] [[cool](https://papers.cool/arxiv/2411.16809)] [[pdf](https://arxiv.org/pdf/2411.16809)]
			> **Authors**: Jianghao Gong,Peiqi Yan,Yue Zhang,Hongli An,Logan Liu
			> **First submission**: 2024-11-25
			> **First announcement**: 2024-11-26
			> **comment**: No comments
			- **标题**: 区块链遇到LLM：双向整合的生活调查
			- **领域**: 密码学和安全,人工智能
			- **摘要**: 在大型语言模型的领域中，通过持续的技术进步和创新所推动的多模式大语模型和解释性研究已取得了很大的进步。尽管如此，安全和隐私问题仍在该领域的巨大挑战中构成巨大挑战。区块链技术的出现以其分散性的性质，防篡改属性，分布式存储功能和可追溯性为特征，为解决这些问题提供了新的方法。这两种技术都独立地具有巨大的发展潜力。然而，他们的结合揭示了大量的跨学科机会和增长前景。当前的研究趋势越来越集中于区块链与大语言模型的整合，目的是通过这种融合来弥补其各自的局限性，并促进进一步的技术进化。在这项研究中，我们评估了这两种技术的优势和发展限制，并探讨了它们组合的可能性和发展潜力。本文主要研究了两个方向的技术融合：首先，大型语言模型在区块链中的应用，我们在其中确定了六个主要的开发方向，并探索了解决区块链技术及其应用程序方案的缺点的解决方案；其次，将区块链技术应用于大型语言模型，利用区块链的特征来纠正大型语言模型的缺陷并探索其在多个领域的应用潜力。

		- ### SeafloorAI: A Large-scale Vision-Language Dataset for Seafloor Geological Survey [[arxiv](https://arxiv.org/abs/2411.00172)] [[cool](https://papers.cool/arxiv/2411.00172)] [[pdf](https://arxiv.org/pdf/2411.00172)]
			> **Authors**: Kien X. Nguyen,Fengchun Qiao,Arthur Trembanis,Xi Peng
			> **First submission**: 2024-10-31
			> **First announcement**: 2024-11-01
			> **comment**: No comments
			- **标题**: Seafloorai：海底地质调查局的大规模视觉语言数据集
			- **领域**: 计算机视觉和模式识别,机器学习
			- **摘要**: 海洋科学中机器学习模型进步的主要障碍，尤其是在声纳图像分析中，是AI-Ready数据集的稀缺性。尽管已经努力公开提供AI-Ready Sonar图像数据集，但它们在环境环境和规模方面受到了限制。为了弥合这一差距，我们介绍了Seafloorai，这是第一个广泛的AI-Ready数据集，用于与海洋科学家合作策划的5个地质层的海底映射。我们通过合并语言组件来进一步将数据集扩展到海底，以促进声纳图像的视觉和具有语言能力的机器学习模型的发展。该数据集由62个地理分布的数据调查组成，跨越17,300平方公里，具有696K声纳图像，827K注释的分段掩码，696K详细的语言描述和大约7m的Question-Question-Asswer Pairs。通过使我们的数据处理源代码公开可用，我们旨在吸引海洋科学界丰富数据库并激发机器学习社区开发更健壮的模型。这种协作方法将增强两个字段中数据集的功能和应用。

		- ### Autoregressive Models in Vision: A Survey [[arxiv](https://arxiv.org/abs/2411.05902)] [[cool](https://papers.cool/arxiv/2411.05902)] [[pdf](https://arxiv.org/pdf/2411.05902)]
			> **Authors**: Jing Xiong,Gongye Liu,Lun Huang,Chengyue Wu,Taiqiang Wu,Yao Mu,Yuan Yao,Hui Shen,Zhongwei Wan,Jinfa Huang,Chaofan Tao,Shen Yan,Huaxiu Yao,Lingpeng Kong,Hongxia Yang,Mi Zhang,Guillermo Sapiro,Jiebo Luo,Ping Luo,Ngai Wong
			> **First submission**: 2024-11-08
			> **First announcement**: 2024-11-11
			> **comment**: No comments
			- **标题**: 视觉中的自回归模型：一项调查
			- **领域**: 计算机视觉和模式识别,计算语言学
			- **摘要**: 自自然语言处理领域（NLP）领域取得了巨大成功。最近，自回归模型已成为计算机视觉中的重要重点领域，它们在产生高质量的视觉内容方面表现出色。 NLP中的自动回归模型通常在子字代币上运行。但是，计算机视觉中的表示策略可能会在不同级别上有所不同，\ textit {i.e。}，像素级，令牌级别或比例级别，反映了与语言的顺序结构相比，视觉数据的多样性和分层性质。这项调查全面研究了有关视觉应用的自回旋模型的文献。为了提高来自不同研究背景的研究人员的可读性，我们从视觉中的初步序列表示和建模开始。接下来，我们将视觉自回归模型的基本框架分为三个一般子类别，包括基于代表策略的基于像素，基于令牌的基于代币和基于比例的模型。然后，我们探索自回归模型与其他生成模型之间的互连。此外，我们提出了计算机视觉中自回归模型的多面分类，包括图像生成，视频生成，3D代和多模式生成。我们还详细介绍了它们在不同领域的应用，包括体现的AI和3D Medical AI等新兴领域，其中约有250个相关参考。最后，我们强调了目前对视觉自回归模型的挑战，并提出了有关潜在研究方向的建议。我们还设置了一个GitHub存储库来组织本调查中包含的论文：\ url {https://github.com/chaofantao/autoregrelistion-models-models-in-vision-survey}。

		- ### A Survey on Vision Autoregressive Model [[arxiv](https://arxiv.org/abs/2411.08666)] [[cool](https://papers.cool/arxiv/2411.08666)] [[pdf](https://arxiv.org/pdf/2411.08666)]
			> **Authors**: Kai Jiang,Jiaxing Huang
			> **First submission**: 2024-11-13
			> **First announcement**: 2024-11-14
			> **comment**: This work will be integrated into another project
			- **标题**: 有关视力自回旋模型的调查
			- **领域**: 计算机视觉和模式识别,人工智能
			- **摘要**: 自回归模型在自然语言处理（NLP）方面表现出色，具有令人印象深刻的可伸缩性，适应性和可推广性。受其在NLP领域取得杰出成功的启发，最近对计算机视觉进行了深入的研究，该模型通过将视觉数据表示为视觉令牌，并为广泛的视觉任务做出自动回归建模，从而执行了下一步的预测，从视觉生成和视觉上的理解到最新的多媒体生成，并与单个自动化的模型结合了单个自动效果模型。本文对视力自回归模型进行了系统的审查，包括开发现有方法的分类法，并强调其主要贡献，优势和局限性，涵盖了各种视觉任务，例如图像生成，视频生成，图像编辑，运动生成，运动图像分析，3D代生成，3D代生成，机器人的机器人操作，并在统一的多态生成和分析中，我们在范围内进行了详尽的研究，我们将详细介绍，我们在范围内进行详尽的研究，包括自动的多模式，综合性，综合了，我们的详细信息，包括自动的范围，综合了，我们的讨论，包括自动的范围，构成了范围，并分析了，我们的范围，包括自动的范围，我们在范围内进行了综合，我们的讨论，以及众所周知的范围，以及众所周知的模型，综合了范围。各种评估数据集的方法。最后，我们概述了未来研究的主要挑战和有希望的方向，提供了路线图，以指导视觉自回旋模型的进一步进步。

		- ### Jailbreak Attacks and Defenses against Multimodal Generative Models: A Survey [[arxiv](https://arxiv.org/abs/2411.09259)] [[cool](https://papers.cool/arxiv/2411.09259)] [[pdf](https://arxiv.org/pdf/2411.09259)]
			> **Authors**: Xuannan Liu,Xing Cui,Peipei Li,Zekun Li,Huaibo Huang,Shuhan Xia,Miaoxuan Zhang,Yueying Zou,Ran He
			> **First submission**: 2024-11-14
			> **First announcement**: 2024-11-15
			> **comment**: ongoing work
			- **标题**: 越狱攻击和针对多模式生成模型的防御：一项调查
			- **领域**: 计算机视觉和模式识别,计算语言学
			- **摘要**: 多模式基础模型的快速发展导致了跨模式理解和产生的显着进步，包括文本，图像，音频和视频。但是，这些模型仍然容易受到越狱攻击的影响，越狱攻击可以绕过内置的安全机制并引起潜在有害内容的生产。因此，了解越狱攻击和现有的防御机制的方法对于确保在现实世界中，尤其是在对安全敏感的应用程序中安全部署多模式生成模型至关重要。为了全面了解该主题，这项调查回顾了越狱和防御模型。首先，鉴于多模式越狱的广义生命周期，我们系统地探索了四个级别的攻击和相应的防御策略：输入，编码器，发电机和输出。基于此分析，我们提出了针对多模式生成模型的攻击方法，防御机制和评估框架的详细分类法。此外，我们涵盖了广泛的输入输出配置，包括任何对文本，任何对视频以及生成系统中的任何对任何对任何一无所有的模式。最后，我们重点介绍了当前的研究挑战，并提出了未来研究的潜在方向。可以在https://github.com/liuxuannan/awesome-multimodal-jailbreak上找到与此工作相对应的开源存储库。

		- ### Instruction-Guided Editing Controls for Images and Multimedia: A Survey in LLM era [[arxiv](https://arxiv.org/abs/2411.09955)] [[cool](https://papers.cool/arxiv/2411.09955)] [[pdf](https://arxiv.org/pdf/2411.09955)]
			> **Authors**: Thanh Tam Nguyen,Zhao Ren,Trinh Pham,Thanh Trung Huynh,Phi Le Nguyen,Hongzhi Yin,Quoc Viet Hung Nguyen
			> **First submission**: 2024-11-15
			> **First announcement**: 2024-11-18
			> **comment**: Fixed a serious error in author information
			- **标题**: 指导指导的图像和多媒体的编辑控件：LLM时代的调查
			- **领域**: 计算机视觉和模式识别,人工智能,人机交互,机器学习,多媒体
			- **摘要**: 大型语言模型（LLM）和多模式学习的快速发展已改变了数字内容的创建和操纵。传统的视觉编辑工具需要大量的专业知识，从而限制可访问性。基于教学的编辑的最新进展已使自然语言作为用户意图和复杂编辑操作之间的桥梁实现了与视觉内容的直观互动。这项调查概述了这些技术，重点介绍了LLM和多模型模型如何使用户能够在没有深层技术知识的情况下实现精确的视觉修改。通过综合100多个出版物，我们探讨了从生成对抗网络到扩散模型的方法，检查了多模式集成以进行细颗粒内容控制。我们讨论了跨时尚，3D场景操纵和视频综合等领域的实际应用，突出了可访问性的增加并与人类直觉保持一致。我们的调查比较了现有文献，强调了LLM授权的编辑，并确定了刺激进一步研究的关键挑战。我们旨在使从娱乐到教育的各个行业之间的强大视觉编辑民主化。鼓励有兴趣的读者通过https://github.com/tamlhp/awsome-instruction-editing访问我们的存储库。

		- ### A Survey of Medical Vision-and-Language Applications and Their Techniques  [[arxiv](https://arxiv.org/abs/2411.12195)] [[cool](https://papers.cool/arxiv/2411.12195)] [[pdf](https://arxiv.org/pdf/2411.12195)]
			> **Authors**: Qi Chen,Ruoshan Zhao,Sinuo Wang,Vu Minh Hieu Phan,Anton van den Hengel,Johan Verjans,Zhibin Liao,Minh-Son To,Yong Xia,Jian Chen,Yutong Xie,Qi Wu
			> **First submission**: 2024-11-18
			> **First announcement**: 2024-11-19
			> **comment**: No comments
			- **标题**: 对医学视觉和语言应用的调查及其技术
			- **领域**: 计算机视觉和模式识别
			- **摘要**: 医疗视觉和语言模型（MVLM）由于能力提供了自然语言界面来解释复杂的医学数据，因此引起了重大兴趣。它们的应用程序用途广泛，有可能提高个别患者的诊断准确性和决策，同时还可以通过对大型数据集进行更有效的分析来增强公共卫生监测，疾病监测和决策。 MVLM将自然语言处理与医学图像相结合，以使对医学图像的更全面和上下文的理解以及其相应的文本信息。与经过多种非专业数据集培训的一般视觉和语言模型不同，MVLM是针对医疗领域的专门构建的，可以自动从医学图像和文本报告中提取和解释关键信息，以支持临床决策。 MVLM的流行临床应用包括自动化医学报告生成，医学视觉问题答案，医学多模式分割，诊断和预后以及医学图像文本检索。在这里，我们提供了MVLMS及其应用的各种医疗任务的全面概述。我们对各种视觉和语言模型体系结构进行了详细的分析，重点介绍了他们独特的跨模式集成/剥削医学视觉和文本特征的策略。我们还检查了用于这些任务的数据集，并根据标准化评估指标比较了不同模型的性能。此外，我们强调了潜在的挑战，并总结了未来的研究趋势和方向。论文和代码的完整集合可在以下网址提供：https：//github.com/ytongxie/medical-vision-vision-and-language-tasks-and-methodologies-a-survey。

		- ### MME-Survey: A Comprehensive Survey on Evaluation of Multimodal LLMs [[arxiv](https://arxiv.org/abs/2411.15296)] [[cool](https://papers.cool/arxiv/2411.15296)] [[pdf](https://arxiv.org/pdf/2411.15296)]
			> **Authors**: Chaoyou Fu,Yi-Fan Zhang,Shukang Yin,Bo Li,Xinyu Fang,Sirui Zhao,Haodong Duan,Xing Sun,Ziwei Liu,Liang Wang,Caifeng Shan,Ran He
			> **First submission**: 2024-11-22
			> **First announcement**: 2024-11-25
			> **comment**: Produced by MME+MMBench+LLaVA Teams. Project Page: https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Benchmarks
			- **标题**: mme-survey：一项关于多模式LLMS评估的综合调查
			- **领域**: 计算机视觉和模式识别,人工智能,计算语言学
			- **摘要**: 作为人工智能（AGI）的重要方向，多模式的大语言模型（MLLM）吸引了行业和学术界的关注。在预先训练的LLM的基础上，这个模型家族进一步发展了令人印象深刻的多模式感知和推理能力，例如给出流程图或基于图像创建故事的编写代码。在开发过程中，评估至关重要，因为它为改进模型提供了直观的反馈和指导。不同于传统的火车 - 测试范式，它仅倾向于单个任务，例如图像分类，MLLM的多功能性刺激了各种新基准和评估方法的兴起。在本文中，我们旨在介绍MLLM评估的全面调查，讨论四个关键方面：1）汇总的基准类型除以评估能力，包括基础能力，模型自我分析和范围应用； 2）基准集团的典型过程，包括数据收集，注释和预防措施； 3）由法官，公制和工具包组成的系统评估方式； 4）下一个基准测试的前景。这项工作旨在为研究人员轻松掌握如何根据不同的需求有效评估MLLM并激发更好的评估方法，从而推动MLLM研究的进步。

		- ### Multimodal Alignment and Fusion: A Survey [[arxiv](https://arxiv.org/abs/2411.17040)] [[cool](https://papers.cool/arxiv/2411.17040)] [[pdf](https://arxiv.org/pdf/2411.17040)]
			> **Authors**: Songtao Li,Hao Tang
			> **First submission**: 2024-11-25
			> **First announcement**: 2024-11-26
			> **comment**: 210+ references
			- **标题**: 多模式对准和融合：调查
			- **领域**: 计算机视觉和模式识别
			- **摘要**: 这项调查对机器学习中的多模式对齐和融合的最新进步进行了全面的综述，这是由于文本，图像，音频和视频等数据类型越来越多的多样性所激发的。多模式集成可以通过利用不同模式的互补信息，并促进知识转移的情况下，可以提高模型的准确性和更广泛的适用性。我们系统地对现有的一致性和融合技术进行了系统的分类和分析，从对200多篇相关论文的广泛审查中获取了见解。此外，这项调查解决了多模式数据集成的挑战 - 包括对齐问题，噪声弹性和功能表示差异 - 同时着重于社交媒体分析，医学成像和情感识别等领域中的应用。所提供的见解旨在指导未来的研究，以优化多模式学习系统，以增强其在各种应用程序中的可扩展性，鲁棒性和概括性。
		- ### Passive Deepfake Detection Across Multi-modalities: A Comprehensive Survey [[arxiv](https://arxiv.org/abs/2411.17911)] [[cool](https://papers.cool/arxiv/2411.17911)] [[pdf](https://arxiv.org/pdf/2411.17911)]
			> **Authors**: Hong-Hanh Nguyen-Le,Van-Tuan Tran,Dinh-Thuc Nguyen,Nhien-An Le-Khac
			> **First submission**: 2024-11-26
			> **First announcement**: 2024-11-27
			> **comment**: 26 pages
			- **标题**: 跨多模式的被动深层检测：一项全面的调查
			- **领域**: 计算机视觉和模式识别,密码学和安全
			- **摘要**: 近年来，Deepfakes（DFS）被用于恶意目的，例如个人模仿，错误信息传播以及艺术家的风格模仿，引发了有关道德和安全问题的疑问。但是，现有的调查重点是用于单个模式的被动DF检测方法的准确性，例如图像，视频或音频。这项全面的调查探讨了多种方式的被动方法，包括图像，视频，音频和多模式域，并将我们的讨论扩展到超出检测准确性，包括概括，鲁棒性，属性和解释性。此外，我们讨论了被动方法的威胁模型，包括潜在的对抗策略以及不同水平的对手知识和能力。我们还强调了当前在DF检测中的挑战，包括在不同的生成模型中缺乏概括，对全面的可信度评估的需求以及现有多模式方法的局限性。最后，我们提出了未来的研究方向，该方向在被动DF检测领域中解决了这些未开发和新兴问题，例如自适应学习，动态基准，整体可信赖性评估以及用于说话的视频发电的多模式检测器。
	
	
	10. [monthly-category-2024-12](monthly-category-2024-12)

		- ### From Specific-MLLMs to Omni-MLLMs: A Survey on MLLMs Aligned with Multi-modalities [[arxiv](https://arxiv.org/abs/2412.11694)] [[cool](https://papers.cool/arxiv/2412.11694)] [[pdf](https://arxiv.org/pdf/2412.11694)]
			> **Authors**: Shixin Jiang,Jiafeng Liang,Jiyuan Wang,Xuan Dong,Heng Chang,Weijiang Yu,Jinhua Du,Ming Liu,Bing Qin
			> **First submission**: 2024-12-16
			> **First announcement**: 2024-12-17
			> **comment**: 35 pages
			- **标题**: 从特定的MLLMs到Omni-MLLMs：与多模式对齐的MLLM的调查
			- **领域**: 人工智能,计算语言学,机器学习
			- **摘要**: 为了解决现实情况下的复杂任务，越来越多的研究人员专注于Omni-Mllms，旨在获得Omni-Modal-Modal的理解和产生。除了任何特定非语言模式的约束之外，Omni-Mllms还将各种非语言模式映射到LLMS的嵌入空间中，并使单个模型中模态的任意组合具有相互作用和理解。在本文中，我们系统地研究了相关研究，并对Omni-Mllms进行了全面的调查。具体而言，我们首先解释了Omni-Mllms的四个核心组成部分，用于统一的多模式建模，并具有细致的分类法，提供了新的观点。然后，我们介绍了通过两阶段培训实现的有效整合，并讨论相应的数据集和评估。此外，我们总结了当前Omni-Mllms的主要挑战，并概述了未来的方向。我们希望本文成为初学者的介绍，并促进相关研究的进步。资源已在https://github.com/threegold116/awesome-omni-mllms上公开提供。

		- ### Survey of Large Multimodal Model Datasets, Application Categories and Taxonomy [[arxiv](https://arxiv.org/abs/2412.17759)] [[cool](https://papers.cool/arxiv/2412.17759)] [[pdf](https://arxiv.org/pdf/2412.17759)]
			> **Authors**: Priyaranjan Pattnayak,Hitesh Laxmichand Patel,Bhargava Kumar,Amit Agarwal,Ishan Banerjee,Srikant Panda,Tejaswini Kumar
			> **First submission**: 2024-12-23
			> **First announcement**: 2024-12-24
			> **comment**: No comments
			- **标题**: 大型多模式模型数据集，应用程序类别和分类学调查
			- **领域**: 人工智能,计算机视觉和模式识别,机器学习
			- **摘要**: 多模式学习是人工智能中快速发展的领域，试图通过整合和分析各种类型的数据（包括文本，图像，音频和视频）来构建更广泛和健壮的系统。受到人类通过多种感官吸收信息的能力的启发，此方法可以实现诸如文本到视频转换，视觉问题的回答和图像字幕之类的应用程序。在此概述中，强调了支持多模式模型（MLLM）的数据集中的最新发展。大规模的多模式数据集是必不可少的，因为它们允许对这些模型进行彻底的测试和培训。该研究强调了他们对学科的贡献，研究了各种数据集，包括用于培训的数据集，特定于领域的任务和现实世界应用程序。它还强调了在一系列方案，可伸缩性和适用性中评估模型性能的关键基准数据集的重要性。由于多模式学习总是在变化，因此克服这些障碍将有助于AI研究，并应用应用新高度。

		- ### A Survey on Large Language Model Acceleration based on KV Cache Management [[arxiv](https://arxiv.org/abs/2412.19442)] [[cool](https://papers.cool/arxiv/2412.19442)] [[pdf](https://arxiv.org/pdf/2412.19442)]
			> **Authors**: Haoyang Li,Yiming Li,Anxin Tian,Tianhao Tang,Zhanchao Xu,Xuejia Chen,Nicole Hu,Wei Dong,Qing Li,Lei Chen
			> **First submission**: 2024-12-26
			> **First announcement**: 2024-12-30
			> **comment**: No comments
			- **标题**: 基于KV缓存管理的大型语言模型加速度的调查
			- **领域**: 人工智能,分布式、并行和集群计算
			- **摘要**: 大型语言模型（LLM）彻底改变了广泛的领域，例如自然语言处理，计算机视觉和多模式任务，因为它们能够理解上下文和执行逻辑推理。但是，LLM的计算和内存需求，尤其是在推断期间，在将其扩展到现实世界，长篇下C下文和实时应用程序时会构成重大挑战。键值（KV）缓存管理已成为一种关键的优化技术，用于通过减少冗余计算和改善内存利用来加速LLM推断。这项调查提供了针对LLM加速的KV缓存管理策略的全面概述，将其分为令牌级别，模型级别和系统级优化。令牌级的策略包括KV缓存选择，预算分配，合并，量化和低级别分解，而模型级优化的侧重于架构创新和注意力机制，以增强KV重复使用。系统级别的方法解决内存管理，调度和硬件感知设计，以提高各种计算环境的效率。此外，调查还概述了用于评估这些策略的文本和多模式数据集和基准。通过介绍详细的分类法和比较分析，这项工作旨在为研究人员和从业人员提供有用的见解，以支持开发高效且可扩展的KV缓存管理技术，从而有助于LLM在现实世界中的实际部署。 KV缓存管理的策划纸张列表在：\ href {https://github.com/treai-lab/awesome-kv-cache-management} {https://github.com/treeai-lab/awesome-lab/awesome-kv-cache-management}。

		- ### Explainable and Interpretable Multimodal Large Language Models: A Comprehensive Survey [[arxiv](https://arxiv.org/abs/2412.02104)] [[cool](https://papers.cool/arxiv/2412.02104)] [[pdf](https://arxiv.org/pdf/2412.02104)]
			> **Authors**: Yunkai Dang,Kaichen Huang,Jiahao Huo,Yibo Yan,Sirui Huang,Dongrui Liu,Mengxi Gao,Jie Zhang,Chen Qian,Kun Wang,Yong Liu,Jing Shao,Hui Xiong,Xuming Hu
			> **First submission**: 2024-12-02
			> **First announcement**: 2024-12-03
			> **comment**: No comments
			- **标题**: 可解释且可解释的多模式大语言模型：一项全面调查
			- **领域**: 计算语言学
			- **摘要**: 人工智能（AI）的快速发展彻底改变了许多领域，大型语言模型（LLM）和计算机视觉（CV）系统分别推动了自然语言理解和视觉处理的进步。这些技术的融合促进了多模式AI的兴起，从而使更丰富的跨模式理解能够跨越文本，视觉，音频和视频方式。尤其是多模式的大语言模型（MLLM）已成为一个强大的框架，在图像文本生成，视觉问题答案和跨模式检索等任务中展示了令人印象深刻的功能。尽管取得了这些进步，但MLLM的复杂性和规模在可解释性和解释性方面带来了重大挑战，对于在高风险应用中建立透明度，可信度和可靠性至关重要。本文提供了有关MLLM的可解释性和解释性的全面调查，提出了一个新颖的框架，该框架将现有研究对三个角度进行分类：（i）数据，（ii）模型，（iii）培训\＆推断。我们系统地分析了从代币级别到嵌入级别表示，评估与建筑分析和设计相关的方法，并探索提高透明度的培训和推理策略。通过比较各种方法，我们确定了它们的优势和局限性，并提出了未来的研究方向，以解决多模式解释性中未解决的挑战。这项调查提供了提高MLLM的可解释性和透明度的基础资源，指导研究人员和从业人员开发更负责任，强大的多模式AI系统。

		- ### A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges [[arxiv](https://arxiv.org/abs/2412.11936)] [[cool](https://papers.cool/arxiv/2412.11936)] [[pdf](https://arxiv.org/pdf/2412.11936)]
			> **Authors**: Yibo Yan,Jiamin Su,Jianxiang He,Fangteng Fu,Xu Zheng,Yuanhuiyi Lyu,Kun Wang,Shen Wang,Qingsong Wen,Xuming Hu
			> **First submission**: 2024-12-16
			> **First announcement**: 2024-12-17
			> **comment**: No comments
			- **标题**: 多模式大语言模型时代的数学推理调查：基准，方法和挑战
			- **领域**: 计算语言学
			- **摘要**: 数学推理是人类认知的一个核心方面，在许多领域，从教育问题到科学进步至关重要。随着人工通用情报（AGI）的进步，将大语言模型（LLMS）与数学推理任务相结合变得越来越重要。这项调查提供了对多模式大语模型（MLLM）时代数学推理的首次全面分析。我们回顾了自2021年以来发表的200多个研究，并研究了数学插件的最新发展，重点是多模式设置。我们将该领域分为三个维度：基准，方法和挑战。特别是，我们探讨了多模式数学推理管道，以及（M）LLM和相关方法的作用。最后，我们确定了阻碍该领域中AGI实现的五个主要挑战，从而为增强多模式推理能力的未来方向提供了见解。这项调查是研究社区的关键资源，以促进LLMS解决复杂多模式推理任务的能力。

		- ### Next Token Prediction Towards Multimodal Intelligence: A Comprehensive Survey [[arxiv](https://arxiv.org/abs/2412.18619)] [[cool](https://papers.cool/arxiv/2412.18619)] [[pdf](https://arxiv.org/pdf/2412.18619)]
			> **Authors**: Liang Chen,Zekun Wang,Shuhuai Ren,Lei Li,Haozhe Zhao,Yunshui Li,Zefan Cai,Hongcheng Guo,Lei Zhang,Yizhe Xiong,Yichi Zhang,Ruoyu Wu,Qingxiu Dong,Ge Zhang,Jian Yang,Lingwei Meng,Shujie Hu,Yulong Chen,Junyang Lin,Shuai Bai,Andreas Vlachos,Xu Tan,Minjia Zhang,Wen Xiao,Aaron Yee, et al. (2 additional authors not shown)
			> **First submission**: 2024-12-16
			> **First announcement**: 2024-12-25
			> **comment**: 69 papes, 18 figures, repo at https://github.com/LMM101/Awesome-Multimodal-Next-Token-Prediction
			- **标题**: 对多模式智能的下一步预测：一项全面调查
			- **领域**: 计算语言学,人工智能,计算机视觉和模式识别,机器学习,多媒体,音频和语音处理
			- **摘要**: 在自然语言处理中的语言建模基础上，隔壁预测（NTP）已演变为一个多功能的培训目标，以实现各种方式的机器学习任务，从而取得了相当大的成功。随着大型语言模型（LLMS）在文本模式中统一理解和生成任务，最近的研究表明，来自不同模式的任务也可以有效地封装在NTP框架中，将多模式信息转换为代币并预测下一个给定上下文的下一个。这项调查介绍了一项全面的分类学，该分类法统一了通过NTP镜头在多模式学习中统一的理解和产生。提出的分类法涵盖了五个关键方面：多模式令牌化，MMNTP模型体系结构，统一任务表示，数据集\＆评估以及开放挑战。这种新的分类法旨在帮助研究人员探索多模式智能。相关的GitHub存储库收集最新论文和存储库，请访问https://github.com/lmm101/awesome-multimodal-next-token-prediction

		- ### Deepfake Media Generation and Detection in the Generative AI Era: A Survey and Outlook [[arxiv](https://arxiv.org/abs/2411.19537)] [[cool](https://papers.cool/arxiv/2411.19537)] [[pdf](https://arxiv.org/pdf/2411.19537)]
			> **Authors**: Florinel-Alin Croitoru,Andrei-Iulian Hiji,Vlad Hondru,Nicolae Catalin Ristea,Paul Irofti,Marius Popescu,Cristian Rusu,Radu Tudor Ionescu,Fahad Shahbaz Khan,Mubarak Shah
			> **First submission**: 2024-11-29
			> **First announcement**: 2024-12-02
			> **comment**: No comments
			- **标题**: 生成AI时代的DeepFake媒体生成和检测：调查和前景
			- **领域**: 计算机视觉和模式识别,人工智能,机器学习,多媒体,声音,音频和语音处理
			- **摘要**: 随着生成建模的最新进展，Deepfake内容的现实主义一直在稳定增长，甚至达到人们经常无法在网上检测到操纵的媒体内容的地步，从而被欺骗到各种骗局中。在本文中，我们调查了深层生成和检测技术，包括该领域的最新发展，例如扩散模型和神经辐射场。我们的文献评论涵盖了所有DeepFake媒体类型，包括图像，视频，音频和多模式（视听）内容。我们根据用于更改或生成伪造内容的程序来确定各种深层效果。我们进一步构建了深层产生和检测方法的分类法，说明了使用这些方法的重要组和域的重要组。接下来，我们收集用于DeepFake检测的数据集，并在最受欢迎的数据集上提供最佳性能DeepFake检测器的更新排名。此外，我们开发了一种新型的多模式基准，以评估分布含量含量的深层探测器。结果表明，最新的检测器无法推广到未见的深泡产生器产生的深泡含量。最后，我们提出未来的方向，以获取强大而强大的深层探测器。我们的项目页面和新基准可以在https://github.com/croitorualin/biodeep上找到。

		- ### Personalized Multimodal Large Language Models: A Survey [[arxiv](https://arxiv.org/abs/2412.02142)] [[cool](https://papers.cool/arxiv/2412.02142)] [[pdf](https://arxiv.org/pdf/2412.02142)]
			> **Authors**: Junda Wu,Hanjia Lyu,Yu Xia,Zhehao Zhang,Joe Barrow,Ishita Kumar,Mehrnoosh Mirtaheri,Hongjie Chen,Ryan A. Rossi,Franck Dernoncourt,Tong Yu,Ruiyi Zhang,Jiuxiang Gu,Nesreen K. Ahmed,Yu Wang,Xiang Chen,Hanieh Deilamsalehy,Namyong Park,Sungchul Kim,Huanrui Yang,Subrata Mitra,Zhengmian Hu,Nedim Lipka,Dang Nguyen,Yue Zhao, et al. (2 additional authors not shown)
			> **First submission**: 2024-12-02
			> **First announcement**: 2024-12-03
			> **comment**: No comments
			- **标题**: 个性化的多模式大语言模型：调查
			- **领域**: 计算机视觉和模式识别,人工智能,计算语言学,信息检索
			- **摘要**: 多模式的大型语言模型（MLLM）由于其最新性能以及整合多种数据模式（例如文本，图像和音频）的能力而变得越来越重要，以高精度执行复杂的任务。本文介绍了一项有关个性化多式模式模型的全面调查，重点是其建筑，培训方法和应用。我们提出了一种直观的分类法，以对将MLLM个性化的技术分类为个人用户，并相应地讨论这些技术。此外，我们讨论了如何在适当的时候将这些技术组合或适应，以突出它们的优势和基本的理由。我们还提供了现有研究中调查的个性化任务的简洁摘要以及常用的评估指标。此外，我们总结了可用于基准个性化MLLM的数据集。最后，我们概述了关键的开放挑战。这项调查旨在为寻求理解和推动个性化多模式大型语言模型的研究人员和从业人员提供宝贵资源。
		- ### AgriBench: A Hierarchical Agriculture Benchmark for Multimodal Large Language Models [[arxiv](https://arxiv.org/abs/2412.00465)] [[cool](https://papers.cool/arxiv/2412.00465)] [[pdf](https://arxiv.org/pdf/2412.00465)]
			> **Authors**: Yutong Zhou,Masahiro Ryo
			> **First submission**: 2024-11-30
			> **First announcement**: 2024-12-03
			> **comment**: Accepted by CVPPA @ECCV2024. Dataset: https://github.com/Yutong-Zhou-cv/AgriBench
			- **标题**: Agribench：多模式模型的分层农业基准
			- **领域**: 计算机视觉和模式识别,人工智能
			- **摘要**: 我们介绍了Agribench，这是第一个旨在评估农业应用多模型模型（MM-LLMS）的农业基准。 To further address the agriculture knowledge-based dataset limitation problem, we propose MM-LUCAS, a multimodal agriculture dataset, that includes 1,784 landscape images, segmentation masks, depth maps, and detailed annotations (geographical location, country, date, land cover and land use taxonomic details, quality scores, aesthetic scores, etc), based on the Land Use/Cover Area Frame Survey (LUCAS)数据集包含有关欧盟（EU）领土土地使用和土地覆盖的可比统计数据。这项工作提出了推进农业MM-llms的开创性观点，并且仍在进行中，为未来的特定专家基于知识的MM-llms提供了宝贵的见解。

		- ### A Comprehensive Survey of Action Quality Assessment: Method and Benchmark [[arxiv](https://arxiv.org/abs/2412.11149)] [[cool](https://papers.cool/arxiv/2412.11149)] [[pdf](https://arxiv.org/pdf/2412.11149)]
			> **Authors**: Kanglei Zhou,Ruizhi Cai,Liyuan Wang,Hubert P. H. Shum,Xiaohui Liang
			> **First submission**: 2024-12-15
			> **First announcement**: 2024-12-16
			> **comment**: No comments
			- **标题**: 对行动质量评估的全面调查：方法和基准测试
			- **领域**: 计算机视觉和模式识别
			- **摘要**: 行动质量评估（AQA）定量评估人类行动的质量，提供自动评估，以减少人类判断中的偏见。它的应用程序涵盖了体育分析，技能评估和医疗服务等领域。 AQA的最新进展引入了创新的方法，但是类似的方法经常跨不同领域交织在一起，突出了阻碍系统评价的分散性质。此外，缺乏统一的基准和有限的计算比较阻碍了对AQA方法的一致评估和公平评估。在这项工作中，我们通过系统地分析超过150个与AQA相关的论文来开发层次分类法，构建统一的基准，并对当前趋势，挑战和未来的方向进行深入分析，从而解决这些差距。我们的层次分类学对基于输入方式（视频，骨架，多模式）及其特定特征的AQA方法进行了分类，从而突出了各种方法的进化和相互关系。为了促进标准化，我们提出了一个统一的基准测试，并集成了不同的数据集，以评估评估精度和计算效率。最后，我们回顾了新兴任务特定的应用程序，并确定了AQA中未经探索的挑战，从而为未来的研究方向提供了可行的见解。这项调查旨在加深对AQA进度的了解，促进方法比较并指导未来的创新。可以在https://zhoukanglei.github.io/aqa-survey上找到项目网页。

		- ### Towards Visual Grounding: A Survey [[arxiv](https://arxiv.org/abs/2412.20206)] [[cool](https://papers.cool/arxiv/2412.20206)] [[pdf](https://arxiv.org/pdf/2412.20206)]
			> **Authors**: Linhui Xiao,Xiaoshan Yang,Xiangyuan Lan,Yaowei Wang,Changsheng Xu
			> **First submission**: 2024-12-28
			> **First announcement**: 2024-12-30
			> **comment**: TPAMI under review. We keep tracing related works at https://github.com/linhuixiao/Awesome-Visual-Grounding
			- **标题**: 迈向视觉接地：调查
			- **领域**: 计算机视觉和模式识别
			- **摘要**: 视觉接地也称为参考表达理解和短语接地。它涉及基于给定的文本描述在图像中将自然数量的特定区域定位。这项任务的目的是模仿社交对话中普遍的参考关系，使机器为人类般的多模式理解能力提供了装备。因此，它在各个领域都有广泛的应用。然而，自2021年以来，视觉接地取得了重大的进步，新兴的概念，例如扎根的预训练，接地多模式LLM，广义视觉接地和GIGA像素接地，这带来了许多新的挑战。在这项调查中，我们最初研究了视觉接地的发展历史，并提供了基本背景知识的概述。我们系统地跟踪和总结了进步并精心组织视觉接地的各种环境，从而确立了这些设置的精确定义，以标准化未来的研究并确保进行公平的比较。此外，我们深入研究了几个高级主题，并突出了许多视觉接地的应用。最后，我们概述了视觉基础面临的挑战，并为未来的研究提出了宝贵的方向，这可能是后续研究人员的灵感。通过提取共同的技术细节，本调查涵盖了过去十年来每个亚主题中的代表作品。最好的是，本文介绍了接地领域当前可用的最全面的概述。该调查旨在适合初学者和经验丰富的研究人员，是理解关键概念和跟踪最新研究发展的宝贵资源。我们在https://github.com/linhuixiao/awesome-visual-grounding上一直在追踪相关作品。

		- ### Modular Conversational Agents for Surveys and Interviews [[arxiv](https://arxiv.org/abs/2412.17049)] [[cool](https://papers.cool/arxiv/2412.17049)] [[pdf](https://arxiv.org/pdf/2412.17049)]
			> **Authors**: Jiangbo Yu,Jinhua Zhao,Luis Miranda-Moreno,Matthew Korp
			> **First submission**: 2024-12-22
			> **First announcement**: 2024-12-23
			> **comment**: No comments
			- **标题**: 调查和访谈的模块化对话代理
			- **领域**: 人机交互,计算语言学,计算机与社会,多媒体
			- **摘要**: 调查和访谈被广泛用于收集有关新兴或假设情景的见解。传统的人为主导的方法通常面临与成本，可扩展性和一致性有关的挑战。最近，各种领域已经开始探索由生成人工智能（AI）技术提供动力的对话代理（聊天机器人）的使用。但是，考虑到运输投资和政策的决策通常会带来大量的公共和环境风险，调查和访谈在整合AI代理方面面临着独特的挑战，强调了对严格，资源有效的方法的需求，以增强参与者的参与并确保隐私。本文通过引入模块化方法及其设计AI代理的参数化过程来解决这一差距。我们详细介绍了系统体系结构，整合工程的提示，专业知识库以及可定制的，面向目标的对话逻辑。我们通过三项实证研究证明了模块化方法的适应性，可推广性和功效：（1）旅行偏好调查，突出有条件的逻辑和多模式（语音，文本和图像生成）功能； （2）对新建造的新型基础设施项目的舆论启发，展示问题定制和多语言（英语和法语）功能； （3）有关技术对未来运输系统的影响的专家咨询，突出了针对开放式问题的实时，澄清请求功能，处理不稳定的输入方面的弹性以及有效的成绩单后处理。结果表明，AI代理会提高完成率和响应质量。此外，模块化方法表现出可控性，灵活性和鲁棒性，同时解决了关键的道德，隐私，安全性和令牌消费问题。

		- ### A Survey on Sequential Recommendation [[arxiv](https://arxiv.org/abs/2412.12770)] [[cool](https://papers.cool/arxiv/2412.12770)] [[pdf](https://arxiv.org/pdf/2412.12770)]
			> **Authors**: Liwei Pan,Weike Pan,Meiyan Wei,Hongzhi Yin,Zhong Ming
			> **First submission**: 2024-12-17
			> **First announcement**: 2024-12-18
			> **comment**: No comments
			- **标题**: 关于连续建议的调查
			- **领域**: 信息检索
			- **摘要**: 与大多数常规建议问题不同，顺序建议通过利用相互作用的项目之间的内部顺序和依赖性来关注学习用户的偏好，这已经受到了研究人员和从业者的极大关注。近年来，我们目睹了这一领域取得的巨大进步和成就，需要进行新的调查。在这项调查中，我们从新的角度研究了SR问题（即，构建项目的属性），并总结了顺序建议中使用的最新技术，例如纯基于ID的SR，带有侧面信息，多模式SR，生成SR，LLM-PAREED SR，Ultra-Long SR，Ultra-Long SR，Ultra-long-long-long-long sr和Data-data-augented sr。此外，我们在顺序推荐中介绍了一些前沿研究主题，例如开放域SR，数据以数据为中心的SR，Come-Edge-Edge-Edge-Edge Cromportation Sr，Contunuel Sr，Sr，SR，for Ode-Oxply和可解释的SR。我们认为，我们的调查可以作为该领域读者的宝贵路线图。
		- ### Survey of different Large Language Model Architectures: Trends, Benchmarks, and Challenges [[arxiv](https://arxiv.org/abs/2412.03220)] [[cool](https://papers.cool/arxiv/2412.03220)] [[pdf](https://arxiv.org/pdf/2412.03220)]
			> **Authors**: Minghao Shao,Abdul Basit,Ramesh Karri,Muhammad Shafique
			> **First submission**: 2024-12-04
			> **First announcement**: 2024-12-05
			> **comment**: No comments
			- **标题**: 对不同语言模型体系结构的调查：趋势，基准和挑战
			- **领域**: 机器学习
			- **摘要**: 大型语言模型（LLMS）代表了一类深度学习模型，旨在理解自然语言并对各种提示或查询产生连贯的响应。这些模型远远超过了常规神经网络的复杂性，通常包含数十个神经网络层，并包含数十亿至万亿个参数。它们通常在庞大的数据集上进行培训，利用基于变压器块的体系结构。当今的LLM是多功能的，能够执行从文本生成和语言翻译到问题答案以及代码生成和分析的一系列任务。这些模型的高级子集（称为多模式大语言模型（MLLM））扩展了LLM功能来处理和解释多个数据模式，包括图像，音频和视频。这种增强功能使MLLM具有视频编辑，图像理解和视觉内容字幕的功能。这项调查概述了LLM的最新进展。我们首先要追踪LLM的发展，然后深入研究MLLM的出现和细微差别。我们分析新兴的最先进的MLLM，探索他们的技术特征，优势和局限性。此外，我们对这些模型进行了比较分析，并讨论了它们的挑战，潜在的局限性以及未来发展的前景。

		- ### Video Quality Assessment: A Comprehensive Survey [[arxiv](https://arxiv.org/abs/2412.04508)] [[cool](https://papers.cool/arxiv/2412.04508)] [[pdf](https://arxiv.org/pdf/2412.04508)]
			> **Authors**: Qi Zheng,Yibo Fan,Leilei Huang,Tianyu Zhu,Jiaming Liu,Zhijian Hao,Shuo Xing,Chia-Ju Chen,Xiongkuo Min,Alan C. Bovik,Zhengzhong Tu
			> **First submission**: 2024-12-04
			> **First announcement**: 2024-12-06
			> **comment**: No comments
			- **标题**: 视频质量评估：一项全面调查
			- **领域**: 图像和视频处理,计算机视觉和模式识别
			- **摘要**: 视频质量评估（VQA）是一项重要的处理任务，旨在以高度与人类对感知质量的判断一致的方式预测视频的质量。传统的VQA模型基于自然图像和/或视频统计数据，这些模型既受到现实世界的预测图像的模型和人类视觉系统的双重模型的启发，仅在现实世界中用户生成的内容（UGC）上提供有限的预测性能，这在最近的大型VQA数据库中被大量的VQA数据库所示，其中包含大量多样化视频内容的大量视频内容。幸运的是，深度神经网络和大型多模型模型（LMM）的最新进展已在解决此问题方面取得了重大进展，与先前的手工制作模型相比，结果更好。已经开发了许多基于深度学习的VQA模型，并在此方向上取得了进步，这是由内容多样性的，大规模的人类标记的数据库驱动的，这些数据库提供了地面真相心理学的视频质量数据。在这里，我们对VQA算法开发以及使其成为可能的基准研究和数据库的最新进展进行了全面调查。我们还分析了有关研究设计和VQA算法体系结构的开放研究方向。 github链接：https：//github.com/taco-group/video-equality-ecsessment-a-comprehmiss-survey

		- ### From Generalist to Specialist: A Survey of Large Language Models for Chemistry [[arxiv](https://arxiv.org/abs/2412.19994)] [[cool](https://papers.cool/arxiv/2412.19994)] [[pdf](https://arxiv.org/pdf/2412.19994)]
		> **Authors**: Yang Han,Ziping Wan,Lu Chen,Kai Yu,Xin Chen
		> **First submission**: 2024-12-27
		> **First announcement**: 2024-12-30
		> **comment**: COLING2025,We maintain an up-to-date Github repository at: https://github.com/OpenDFM/LLM4Chemistry
		- **标题**: 从通才到专家：化学大语模型的调查
		- **领域**: 化学物理,人工智能,计算语言学,机器学习
		- **摘要**: 大型语言模型（LLMS）显着改变了我们的日常生活，并建立了自然语言处理（NLP）的新范式。但是，在广泛的基于Web的文本上，LLM的主要预读是不足以进行先进的科学发现，尤其是在化学方面。专业化学数据的稀缺性，再加上多模式数据的复杂性，例如2D图，3D结构和频谱，提出了不同的挑战。尽管几项研究已经回顾了化学方面的语言模型（PLM），但有明显的系统调查专门针对化学的LLM。在本文中，我们概述了将域特异性化学知识和多模式信息纳入LLM的方法，我们还将化学LLMS概念化为使用化学工具的代理，并研究了它们加速科学研究的潜力。此外，我们总结了现有的基准测试，以评估LLM的化学能力。最后，我们严格研究当前的挑战，并确定未来研究的有希望的方向。通过这项综合调查，我们旨在帮助研究人员保持化学LLMS开发的最前沿，并激发该领域的创新应用。

	12. [monthly-category-2025-01](monthly-category-2025-01)

		- ### Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches [[arxiv](https://arxiv.org/abs/2501.03151)] [[cool](https://papers.cool/arxiv/2501.03151)] [[pdf](https://arxiv.org/pdf/2501.03151)]
			> **Authors**: Alhassan Mumuni,Fuseini Mumuni
			> **First submission**: 2025-01-06
			> **First announcement**: 2025-01-07
			> **comment**: No comments
			- **标题**: 人工通用情报（AGI）的大型语言模型：基础原理和方法的调查
			- **领域**: 人工智能,计算机视觉和模式识别,机器学习
			- **摘要**: 基于大规模预处理基础模型（PFM）的生成人工智能（AI）系统，例如视觉语言模型，大语言模型（LLMS），扩散模型和视觉模型（VLA）模型，已经证明了在各种领域和上下文中求解复杂且真正的非琐事AI问题的能力。尤其是多模式的大语言模型（MLLM）从广泛而多样化的数据源中学习，允许世界上富裕和细微的表现形式，从而提供广泛的功能，包括推理能力，参与有意义的对话；与人类和其他代理商合作，共同解决复杂的问题；并了解人类的社会和情感方面。尽管这一令人印象深刻的壮举，但在大规模数据集中训练的最先进的LLM的认知能力仍然是肤浅而脆弱的。因此，通用LLM的通才能力受到严重限制。需要解决许多基本问题 - 实施例，符号接地，因果关系和记忆，以使LLMS获得人级的一般智能。这些概念与人类认知更加一致，并为LLM提供了固有的类似人类的认知特性，这些特性支持实现物理上可行的，语义上有意义的，灵活的，更具概括性的知识和智慧。在这项工作中，我们讨论了上述基础问题和调查最先进的方法，用于在LLMS中实施这些概念。具体而言，我们讨论了如何利用实施例，符号接地，因果关系和记忆的原理来以有机方式获得人工通用智能（AGI）。

		- ### From Screens to Scenes: A Survey of Embodied AI in Healthcare [[arxiv](https://arxiv.org/abs/2501.07468)] [[cool](https://papers.cool/arxiv/2501.07468)] [[pdf](https://arxiv.org/pdf/2501.07468)]
			> **Authors**: Yihao Liu,Xu Cao,Tingting Chen,Yankai Jiang,Junjie You,Minghua Wu,Xiaosong Wang,Mengling Feng,Yaochu Jin,Jintai Chen
			> **First submission**: 2025-01-13
			> **First announcement**: 2025-01-14
			> **comment**: 56 pages, 11 figures, manuscript accepted by Information Fusion
			- **标题**: 从屏幕到场景：对医疗保健体现AI的调查
			- **领域**: 人工智能
			- **摘要**: 全球医疗保健系统在效率，可及性和个性化方面面临持续的挑战。体现的AI（EMAI）由现代AI技术（例如多模式大语言模型和世界模型）提供支持，代表着一种变革性的边境，提供了增强的自主权，并具有与物理世界互动以应对这些挑战的能力。作为一个跨学科和快速发展的研究领域，“医疗保健中的EMAI”跨越了各种领域，例如算法，机器人技术和生物医学。这种复杂性强调了及时审查和分析以跟踪进步，应对挑战和促进跨学科合作的重要性。在本文中，我们提供了EMAI医疗保健“大脑”的全面概述，其中我们介绍了基础AI AI算法，以进行感知，驱动，计划和记忆，并专注于介绍涉及临床干预，日常护理和陪伴，基础设施支持以及生物医学研究的医疗保健应用程序。尽管有希望，但诸如安全问题，模拟平台和现实世界应用之间的差距，缺乏标准化的基准和跨学科范围内的不均匀进展的关键挑战所阻碍了EMAI用于医疗保健的发展。我们讨论技术障碍并探讨道德考虑，并为EMAI在医疗保健中的未来提供了前瞻性的看法。还引入了针对EMAI系统的智能水平的层次结构框架，以指导进一步的发展。通过提供系统的见解，这项工作旨在激发创新和实际应用，为智能，以患者为中心的医疗保健的新时代铺平道路。
		- ### Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey [[arxiv](https://arxiv.org/abs/2501.07766)] [[cool](https://papers.cool/arxiv/2501.07766)] [[pdf](https://arxiv.org/pdf/2501.07766)]
			> **Authors**: Bingchen Liu,Xin Li
			> **First submission**: 2025-01-13
			> **First announcement**: 2025-01-14
			> **comment**: No comments
			- **标题**: 知识图嵌入技术，方法和挑战的大型语言模型：调查
			- **领域**: 计算语言学,人工智能
			- **摘要**: 大型语言模型（LLM）由于其出色的表现而引起了各个领域的大量关注，旨在培训数亿或更多参数，以了解和生成自然语言。随着LLM的出色性能变得显而易见，它们越来越多地应用于知识图嵌入（KGE）相关任务以改善处理结果。作为自然语言处理（NLP）领域的深度学习模型，它学习了大量文本数据，以预测下一个单词或生成与给定文本有关的内容。但是，最近在不同类型的KGE相关场景（例如多模式KGE）和根据其任务特征开放KGE的情况下，LLMS被不同程度调用。在本文中，我们研究了在不同类型的KGE方案中执行与LLMS相关的任务的广泛方法。为了更好地比较各种方法，我们在分类中总结了每个KGE方案。除了分类方法外，我们还提供了该方法及其源代码链接的表格概述，以进行更直接的比较。在文章中，我们还讨论了主要使用这些方法的应用，并为开发该新研究领域的开发提出了几个前瞻性方向。

		- ### Benchmark Evaluations, Applications, and Challenges of Large Vision Language Models: A Survey [[arxiv](https://arxiv.org/abs/2501.02189)] [[cool](https://papers.cool/arxiv/2501.02189)] [[pdf](https://arxiv.org/pdf/2501.02189)]
			> **Authors**: Zongxia Li,Xiyang Wu,Hongyang Du,Huy Nghiem,Guangyao Shi
			> **First submission**: 2025-01-03
			> **First announcement**: 2025-01-06
			> **comment**: 35 pages, 3 figures
			- **标题**: 大型视觉语言模型的基准评估，应用和挑战：调查
			- **领域**: 计算机视觉和模式识别,人工智能,计算语言学,机器学习,机器人技术
			- **摘要**: 在计算机视觉和自然语言处理的交集中，多模式视觉语言模型（VLM）已成为一种变革性技术，使机器能够通过视觉和文本方式来感知和理性。例如，诸如剪辑，克劳德（Claude）和GPT-4V之类的模型在视觉和文本数据上表现出强烈的推理和理解能力，并在零摄像分类上击败了经典的单一模态视觉模型。尽管它们在研究方面迅速发展和在应用方面日益普及，但对现有的VLMS研究的全面调查显然是缺乏的，特别是对于旨在利用VLM在特定领域中的研究人员而言。为此，我们在以下方面提供了VLM的系统概述：过去五年中开发的主要VLM的模型信息（2019-2024）；这些VLM的主要体系结构和培训方法； VLMS的流行基准和评估指标的摘要和分类； VLM的应用，包括具体的代理，机器人技术和视频生成；幻觉，公平和安全等当前VLM所面临的挑战和问题。 https://github.com/zli12321/awsome-vlm-papers-and-models.git中列出了包括论文和模型存储库在内的详细集合。

		- ### Visual question answering: from early developments to recent advances -- a survey [[arxiv](https://arxiv.org/abs/2501.03939)] [[cool](https://papers.cool/arxiv/2501.03939)] [[pdf](https://arxiv.org/pdf/2501.03939)]
			> **Authors**: Ngoc Dung Huynh,Mohamed Reda Bouadjenek,Sunil Aryal,Imran Razzak,Hakim Hacid
			> **First submission**: 2025-01-07
			> **First announcement**: 2025-01-08
			> **comment**: 20 papers
			- **标题**: 视觉问题回答：从早期发展到最近的进步 - 一项调查
			- **领域**: 计算机视觉和模式识别,多媒体
			- **摘要**: 视觉问题回答（VQA）是一个不断发展的研究领域，旨在通过整合图像和语言处理技术，例如特征提取，对象检测，文本嵌入，自然语言理解和语言产生来回答有关视觉内容的问题。随着多模式数据研究的增长，VQA由于其广泛的应用，包括交互式教育工具，医学图像诊断，客户服务，娱乐和社交媒体字幕，引起了人们的关注。此外，VQA通过从图像中产生描述性内容来帮助视力障碍个体起着至关重要的作用。这项调查介绍了VQA体系结构的分类法，根据设计选择和关键组成部分对它们进行分类，以促进比较分析和评估。我们回顾了主要的VQA方法，专注于基于深度学习的方法，并探索大型视觉语言模型（LVLMS）的新兴领域，这些模型在诸如VQA之类的多模式任务中都取得了成功。本文进一步研究了可用的数据集和评估指标，这对于测量VQA系统性能至关重要，然后探索了实际VQA应用程序。最后，我们强调了VQA研究中的持续挑战和未来的方向，提出了开放的问题和潜在的进一步发展领域。这项调查是对最新进步和未来感兴趣的研究人员和从业者的综合资源

		- ### Generative AI for Cel-Animation: A Survey [[arxiv](https://arxiv.org/abs/2501.06250)] [[cool](https://papers.cool/arxiv/2501.06250)] [[pdf](https://arxiv.org/pdf/2501.06250)]
			> **Authors**: Yunlong Tang,Junjia Guo,Pinxin Liu,Zhiyuan Wang,Hang Hua,Jia-Xing Zhong,Yunzhong Xiao,Chao Huang,Luchuan Song,Susan Liang,Yizhi Song,Liu He,Jing Bi,Mingqian Feng,Xinyang Li,Zeliang Zhang,Chenliang Xu
			> **First submission**: 2025-01-08
			> **First announcement**: 2025-01-13
			> **comment**: 20 pages
			- **标题**: 生成AI用于Cel-Animation：调查
			- **领域**: 计算机视觉和模式识别,人工智能,人机交互
			- **摘要**: 传统的赛璐oid（CEL）动画生产管道包括多个基本步骤，包括故事板，布局设计，密钥帧动画，互联网和着色，它们需要大量的手动工作，技术专业知识和大量的时间投资。这些挑战历史上阻碍了Cel-Animation生产的效率和可扩展性。生成人工智能（Genai）的兴起，包括大型语言模型，多模式模型和扩散模型，通过自动化任务（例如框架的生成，着色和故事板创建）来提供创新的解决方案。这项调查探讨了Genai整合如何通过降低技术障碍，通过Anidoc，Tooncrafter和Anisora等工具来拓宽技术障碍，扩大更广泛的创作者的可访问性，并使艺术家能够更多地专注于创造性的表达和艺术创新。尽管具有潜力，但仍保持视觉一致性，确保风格连贯性以及解决道德考虑的问题继续构成挑战。此外，本文讨论了未来的方向，并探讨了AI辅助动画的潜在进步。有关进一步的探索和资源，请访问我们的GitHub存储库：https：//github.com/yunlong10/awesome-ai4animation

		- ### A Survey on Dynamic Neural Networks: from Computer Vision to Multi-modal Sensor Fusion [[arxiv](https://arxiv.org/abs/2501.07451)] [[cool](https://papers.cool/arxiv/2501.07451)] [[pdf](https://arxiv.org/pdf/2501.07451)]
			> **Authors**: Fabio Montello,Ronja Güldenring,Simone Scardapane,Lazaros Nalpantidis
			> **First submission**: 2025-01-13
			> **First announcement**: 2025-01-14
			> **comment**: Under review at International Journal of Computer Vision
			- **标题**: 动态神经网络的调查：从计算机视觉到多模式传感器融合
			- **领域**: 计算机视觉和模式识别
			- **摘要**: 模型压缩对于在嵌入式设备上部署大型计算机视觉模型至关重要。但是，静态优化技术（例如修剪，量化等）忽略了以下事实：不同的输入具有不同的复杂性，因此需要不同量的计算。动态神经网络允许调节计算数量到特定输入。当前有关该主题的文献非常广泛和分散。我们提出了一项全面的调查，该调查在计算机视觉的背景下综合并统一了现有的动态神经网络研究。此外，我们基于网络的哪个组件自适应提供逻辑分类法：输出，计算图或输入。此外，我们认为动态神经网络在传感器融合的背景下特别有益，以更好地适应性，降低降噪和信息优先级。我们朝着这个方向介绍初步作品。

		- ### A Survey on Computational Pathology Foundation Models: Datasets, Adaptation Strategies, and Evaluation Tasks [[arxiv](https://arxiv.org/abs/2501.15724)] [[cool](https://papers.cool/arxiv/2501.15724)] [[pdf](https://arxiv.org/pdf/2501.15724)]
			> **Authors**: Dong Li,Guihong Wan,Xintao Wu,Xinyu Wu,Ajit J. Nirmal,Christine G. Lian,Peter K. Sorger,Yevgeniy R. Semenov,Chen Zhao
			> **First submission**: 2025-01-26
			> **First announcement**: 2025-01-27
			> **comment**: No comments
			- **标题**: 计算病理基础模型的调查：数据集，适应策略和评估任务
			- **领域**: 计算机视觉和模式识别,人工智能
			- **摘要**: 计算病理基础模型（CPATHFM）已成为分析组织病理学数据的强大方法，利用自我监督的学习来从未标记的全片图像中提取强大的特征表示。这些模型归类为单模式和多模式框架，在自动化复杂的病理任务（例如分割，分类和生物标志物发现）方面已经证明了有望。但是，CPATHFM的开发提出了重大挑战，例如有限的数据可访问性，跨数据集的高可变性，特定于领域的适应性的必要性以及缺乏标准化的评估基准。这项调查对计算病理学中的CPathFM进行了全面综述，重点是数据集，适应策略和评估任务。我们分析了关键技术，例如对比度学习和多模式集成，并突出了当前研究中的现有差距。最后，我们从四个角度探索未来的方向来推进CPathFM。这项调查是研究人员，临床医生和AI从业人员的宝贵资源，指导CPATHFMS促进稳健和临床适用的AI驱动病理解决方案。

		- ### Image, Text, and Speech Data Augmentation using Multimodal LLMs for Deep Learning: A Survey [[arxiv](https://arxiv.org/abs/2501.18648)] [[cool](https://papers.cool/arxiv/2501.18648)] [[pdf](https://arxiv.org/pdf/2501.18648)]
			> **Authors**: Ranjan Sapkota,Shaina Raza,Maged Shoman,Achyut Paudel,Manoj Karkee
			> **First submission**: 2025-01-29
			> **First announcement**: 2025-01-31
			> **comment**: No comments
			- **标题**: 使用多模式LLM进行深度学习的图像，文本和语音数据扩展：调查
			- **领域**: 计算机视觉和模式识别
			- **摘要**: 在过去的五年中，研究已从传统的机器学习（ML）和深度学习（DL）方法转变为利用大型语言模型（LLMS），包括多模式，以增强数据增强，以增强概括，并在培训深层卷积神经网络中对过度拟合。但是，尽管现有的调查主要集中在ML和DL技术或有限的模式（文本或图像）上，但差距仍在解决基于LLM的方法的最新进步和多模式应用方面。这项调查通过探索最近的文献利用多模式LLM来增强图像，文本和音频数据，从而填补了这一空白，从而对这些过程有了全面的了解。我们概述了基于LLM的图像，文本和语音增强中使用的各种方法，并讨论了当前方法中确定的局限性。此外，我们确定了对文献中这些局限性的潜在解决方案，以增强使用多模式LLM的数据增强实践的功效。这项调查是未来研究的基础，旨在完善和扩展多模式LLMS的使用，以增强数据集质量和多样性，以实现深度学习应用程序。 (Surveyed Paper GitHub Repo: https://github.com/WSUAgRobotics/data-aug-multi-modal-llm. Keywords: LLM data augmentation, LLM text data augmentation, LLM image data augmentation, LLM speech data augmentation, audio augmentation, voice augmentation, chatGPT for data augmentation, DeepSeek R1 text data augmentation, DeepSeek R1图像增强，使用LLM的图像增强，使用LLM，LLM数据增强的文本增强，用于深度学习应用程序）

		- ### New Fashion Products Performance Forecasting: A Survey on Evolutions, Models and Emerging Trends [[arxiv](https://arxiv.org/abs/2501.10324)] [[cool](https://papers.cool/arxiv/2501.10324)] [[pdf](https://arxiv.org/pdf/2501.10324)]
			> **Authors**: Andrea Avogaro,Luigi Capogrosso,Andrea Toaiari,Franco Fummi,Marco Cristani
			> **First submission**: 2025-01-17
			> **First announcement**: 2025-01-20
			> **comment**: Accepted at the Springer Nature Computer Science journal
			- **标题**: 新的时尚产品性能预测：一项有关演变，模型和新兴趋势的调查
			- **领域**: 机器学习,计算机视觉和模式识别
			- **摘要**: 快速时装行业对新风格和快速生产周期的需求无限的需求导致了巨大的环境负担。生产过多，浪费过多和有害化学物质导致了该行业的负面影响。为了减轻这些问题，迫切需要迫切需要将可持续性和效率优先考虑的范式转变。将基于学习的预测分析纳入时装业是应对环境挑战并推动可持续实践的重要机会。通过预测时尚趋势和优化生产，品牌可以减少其生态足迹，同时在快速变化的市场中保持竞争力。但是，预测时尚销售的主要挑战之一是消费者偏好的动态性质。时尚是周期性的，趋势不断发展和浮出水面。此外，文化变化和意外事件可能会破坏已建立的模式。这个问题也被称为新的时尚产品性能预测（NFPPF），最近它对全球研究景观引起了越来越多的兴趣。鉴于其多学科性质，NFPPF领域已从许多不同的角度接近。这项全面的调查希望提供最新的概述，重点是基于学习的NFPPF策略。该调查基于用于系统评价和荟萃分析（PRISMA）方法流的首选报告项目，从而允许进行系统和完整的文献综述。特别是，我们提出了涵盖NFPPF学习全景的第一个分类学，详细检查了用于增加多模式信息量的不同方法以及可用的最先进的可用数据集。最后，我们讨论挑战和未来的方向。



		- ### A Survey on Diffusion Models for Anomaly Detection [[arxiv](https://arxiv.org/abs/2501.11430)] [[cool](https://papers.cool/arxiv/2501.11430)] [[pdf](https://arxiv.org/pdf/2501.11430)]
			> **Authors**: Jing Liu,Zhenchao Ma,Zepu Wang,Chenxuanyin Zou,Jiayang Ren,Zehua Wang,Liang Song,Bo Hu,Yang Liu,Victor C. M. Leung
			> **First submission**: 2025-01-20
			> **First announcement**: 2025-01-21
			> **comment**: No comments
			- **标题**: 一项关于分散检测扩散模型的调查
			- **领域**: 机器学习,人工智能
			- **摘要**: 扩散模型（DMS）已成为强大的生成AI模型类别，在各个领域的异常检测（AD）任务中显示出巨大的潜力，例如网络安全，欺诈检测，医疗保健和制造。这两个字段的相交称为异常检测（DMAD）的扩散模型，提供了有希望的解决方案，用于识别日益复杂且高维数据中的偏差。在这项调查中，我们回顾了DMAD研究的最新进展。我们首先介绍AD和DMS的基本概念，然后对包括DDPM，DDIMS和SCORE SDE在内的经典DM体系结构进行全面分析。我们将现有的DMAD方法进一步分为基于重建，基于密度和混合方法的方法，从而提供了其方法论创新的详细检查。我们还探索了不同数据模式的各种任务，包括图像，时间序列，视频和多模式数据分析。此外，我们讨论了关键的挑战和新兴的研究方向，包括计算效率，模型解释性，鲁棒性增强，边缘云协作以及与大语言模型的集成。 DMAD研究论文和资源的收集可在https://github.com/fdjingliu/dmad上获得。

		- ### A Survey of World Models for Autonomous Driving [[arxiv](https://arxiv.org/abs/2501.11260)] [[cool](https://papers.cool/arxiv/2501.11260)] [[pdf](https://arxiv.org/pdf/2501.11260)]
			> **Authors**: Tuo Feng,Wenguan Wang,Yi Yang
			> **First submission**: 2025-01-19
			> **First announcement**: 2025-01-20
			> **comment**: Ongoing project
			- **标题**: 对自动驾驶世界模型的调查
			- **领域**: 机器人技术,计算机视觉和模式识别
			- **摘要**: 强大的世界建模方面的进步，从根本上改变了车辆如何解释动态场景并执行安全的决策。特别是，世界模型已成为一项Linchpin技术，提供了整合多传感器数据，语义提示和时间动态的驱动环境的高保真表示。本文系统地回顾了世界模型的自动驾驶模型的最新进展，提出了三层分类学：1）生成未来的物理世界，涵盖图像，BEV-，OG-，OG-和PC基于PC的生成方法，从而通过扩散模型和4D占用率预测来增强场景演变建模； 2）针对智能代理的行为规划，将基于规则驱动的范式和基于学习的范例与成本图优化和增强学习的轨迹学习相结合； 3）预测与计划之间的互动，通过潜在的空间扩散和内存增强体系结构实现多代理协作决策。该研究进一步分析了培训范式，包括自我监督学习，多模式预处理和生成数据增强，同时评估世界模型在场景理解和运动预测任务中的表现。未来的研究必须应对自我监督的表示学习，长尾场景产生和多模式融合的关键挑战，以推动复杂的城市环境中世界模型的实际部署。总体而言，我们的全面分析提供了一个理论框架和技术路线图，用于利用世界模型在推进安全可靠的自动驾驶解决方案方面的变革潜力。

		-  [Vision-Based Multimodal Interfaces: A Survey and Taxonomy for Enhanced Context-Aware System Design](https://arxiv.org/abs/2501.13443)
  			- **标题**: 基于视觉的多模式接口：增强上下文感知系统设计的调查和分类学

	13. [monthly-category-2025-02](monthly-category-2025-02)


		- ### Artificial Intelligence in Spectroscopy: Advancing Chemistry from Prediction to Generation and Beyond [[arxiv](https://arxiv.org/abs/2502.09897)] [[cool](https://papers.cool/arxiv/2502.09897)] [[pdf](https://arxiv.org/pdf/2502.09897)]
			> **Authors**: Kehan Guo,Yili Shen,Gisela Abigail Gonzalez-Montiel,Yue Huang,Yujun Zhou,Mihir Surve,Zhichun Guo,Prayel Das,Nitesh V Chawla,Olaf Wiest,Xiangliang Zhang
			> **First submission**: 2025-02-13
			> **First announcement**: 2025-02-14
			> **comment**: No comments
			- **标题**: 光谱法中的人工智能：从预测到世代及以后的化学反应前进
			- **领域**: 人工智能,机器学习
			- **摘要**: 机器学习（ML）和人工智能（AI）的快速出现已经催化了化学的重大转化，但是这些方法将这些方法应用于光谱和光谱数据，称为光谱机器学习（SpectRAML），它仍然相对尚未被逐渐流行。现代光谱技术（MS，NMR，IR，Raman，UV-VIS）产生了不断增长的高维数据，超出了传统的基于专家的工作流程，对自动化和智能分析产生了迫切需求。在这项调查中，我们提供了统一的综述，对远期任务（分子到光谱预测）和倒数任务（频谱到 - 分子推断）的谱系进行了系统检查的最新方法。我们追踪了光谱中ML的历史演变，从早期模式识别到能够进行高级推理的最新基础模型，并提供了代表性神经体系结构的分类学，包括基于图基和基于变压器的方法。在应对数据质量，多模式集成和计算可扩展性等关键挑战时，我们突出了新兴方向，例如合成数据生成，大规模预处理和少数或零摄像的学习。为了培养可重复的研究，我们还发布了一个开源存储库，其中包含最近的论文及其相应的策划数据集（https://github.com/mine-lab-nd/spectrumml_survey_papers）。我们的调查是研究人员的路线图，并指导光谱和AI交集的进步。


		- ### A Survey on Bridging EEG Signals and Generative AI: From Image and Text to Beyond [[arxiv](https://arxiv.org/abs/2502.12048)] [[cool](https://papers.cool/arxiv/2502.12048)] [[pdf](https://arxiv.org/pdf/2502.12048)]
			> **Authors**: Shreya Shukla,Jose Torres,Abhijit Mishra,Jacek Gwizdka,Shounak Roychowdhury
			> **First submission**: 2025-02-17
			> **First announcement**: 2025-02-18
			> **comment**: No comments
			- **标题**: 一项有关桥接脑电图和生成AI的调查：从图像和文本到超越
			- **领域**: 人工智能,人机交互,机器学习
			- **摘要**: 大脑计算机界面（BCIS）和生成人工智能（Genai）的整合已经开放了大脑信号解码，促进辅助通信，神经表示学习和多模式整合的新边界。 BCI，尤其是那些利用脑电图（EEG）的人，提供了一种将神经活动转化为有意义的输出的非侵入性手段。深度学习的最新进展，包括生成的对抗性网络（GAN）和基于变形金刚的大型语言模型（LLMS），已显着改善了基于脑电图的图像，文本和语音的产生。本文提供了对基于EEG的多模式生成的最先进的文献综述，重点介绍了（i）通过GAN，变异自动编码器（VAE）和扩散模型以及（ii）eeg-to-to-toxt Text生成杠杆化杠杆杠杆化的语言模型和损坏学习方法。此外，我们讨论了EEG到语音综合的新兴领域，这是一种不断发展的多模式前沿。我们重点介绍关键数据集，用例，挑战和EEG功能编码方法，这些方法是生成方法的基础。通过提供基于EEG的生成AI的结构化概述，该调查旨在为研究人员和从业人员提供洞察力，以推动神经解码，增强辅助技术并扩大脑部计算机相互作用的前沿。

		- ### A Survey of Automatic Prompt Engineering: An Optimization Perspective [[arxiv](https://arxiv.org/abs/2502.11560)] [[cool](https://papers.cool/arxiv/2502.11560)] [[pdf](https://arxiv.org/pdf/2502.11560)]
			> **Authors**: Wenwu Li,Xiangfeng Wang,Wenhao Li,Bo Jin
			> **First submission**: 2025-02-17
			> **First announcement**: 2025-02-18
			> **comment**: 19 pages, 4 figures
			- **标题**: 自动及时工程的调查：优化视角
			- **领域**: 人工智能,机器学习
			- **摘要**: 基础模型的兴起已将重点从资源密集的微调转变为促使工程设计，这是一种通过输入设计而不是重量更新来指导模型行为的范式。手动及时工程虽然面临可伸缩性，适应性和跨模式对齐的限制，自动化方法，基于基础模型（FM）的优化，进化方法，基于梯度的优化和强化学习，但提供了有希望的解决方案。但是，现有的调查仍然跨越模态和方法论。本文通过统一的优化理论镜头介绍了对自动化及时工程的首次全面调查。我们将迅速优化的正式优化作为一个最大化问题，而不是离散，连续和混合提示空间，通过其优化变量（指令，软提示，示例），特定于任务的目标和计算框架来系统地组织方法。通过将理论表述与跨文本，视觉和多模式领域的实际实现相结合，该调查为研究人员和从业人员建立了一个基本框架，同时突出了在约束优化和面向代理的及时设计方面未经驱动的边界。


		- ### Large Multimodal Models for Low-Resource Languages: A Survey [[arxiv](https://arxiv.org/abs/2502.05568)] [[cool](https://papers.cool/arxiv/2502.05568)] [[pdf](https://arxiv.org/pdf/2502.05568)]
			> **Authors**: Marian Lupascu,Ana-Cristina Rogoz,Mihai Sorin Stupariu,Radu Tudor Ionescu
			> **First submission**: 2025-02-08
			> **First announcement**: 2025-02-10
			> **comment**: No comments
			- **标题**: 低资源语言的大型多式模型：调查
			- **领域**: 计算语言学,人工智能,机器学习
			- **摘要**: 在这项调查中，我们系统地分析了用于调整低资源（LR）语言的大型多模型模型（LMM）的技术，研究了从视觉增强和数据创建到跨模式传输和融合策略的方法。通过对跨75 LR语言的106项研究的全面分析，我们确定了研究人员如何应对有限数据和计算资源的挑战的关键模式。我们发现，视觉信息通常是改善LR设置模型性能的关键桥梁，尽管在幻觉缓解和计算效率等领域仍存在重大挑战。我们旨在为研究人员提供清楚的了解，以使LR（研究研究的）语言更容易使LMM更容易获得挑战。我们通过以下网址提供的开源存储库来补充：https：//github.com/marianlupascu/lmm4lrl-survey。



		- ### Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation [[arxiv](https://arxiv.org/abs/2502.05151)] [[cool](https://papers.cool/arxiv/2502.05151)] [[pdf](https://arxiv.org/pdf/2502.05151)]
			> **Authors**: Steffen Eger,Yong Cao,Jennifer D'Souza,Andreas Geiger,Christian Greisinger,Stephanie Gross,Yufang Hou,Brigitte Krenn,Anne Lauscher,Yizhi Li,Chenghua Lin,Nafise Sadat Moosavi,Wei Zhao,Tristan Miller
			> **First submission**: 2025-02-07
			> **First announcement**: 2025-02-10
			> **comment**: Work in progress. Will be updated soon
			- **标题**: 通过大型语言模型转化科学：一项有关AI辅助科学发现，实验，内容生成和评估的调查
			- **领域**: 计算语言学,人工智能,计算机视觉和模式识别,机器学习
			- **摘要**: 随着大型多模式模型的出现，科学现在正处于基于AI的技术转型的一个门槛上。最近，已经提出了众多新的AI模型和工具，有望使全球研究人员和学者更有效，有效地进行研究。这包括研究周期的所有方面，特别是（1）寻找相关文献； （2）产生研究思想和进行实验；生成（3）基于文本的和（4）多模式内容（例如，科学数字和图）； （5）基于AI的自动同行评审。在这项调查中，我们对这些令人兴奋的最新发展提供了深入的概述，这些发展有望从根本上改变科学研究过程。我们的调查涵盖了上面概述的五个方面，表明相关的数据集，方法和结果（包括评估）以及未来研究的限制和范围。关于这些工具缺点和滥用潜力（假科学，窃，对研究完整性的危害）的道德问题在我们的讨论中特别重要。我们希望我们的调查不仅将成为该领域的新移民的参考指南，而且还将成为“ AI4Science”领域的新计划的催化剂。


		- ### Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation [[arxiv](https://arxiv.org/abs/2502.08826)] [[cool](https://papers.cool/arxiv/2502.08826)] [[pdf](https://arxiv.org/pdf/2502.08826)]
			> **Authors**: Mohammad Mahdi Abootorabi,Amirhosein Zobeiri,Mahdi Dehghani,Mohammadali Mohammadkhani,Bardia Mohammadi,Omid Ghahroodi,Mahdieh Soleymani Baghshah,Ehsaneddin Asgari
			> **First submission**: 2025-02-12
			> **First announcement**: 2025-02-13
			> **comment**: GitHub repository: https://github.com/llm-lab-org/Multimodal-RAG-Survey
			- **标题**: 以任何方式询问：一项关于多式联运的全面调查
			- **领域**: 计算语言学,人工智能,信息检索
			- **摘要**: 大型语言模型（LLM）由于依赖静态培训数据而与幻觉和过时的知识斗争。通过集成外部动态信息来增强事实和更新的基础，检索增强的生成（RAG）通过整合外部动态信息来减轻这些问题。多模式学习的最新进展导致了多模式抹布的发展，并结合了多种模式，例如文本，图像，音频和视频，以增强生成的输出。但是，跨模式的对齐和推理对多模式抹布引入了独特的挑战，将其与传统的单峰抹布区分开。这项调查提供了对多模式抹布系统的结构化和全面分析，涵盖了检索，融合，增强和一代中的数据集，指标，基准，评估，方法和创新。我们精确地审查了培训策略，鲁棒性增强和损失功能，同时还探索了多种多态的破布场景。此外，我们讨论了支持这个不断发展的领域进步的开放挑战和未来的研究方向。这项调查为开发更有效和可靠的AI系统的基础奠定了基础，这些系统有效地利用了多模式动态外部知识库。资源可在https://github.com/llm-lab-org/multimodal-rag-survey上找到。

		- ### Semantic Role Labeling: A Systematical Survey [[arxiv](https://arxiv.org/abs/2502.08660)] [[cool](https://papers.cool/arxiv/2502.08660)] [[pdf](https://arxiv.org/pdf/2502.08660)]
			> **Authors**: Huiyao Chen,Meishan Zhang,Jing Li,Min Zhang,Lilja Øvrelid,Jan Hajič,Hao Fei
			> **First submission**: 2025-02-09
			> **First announcement**: 2025-02-13
			> **comment**: No comments
			- **标题**: 语义角色标签：系统调查
			- **领域**: 计算语言学
			- **摘要**: 语义角色标签（SRL）是一种中央自然语言处理（NLP）任务，旨在了解文本中的语义角色，从而促进了广泛的下游应用程序。尽管SRL获得了广泛而持久的研究，但目前缺乏全面的调查，可以彻底组织和综合该领域。本文旨在回顾过去二十年来SRL社区的整个研究轨迹。我们首先提供SRL的完整定义。为了提供全面的分类法，我们将SRL方法论分为四个关键角度：模型架构，语法功能建模，应用程序方案和多模式扩展。此外，我们讨论了SRL基准，评估指标和范式建模方法，同时还探索了各个领域的实际应用。最后，我们分析了SRL的未来研究方向，以解决SRL在大语言模型（LLMS）（LLMS）及其对更广泛的NLP景观的潜在影响的不断发展的作用。我们维护一个公共存储库，并始终在以下网址更新相关资源

		- ### A Survey of LLM-based Agents in Medicine: How far are we from Baymax? [[arxiv](https://arxiv.org/abs/2502.11211)] [[cool](https://papers.cool/arxiv/2502.11211)] [[pdf](https://arxiv.org/pdf/2502.11211)]
			> **Authors**: Wenxuan Wang,Zizhan Ma,Zheng Wang,Chenghan Wu,Wenting Chen,Xiang Li,Yixuan Yuan
			> **First submission**: 2025-02-16
			> **First announcement**: 2025-02-17
			> **comment**: No comments
			- **标题**: 一项基于LLM的医学代理的调查：我们离Baymax有多远？
			- **领域**: 计算语言学,人工智能,计算机视觉和模式识别
			- **摘要**: 大型语言模型（LLM）通过开发基于LLM的代理商可以理解，推理和协助医疗任务来改变医疗保健。这项调查提供了对基于LLM的医学代理商的全面审查，研究了其体系结构，应用和挑战。我们分析了医疗代理系统的关键组成部分，包括系统概况，临床计划机制，医疗推理框架和外部能力增强。该调查涵盖了主要的应用程序方案，例如临床决策支持，医疗文献，培训模拟和医疗服务优化。我们讨论用于评估这些代理在医疗保健环境中的表现的评估框架和指标。尽管基于LLM的代理商在增强医疗保健提供方面表现出了希望，但仍有一些挑战，包括幻觉管理，多模式整合，实施障碍和道德考虑。该调查结束了，强调未来的研究方向，包括受LLM体系结构最近发展，与物理系统集成以及培训模拟的改进的医学推理的进步。这项工作为研究人员和从业人员提供了有关医学中LLM代理的现状和未来前景的结构化概述。
		
		- ### How to Upscale Neural Networks with Scaling Law? A Survey and Practical Guidelines [[arxiv](https://arxiv.org/abs/2502.12051)] [[cool](https://papers.cool/arxiv/2502.12051)] [[pdf](https://arxiv.org/pdf/2502.12051)]
			> **Authors**: Ayan Sengupta,Yash Goel,Tanmoy Chakraborty
			> **First submission**: 2025-02-17
			> **First announcement**: 2025-02-18
			> **comment**: 20 pages, 8 tables, 4 figures
			- **标题**: 如何使用缩放法来提高神经网络？调查和实用准则
			- **领域**: 计算语言学,机器学习
			- **摘要**: 神经缩放定律通过揭示模型大小，数据集量和计算资源之间的可预测关系，彻底改变了大规模AI模型的设计和优化。早期研究在模型绩效中建立了幂律关系，从而导致了最佳的缩放策略。但是，最近的研究强调了它们在架构，方式和部署环境之间的局限性。稀疏的模型，专家的混合物，检索式学习和多模型通常偏离传统的缩放模式。此外，缩放行为在视觉，增强学习和微调等领域各不相同，强调了对更细微的方法的需求。在这项调查中，我们综合了50多项研究的见解，研究了缩放定律的理论基础，经验发现和实际含义。我们还探讨了关键挑战，包括数据效率，推理缩放和特定于体系结构的约束，并提倡针对现实世界应用量身定制的自适应缩放策略。我们建议，尽管扩展法律提供了有用的指南，但它们并不总是在所有架构和培训策略中概括。


		- ### LLMs in Software Security: A Survey of Vulnerability Detection Techniques and Insights [[arxiv](https://arxiv.org/abs/2502.07049)] [[cool](https://papers.cool/arxiv/2502.07049)] [[pdf](https://arxiv.org/pdf/2502.07049)]
			> **Authors**: Ze Sheng,Zhicheng Chen,Shuning Gu,Heqing Huang,Guofei Gu,Jeff Huang
			> **First submission**: 2025-02-10
			> **First announcement**: 2025-02-11
			> **comment**: 33 pages, 12 figures
			- **标题**: 软件安全性LLM：漏洞检测技术和见解的调查
			- **领域**: 密码学和安全,人工智能
			- **摘要**: 大型语言模型（LLM）正在成为用于软件漏洞检测的变革性工具，从而解决了安全域中的关键挑战。传统方法（例如静态和动态分析）通常由于低效率，高误报率以及现代软件系统日益增长的复杂性而动摇。通过利用其分析代码结构的能力，识别模式并生成维修建议，LLM，以GPT，BERT和CODEBERT等模型为例，提出了一种新颖且可扩展的方法来减轻脆弱性。本文提供了脆弱性检测中LLM的详细调查。它研究了关键方面，包括模型架构，应用程序方法，目标语言，微调策略，数据集和评估指标。我们还分析了当前研究问题的范围，突出了现有方法的优势和劣势。此外，我们应对诸如跨语言漏洞检测，多模式数据集成和存储库级分析等挑战。基于这些发现，我们为在低资源场景中的数据集可伸缩性，模型可解释性和应用程序等问题提出了解决方案。我们的贡献是三个方面：（1）对LLM在脆弱性检测中的应用； （2）对研究之间共享模式和差异的分析，并具有理解该领域的统一框架； （3）关键挑战和未来研究方向的摘要。这项工作为推进基于LLM的脆弱性检测提供了宝贵的见解。我们还在https://github.com/owensanzas/llm-for-vulnerability-detection上维护并定期更新最新的选定论文
		
		- ### A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations [[arxiv](https://arxiv.org/abs/2502.14881)] [[cool](https://papers.cool/arxiv/2502.14881)] [[pdf](https://arxiv.org/pdf/2502.14881)]
			> **Authors**: Mang Ye,Xuankun Rong,Wenke Huang,Bo Du,Nenghai Yu,Dacheng Tao
			> **First submission**: 2025-02-14
			> **First announcement**: 2025-02-21
			> **comment**: 22 pages, 2 figures
			- **标题**: 大型视觉模型的安全性调查：攻击，防御和评估
			- **领域**: 密码学和安全,计算机视觉和模式识别
			- **摘要**: 随着大型视觉模型（LVLM）的快速发展，确保其安全性已成为至关重要的研究领域。这项调查提供了对LVLM安全性的全面分析，涵盖了诸如攻击，防御和评估方法之类的关键方面。我们介绍了一个统一的框架，该框架整合了这些相互关联的组件，为LVLM的脆弱性和相应的缓解策略提供了整体观点。通过对LVLM生命周期的分析，我们引入了一个分类框架，该框架区分推理和训练阶段，并提供了进一步的子类别，以提供更深入的见解。此外，我们强调了现有研究的局限性，并概述了未来的方向，旨在增强LVLM的鲁棒性。作为我们研究的一部分，我们对最新的LVLM DeepSeek Janus-Pro进行了一系列安全评估，并对结果进行了理论分析。我们的发现提供了提高LVLM安全性并确保其在高风险，现实世界中的安全部署的战略建议。这项调查旨在作为未来研究的基石，促进了模型的开发，不仅可以突破多模式智能的界限，而且还遵守了最高的安全和道德完整性标准。此外，为了帮助这一领域的研究，我们创建了一个公共存储库，以不断编译和更新有关LVLM安全的最新工作：https：//github.com/xuankunrong/awsome/awsome-lvlm-safety。


		- ### Efficiently Integrate Large Language Models with Visual Perception: A Survey from the Training Paradigm Perspective [[arxiv](https://arxiv.org/abs/2502.01524)] [[cool](https://papers.cool/arxiv/2502.01524)] [[pdf](https://arxiv.org/pdf/2502.01524)]
			> **Authors**: Xiaorui Ma,Haoran Xie,S. Joe Qin
			> **First submission**: 2025-02-03
			> **First announcement**: 2025-02-04
			> **comment**: 28 pages, 3 figures
			- **标题**: 有效地将大型语言模型与视觉感知整合：从训练范式角度来看的调查
			- **领域**: 计算机视觉和模式识别,人工智能,计算语言学,机器学习
			- **摘要**: 视觉语言方式的整合一直是多模式学习的重点，传统上依赖于视觉识别的模型。但是，随着大型语言模型（LLM）的出现，朝着将LLM与视觉方式结合在一起的明显转变。此后，将视力模式纳入LLM的训练范例已经发展。最初，该方法是通过预处理模态积分器（名为单阶段调整）来整合模式。此后，它已将其分支为重点是增强性能的方法，称为两阶段调整，以及那些优先级参数效率（称为直接适应）。但是，现有的调查主要通过两阶段的调整来解决最新的大语言模型（VLLM），从而差距了解训练范式的演变及其独特的参数有效考虑因素。本文对顶级会议，期刊和高度引用的Arxiv论文进行了分类和审查，从训练范式的角度来调整了参数效率。我们首先介绍LLM和参数效率学习方法的架构，然后讨论视觉编码器和模态积分器的全面分类学。然后，我们回顾了三个培训范例及其效率注意事项，总结了VLLM领域的基准。为了更深入了解其在参数效率上的有效性，我们比较并讨论了代表模型的实验结果，其中重复了直接适应范式的实验。该调查提供了有关最新发展和实际用途的见解，是研究人员和从业者有效地整合到LLM中的重要指南。

	- ### Embodied Intelligence for 3D Understanding: A Survey on 3D Scene Question Answering [[arxiv](https://arxiv.org/abs/2502.00342)] [[cool](https://papers.cool/arxiv/2502.00342)] [[pdf](https://arxiv.org/pdf/2502.00342)]
		> **Authors**: Zechuan Li,Hongshan Yu,Yihao Ding,Yan Li,Yong He,Naveed Akhtar
		> **First submission**: 2025-02-01
		> **First announcement**: 2025-02-04
		> **comment**: Work in progress
		- **标题**: 3D理解的体现智能：关于3D场景问题的调查回答
		- **领域**: 计算机视觉和模式识别
		- **摘要**: 3D场景问题回答（3D SQA）代表了一个跨学科的任务，该任务集成了3D视觉感知和自然语言处理，从而赋予智能代理以理解和与复杂的3D环境进行交互。大型多模式建模的最新进展推动了不同数据集的创建，并刺激了3D SQA的指令调整和零摄像方法的开发。但是，这种快速的进步引入了挑战，尤其是在跨数据集和基线的统一分析和比较时。本文介绍了对3D SQA的首次全面调查，系统地审查了数据集，方法和评估指标，同时着重强调了数据集标准化，多模式融合和任务设计的关键挑战和未来机会。

	
	- ### Survey on AI-Generated Media Detection: From Non-MLLM to MLLM [[arxiv](https://arxiv.org/abs/2502.05240)] [[cool](https://papers.cool/arxiv/2502.05240)] [[pdf](https://arxiv.org/pdf/2502.05240)]
		> **Authors**: Yueying Zou,Peipei Li,Zekun Li,Huaibo Huang,Xing Cui,Xuannan Liu,Chenghanyu Zhang,Ran He
		> **First submission**: 2025-02-07
		> **First announcement**: 2025-02-10
		> **comment**: No comments
		- **标题**: 对AI生成的媒体检测的调查：从非MLLM到MLLM
		- **领域**: 计算机视觉和模式识别
		- **摘要**: AI生成的媒体的扩散对信息真实性和社会信任提出了重大挑战，这使得可靠的检测方法高度要求。检测AI生成的培养基的方法已迅速发展，与多模式大型语言模型（MLLM）的进步相似。当前的检测方法可以分为两个主要组：基于非MLLM和基于MLLM的方法。前者采用了由深度学习技术提供动力的高精度，特定于领域的探测器，而后者则利用基于MLLM的通用检测器，这些探测器基于整合真实性验证，解释性和本地化功能的MLLM。尽管在该领域取得了重大进展，但文献中仍然存在有关一项综合调查的差距，该调查研究了从域特异性到通用检测方法的过渡。本文通过对两种方法进行系统的综述，从单模式和多模式的角度分析它们来解决这一差距。我们对这些类别进行了详细的比较分析，研究了它们的方法论上的相似性和差异。通过此分析，我们探讨了潜在的混合方法，并确定了伪造检测中的关键挑战，为将来的研究提供了方向。此外，随着MLLM在检测任务中越来越普遍，道德和安全考虑因素已成为关键的全球关注点。我们研究了各个司法管辖区围绕生成AI（Genai）的监管景观，为该领域的研究人员和从业人员提供了宝贵的见解。
	
	- ### A Survey on Industrial Anomalies Synthesis [[arxiv](https://arxiv.org/abs/2502.16412)] [[cool](https://papers.cool/arxiv/2502.16412)] [[pdf](https://arxiv.org/pdf/2502.16412)]
		> **Authors**: Xichen Xu,Yanshu Wang,Yawen Huang,Jiaqi Liu,Xiaoning Lei,Guoyang Xie,Guannan Jiang,Zhichao Lu
		> **First submission**: 2025-02-22
		> **First announcement**: 2025-02-24
		> **comment**: No comments
		- **标题**: 一项关于工业异常合成的调查
		- **领域**: 计算机视觉和模式识别,计算工程、金融和科学
		- **摘要**: 本文全面回顾了异常合成方法。现有的调查专注于有限的技术，缺少整体现场视图和理解方法互连。相比之下，我们的研究提供了统一的综述，涵盖了基于手工制作的，基于分布的生成模型（GM）的基于手工制作的，基于视觉模型和基于视觉模型（VLM）基于基于的综合的代表性方法。我们介绍了第一个工业异常合成（IAS）分类法。先前的工作缺乏正式分类或使用简单的分类法，妨碍结构化的比较和趋势识别。我们的分类法提供了一个精细的框架，反映了方法论进步和实际含义，从而扎根未来的研究。此外，我们探讨了跨模式合成和大规模VLM。先前的调查忽略了异常合成中的多模式数据和VLM，将见解限制在其优势中。我们的调查分析了它们的整合，收益，挑战和前景，提供了通过多模式学习来提高IAS的路线图。可以在https://github.com/m-3lab/awesome-anomaly-synthesis中获得更多资源。


	- ### A Survey on Multimodal Recommender Systems: Recent Advances and Future Directions [[arxiv](https://arxiv.org/abs/2502.15711)] [[cool](https://papers.cool/arxiv/2502.15711)] [[pdf](https://arxiv.org/pdf/2502.15711)]
		> **Authors**: Jinfeng Xu,Zheyu Chen,Shuo Yang,Jinze Li,Wei Wang,Xiping Hu,Steven Hoi,Edith Ngai
		> **First submission**: 2025-01-22
		> **First announcement**: 2025-02-24
		> **comment**: No comments
		- **标题**: 一项关于多模式推荐系统的调查：最新进展和未来方向
		- **领域**: 信息检索,多媒体
		- **摘要**: 从互联网上快速扩展的信息中获取有价值的数据已成为一个重大问题，并且推荐系统已成为一种广泛使用且有效的工具，可帮助用户发现感兴趣的项目。推荐系统的本质在于它们能够预测用户评级或各种项目的偏好，并随后根据历史互动数据和公开可用信息推荐最相关的评分。随着多种多媒体服务的出现，包括文本，图像，视频和音频，人类可以通过多种方式感知世界。因此，能够理解和解释不同模态数据的推荐系统可以更有效地指出个体偏好。多模式推荐系统（MRS）不仅捕获了多种模态的隐式交互信息，而且有可能发现这些模式之间隐藏的关系。这项调查的主要目的是全面回顾MRS的最新研究进步，并从技术角度分析模型。具体而言，我们旨在从技术角度总结太太的一般过程和主要挑战。然后，我们通过将其分类为四个关键领域来介绍现有的MRS模型：特征提取，编码器，多模式融合和损耗功能。最后，我们进一步讨论了开发和增强MRS的潜在未来方向。这项调查是MRS Field Mrs Field的研究人员和从业人员的综合指南，提供了有关MRS技术现状的见解，并确定了未来研究的领域。我们希望有助于开发更复杂和有效的多模式推荐系统。为了访问本文的更多详细信息，我们开源一个存储库：https：//github.com/jinfeng-xu/awesome-multimodal-recommender-systems。

	- ### BalanceBenchmark: A Survey for Multimodal Imbalance Learning [[arxiv](https://arxiv.org/abs/2502.10816)] [[cool](https://papers.cool/arxiv/2502.10816)] [[pdf](https://arxiv.org/pdf/2502.10816)]
		> **Authors**: Shaoxuan Xu,Menglu Cui,Chengxiang Huang,Hongfa Wang,Di Hu
		> **First submission**: 2025-02-15
		> **First announcement**: 2025-02-17
		> **comment**: 9 pages, 3 figures
		- **标题**: BalanceBenchmark：多模式失衡学习的调查
		- **领域**: 机器学习,人工智能
		- **摘要**: 多模式学习已引起关注，因为它可以整合来自不同模式的信息的能力。但是，多模式的失衡问题通常会阻碍它，在这些问题中，某些模态占主导地位，而其他模式仍然不足。尽管最近的研究提出了各种方法来减轻此问题，但它们缺乏全面且公平的比较。在本文中，我们根据他们采用减轻失衡的策略进行了系统地将各种主流多模式不平衡算法分为四组。为了促进对这些方法的全面评估，我们引入了BalanceBenchmark，这是一个基准，包括多个使用多维数据集和评估指标，从三个角度：性能，不平衡程度和复杂性。为了确保公平的比较，我们开发了一个模块化和可扩展的工具包，该工具包标准化了不同方法的实验工作流程。基于使用BalanceBenchmark的实验，我们已经确定了有关性能，平衡程度和计算复杂性方面不同方法组的特征和优势的几个关键见解。我们希望这种分析可以激发更有效的方法来解决未来的失衡问题以及基础模型。该工具包的代码可在https://github.com/gewu-lab/balancebenchmark上获得。

	- ### Artificial intelligence-enabled detection and assessment of Parkinson's disease using multimodal data: A survey [[arxiv](https://arxiv.org/abs/2502.10703)] [[cool](https://papers.cool/arxiv/2502.10703)] [[pdf](https://arxiv.org/pdf/2502.10703)]
		> **Authors**: Aite Zhao,Yongcan Liu,Xinglin Yu,Xinyue Xing
		> **First submission**: 2025-02-15
		> **First announcement**: 2025-02-17
		> **comment**: No comments
		- **标题**: 使用多模式数据对帕金森氏病的启用人工智能检测和评估：一项调查
		- **领域**: 机器学习,声音
		- **摘要**: 高度适应性和可重复使用的人工智能（AI）模型的快速出现将彻底改变医疗领域，尤其是在帕金森氏病（PD）的诊断和管理中。当前，尚无有效的生物标志物来诊断PD，评估其严重性或跟踪其进展。现在，许多AI算法用于PD诊断和治疗，能够基于多模式和异构疾病症状数据执行各种分类任务，例如步态，手动运动和PD患者的语音模式。它们提供表达的反馈，包括预测PD的潜在可能性，评估个体或多种症状的严重性，有助于早期检测以及评估康复和治疗效果，从而证明先进的医学诊断能力。因此，这项工作通过生物识别症状识别进行了对有关PD检测和评估的最新作品的汇编，重点是机器学习和深度学习方法，强调其收益，揭露其弱点，以及它们在开放新的研究道路上的影响。此外，它还对用于解决相关约束的数据集，方法和架构进行了分类和表征。此外，本文探讨了数据驱动的AI技术在PD诊断中带来的潜在机会和挑战。

	- ### Connector-S: A Survey of Connectors in Multi-modal Large Language Models [[arxiv](https://arxiv.org/abs/2502.11453)] [[cool](https://papers.cool/arxiv/2502.11453)] [[pdf](https://arxiv.org/pdf/2502.11453)]
		> **Authors**: Xun Zhu,Zheng Zhang,Xi Chen,Yiming Shi,Miao Li,Ji Wu
		> **First submission**: 2025-02-17
		> **First announcement**: 2025-02-18
		> **comment**: No comments
		- **标题**: 连接器-S：多模式大语言模型中连接器的调查
		- **领域**: 机器学习,人工智能
		- **摘要**: 随着多模式大语言模型（MLLM）的快速发展，连接器在桥接多种方式和增强模型性能方面起着关键作用。但是，连接器的设计和演变尚未进行全面分析，在了解这些组件如何运行并阻碍更强大的连接器的开发方面留下了差距。在这项调查中，我们系统地检查了MLLM中连接器的当前进度，并提出了结构化的分类法，将连接器分类为原子操作（映射，压缩，专家的混合物）和整体设计（多层，多层编码器，多模式场景），以突出显示其技术和进步。此外，我们讨论了一些有希望的研究前沿和挑战，包括高分辨率输入，动态压缩，指南信息选择，组合策略和解释性。该调查旨在作为研究人员的基础参考和明确的路线图，为下一代连接器的设计和优化提供宝贵的见解，以增强MLLM的性能和适应性。
	
	- ### A Survey on Mechanistic Interpretability for Multi-Modal Foundation Models [[arxiv](https://arxiv.org/abs/2502.17516)] [[cool](https://papers.cool/arxiv/2502.17516)] [[pdf](https://arxiv.org/pdf/2502.17516)]
		> **Authors**: Zihao Lin,Samyadeep Basu,Mohammad Beigi,Varun Manjunatha,Ryan A. Rossi,Zichao Wang,Yufan Zhou,Sriram Balasubramanian,Arman Zarei,Keivan Rezaei,Ying Shen,Barry Menglong Yao,Zhiyang Xu,Qin Liu,Yuxiang Zhang,Yan Sun,Shilong Liu,Li Shen,Hongxuan Li,Soheil Feizi,Lifu Huang
		> **First submission**: 2025-02-22
		> **First announcement**: 2025-02-25
		> **comment**: 30 pages, 4 Figures, 10 Tables
		- **标题**: 关于多模式基础模型的机械解释性的调查
		- **领域**: 机器学习,人工智能
		- **摘要**: 基础模型的兴起已经改变了机器学习研究，促使努力揭示其内部运作，并开发更高效，更可靠的应用程序以更好地控制。尽管在解释大语言模型（LLM），多模式基础模型（MMFMS）（例如对比视觉模型，生成视觉语言模型和文本对图像模型）方面取得了重大进展，并在非兴趣框架之外提出了独特的解释性挑战。尽管进行了初步研究，但LLM和MMFM的可解释性之间仍然存在很大的差距。该调查探讨了两个关键方面：（1）LLM可解释性方法对多模型模型的适应，以及（2）了解单峰语言模型和跨模式系统之间的机械差异。通过系统地审查当前的MMFM分析技术，我们提出了一种结构化分类法的解释性分类法，比较单峰和多模式架构之间的见解，并突出关键的研究差距。

	- ### A Comprehensive Survey on Composed Image Retrieval [[arxiv](https://arxiv.org/abs/2502.18495)] [[cool](https://papers.cool/arxiv/2502.18495)] [[pdf](https://arxiv.org/pdf/2502.18495)]
		> **Authors**: Xuemeng Song,Haoqiang Lin,Haokun Wen,Bohan Hou,Mingzhu Xu,Liqiang Nie
		> **First submission**: 2025-02-18
		> **First announcement**: 2025-02-26
		> **comment**: No comments
		- **标题**: 一项关于构成图像检索的全面调查
		- **领域**: 多媒体,人工智能,计算机视觉和模式识别,信息检索
		- **摘要**: 组成的图像检索（CIR）是一项新兴但具有挑战性的任务，允许用户使用多模式查询搜索目标图像，包括参考图像和修改文本，指定用户对参考图像的所需更改。鉴于其具有巨大的学术和实践价值，CIR已成为计算机视觉和机器学习社区中迅速增长的兴趣领域，尤其是在深度学习方面的进步。据我们所知，目前尚无对CIR的全面审查，可以及时概述该领域。因此，我们综合了包括ACM TOIS，Sigir和CVPR在内的顶级会议和期刊中120多个出版物的见解，我们使用精细的分类法系统地将现有监督的CIR和零摄入CIR模型分类。为了进行全面综述，我们还简要讨论了与CIR密切相关的任务的方法，例如基于属性的CIR和基于对话的CIR。此外，我们通过比较多个数据集的实验结果来总结基准数据集，以评估和分析现有的监督和零射击CIR方法。此外，我们提出了这一领域有希望的未来方向，为对进一步探索感兴趣的研究人员提供了实践见解。在https://github.com/haokunwen/awesome-composed-image-retrieval中维护并不断更新相关工作的策划集合。

	
	- ### A Survey on Video Analytics in Cloud-Edge-Terminal Collaborative Systems [[arxiv](https://arxiv.org/abs/2502.06581)] [[cool](https://papers.cool/arxiv/2502.06581)] [[pdf](https://arxiv.org/pdf/2502.06581)]
		> **Authors**: Linxiao Gong,Hao Yang,Gaoyun Fang,Bobo Ju,Juncen Guo,Xiaoguang Zhu,Xiping Hu,Yan Wang,Peng Sun,Azzedine Boukerche
		> **First submission**: 2025-02-10
		> **First announcement**: 2025-02-11
		> **comment**: No comments
		- **标题**: 一项关于云边缘末端协作系统中视频分析的调查
		- **领域**: 网络和互联网架构,计算机视觉和模式识别,机器学习
		- **摘要**: 视频数据的爆炸性增长推动了云边缘末端协作（CETC）系统中分布式视频分析的开发，从而实现了有效的视频处理，实时推理和隐私保护分析。在多个优点中，CETC系统可以分发视频处理任务，并在云，边缘和终端设备上启用自适应分析，从而在视频监视，自动驾驶和智能城市中取得突破。在这项调查中，我们首先分析了基本建筑组件，包括等级，分布式和混合框架，以及边缘计算平台和资源管理机制。在这些基础的基础上，以边缘为中心的方法强调设备处理，边缘辅助下载和边缘智能，而以云为中心的方法则利用强大的计算能力来用于复杂的视频理解和模型培训。我们的调查还涵盖了混合视频分析，其中包含自适应任务卸载和资源感知的调度技术，可优化整个系统的性能。除了传统的方法之外，大语言模型和多模式集成的最新进展既揭示了平台可伸缩性，数据保护和系统可靠性的机会和挑战。未来的方向还包括可解释的系统，有效的处理机制和高级视频分析，为这个动态领域的研究人员和从业人员提供了宝贵的见解。

	- ### A Comprehensive Survey on Generative AI for Video-to-Music Generation [[arxiv](https://arxiv.org/abs/2502.12489)] [[cool](https://papers.cool/arxiv/2502.12489)] [[pdf](https://arxiv.org/pdf/2502.12489)]
		> **Authors**: Shulei Ji,Songruoyao Wu,Zihao Wang,Shuyu Li,Kejun Zhang
		> **First submission**: 2025-02-17
		> **First announcement**: 2025-02-18
		> **comment**: No comments
		- **标题**: 对视频到音乐的生成AI的全面调查
		- **领域**: 音频和语音处理,人工智能,多媒体
		- **摘要**: 视频到音乐生成的迅速增长可以归因于多模式生成模型的上升。但是，缺乏在该领域的工作中全面梳理的文献。为了填补这一空白，本文使用深层生成的AI技术对视频到音乐的一生进行了全面评论，重点关注三个关键组成部分：视觉功能提取，音乐生成框架和调理机制。我们根据每个组件的设计对现有方法进行分类，从而阐明了不同策略的作用。在此之前，我们提供了视频和音乐方式的细粒度分类，说明了不同类别如何影响一代管道中组件的设计。此外，我们总结了可用的多模式数据集和评估指标，同时突出了该领域的持续挑战。